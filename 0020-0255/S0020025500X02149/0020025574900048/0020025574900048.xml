<doc:document xmlns:doc="http://www.elsevier.com/xml/document/schema"><rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"><rdf:Description rdf:about="http://dx.doi.org/10.1016/0020-0255(74)90004-8"><dc:format xmlns:dc="http://purl.org/dc/elements/1.1/">application/xml</dc:format><dc:title xmlns:dc="http://purl.org/dc/elements/1.1/">On pursuit and feedback in optimal stochastic control-explicit control laws</dc:title><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/"><rdf:Seq><rdf:li>Åke Wernersson</rdf:li></rdf:Seq></dc:creator><dc:description xmlns:dc="http://purl.org/dc/elements/1.1/">Information Sciences 7 (1974) 29-48. doi:10.1016/0020-0255(74)90004-8</dc:description><prism:aggregationType xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/">journal</prism:aggregationType><prism:publicationName xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/">Information Sciences</prism:publicationName><prism:copyright xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/">Copyright © unknown. Published by Elsevier Inc.</prism:copyright><dc:publisher xmlns:dc="http://purl.org/dc/elements/1.1/">Elsevier Inc.</dc:publisher><prism:issn xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/">0020-0255</prism:issn><prism:volume xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/">7</prism:volume><prism:coverDisplayDate xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/">1974</prism:coverDisplayDate><prism:coverDate xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/">1974</prism:coverDate><prism:pageRange xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/">29-48</prism:pageRange><prism:startingPage xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/">29</prism:startingPage><prism:endingPage xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/">48</prism:endingPage><prism:doi xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/">10.1016/0020-0255(74)90004-8</prism:doi><prism:url xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/">http://dx.doi.org/10.1016/0020-0255(74)90004-8</prism:url><dc:identifier xmlns:dc="http://purl.org/dc/elements/1.1/">doi:10.1016/0020-0255(74)90004-8</dc:identifier></rdf:Description></rdf:RDF><dp:document-properties xmlns:dp="http://www.elsevier.com/xml/common/doc-properties/schema"><dp:raw-text>INFORMA T/ON SCIENCES 1, 29-48 (1974) 29

On Pursuit and Feedback in Optimal Stochastic Control-Explicit Control Laws

ÂKE WERNERSSON

Institute for Optimization and Systems Theory, Royal Institute of Technology, S-100 44

Stockholm 70, Sweden

Communicated by L. E. Zachrisson

ABSTRACT

In this paper a non-gaussian discrete time stochastic pursuit problem is solved. Then this
solution is applied to a class of linear stochastic feedback problems with arbitrarily gener-
ated disturbances and incomplete state information. As a by-product, we obtain a general-
ized version of the well-known "separation theorem." In particular, the solution is applied
to obtain explicit feedback laws for systems with imperfectly known disturbance
parameters.

I. INTRODUCTION

The common approach to solving stochastic pursuit problems with incom-
plete state information is to formulate them as feedback problems. Here, we
will do the reverse, i.e., we will first solve a class of pursuit problems by a direct
method using samplewise solutions of the corresponding deterministic problem
and then the stochastic feedback problem. This method has the advantage that
it requires no special assumptions on the measurement noise or on the signal to
be pursued.

OUTLINE OF THE PAPER

First we formulate the pursuit problem heuristically and then, in Sec. 3, we
pose our problem precisely and show a property that is pertinent to understand-
ing our class of admissible control laws.

As an aid in solving the stochastic problem, we shall solve a corresponding de-
terministic pursuit problem in Section 4 and in this way obtain samplewise solu-
tions of the stochastic problem. Unfortunately, these solutions M? (co) are
non-admissible since they are neither "causal" nor functions ofz. Then we
verify that we can get the optimal control law as a conditional expectation, more
precisely the mapping i^ defined by

© American Eisevier Publishing Company. Inc., 1974

30                                                  ÂKE WERNERSSON
â^t)=E[uo^)\Zt]

turns out to define the optimal control law.

In Section 6, the problem of finding optimal feedback laws for the system

X^i =AtXt+BiUt+Uf
Z t =HfXt + Wt

is considered,1 and the optimal feedback law is proved to be equivalent to the
optimal control law for a stochastic pursuit problem.

For non-Gaussian sequentially independent2 disturbances {i^, w^} this feed-
back problem has been treated by Root [1] and Alspach, Sorenson [2]. The
assumption of independent disturbances is too restrictive for many applications
and has been relaxed here (still keeping the feedback law explicit), i.e., an arbi-
trary sequence {i^, w J is considered.

Stochastic control systems with incompletely known noise parameters give an
important class of problems, which will introduce a special kind of sequential
dependence. This is a class of problems where our solutions will give optimal
feedback laws (in the general case, control laws of the "classical form U= -LX"
fails to be optimal).

Because of the nice properties of the solutions delivered by the method used,
we have throughout the paper treated more general problems than is common in
the literature. For example, in the feedback problems we have chosen a general
quadratic form Q(X, U) as criterion function. Further, we allow also "delay in
control action," i.e., the value of a control variable must be decided say d time
units before it affects the system to be controlled.

2. HEURISTIC FORMULATION OF THE
STOCHASTIC PURSUIT PROBLEM

In this section, the pursuit problem is discussed and formulated heuristicly.
A more precise formulation is given in the next section together with a definition
of the relevant mathematical quantities.

We consider a discrete time stochastic pursuit problem with a nonlinear sto-
chastic vector process

yt^=^t(yt,Vt),                        (2.1)

with Vf as excitation noise. The information about y t is received through dis-
turbed nonlinear measurements z f according to

Zt=ht(Vt,Wt).                        (2.2)

'Compare also the recent papers [14] and [15].
2That is (vf, Wf) and (v^., w^} are independent if t ^ r.

OPTIMAL STOCHASTIC CONTROL                                      31

The noise sequences {uJ and {w,} can be rather arbitrary, for example non-
gaussian, mutually and sequentially dependent.

We will use the measurements to control a linear system

x,, =AtX,+Btit,                       (2.3)
so that the expectation of a quadratic form

II XT - Dry T II ß + É' II x' - ^Vt llß, (t) + II "r llß, W       (2.4)

t=0

is minimized (Qo &gt; 0, ßi &gt; 0, Q^ &gt; 0 and £), is an appropriate matrix).
The problem is illustrated by Fig. 2.1.




Non-linear generation  Non-linear     Control     Linear pursuing system

of signal to be         measurement     law

followed

Fig. 2.1. The stochastic pursuit problem.

Our goal is to design the "black box" i^(-), where Zy,.. ., Zy are arguments
in the function ^().

Some comments on Uf should be made. Our problem is to find the optimal
way to choose Uf based on the measurements (ZQ, ..., Zy) = z'', i.e., to construct
the optimal "black box" i^(-). This is equivalent to the problem of finding
optimal mappings «^() such that the stochastic variables u^ = &lt;^(z0 will mini-
mize the criterion function. In the next section it is found that control policies
of the form u^ = «^(z^, ut~\, x1) are already included in the formulation.

3. MATHEMATICAL FORMULATION OF THE
STOCHASTIC PURSUIT PROBLEM

With the previous section as background, the problem is now formulated pre-
cisely. First we make some assumptions, then we state the problem and give

32                                              ÂKE WERNERSSON

some of its properties. Some remarks on the probabilistic set-up are given in
Appendix 1.

THE PURSUIT SIGNAL

The randomness is introduced into the problem only by y o and the sequences
{u,}, {wJ (this makes a minimal but sufficiently large underlying probability
space obvious).

Assumption 3.1. The only requirements3 we put on {u,}, {Wf} and {$,} is
that y f should be such that

E\yîyt\&lt;°° for all r.                     (3.1)
Further we introduce the notation

yr^t=E\yr\zt],
where

z^zo,. ..,z,).

THE ADMISSIBLE CONTROL LAWS

Our problem is to find the optimal sequence of mappings ipo, 1^1,... , ^r-i.
Such a sequence will be denoted by ip and called a policy or control law. By
notations like xf is meant the stochastic variable that is obtained when the
policy if has been used (Xf without a specified if is not completely defined, but
it can be convenient to leave out if if no confusion is possible).

We will make an assumption which says that the "control box" remembers
old measurements perfectly. In the sequel we will also consider "delays in con-
trol" of size d. The assumption below is more general than necessary in that it
also covers time variable delays dt which are "information-preserving." We
specify the information pattern in the following way:

Assumption 3.2. Ifzo,...,z,, are arguments in ^.r(-)&gt; v &lt; r, then they shall
also be among the arguments in i^(-) for every t &gt; T.

This assumption seems unrealistic as it stipulates an increasing memory. But
to leave this type of information pattern will in the general case give rise to very
difficult stochastic control problems, compare [3]. We are now in a position to
define the admissible control policies. Pathological v('): s are eliminated by an
extra assumption in Appendix 1.

Definition 3.1. A control policy ^ = {^()} is admissible if it fulfills Assump-
tion 2 above (and Assumption A 1.1 in Appendix 1). This class of admissible

3We also require &lt;1&gt;^ and h f to be Borel functions.

OPTIMAL STOCHASTIC CONTROL

control laws does not seem to be adequate m the sense that old Uf : s are not in-
cluded, but this is not the case, as follows from Proposition 3.1.

[i i

F il vf - n v il2   + v 11 vf - n i» il2   + il n^ ii2

f. \\x^  L'TyT\\Qy   2- "-^ "^fliOi 'll"rlls,

Problem 3.1. Find the admissible policy ^ that minimizes

r                      r-i
F 11 vf - n v il2  + v il vf - n i» il2

f. \\\X^   ^TVT^Qy   2^ "t   "^fl'O

L                    f=o

when (Ûo &gt; O, Qi &gt; O, 02 &gt; 0)

&lt;+i =/1^+5,M^o given

and

where y^ and z, are as before.

(3.2)

(3.3)

(3.4)

Problem 3.2. (delay in control) Same as the previous problem, but (3.4) is
replaced by

^ = ^(z^) u? &gt; 0 (z^ = 0 when r &lt; 0).

(3.5)

The later problem corresponds to the situation that a control is delayed d steps
before it affects the system. Time variable delays df are possible if Assumption
3.2 is not violated. Our method of solution will also work if we generalize the
criterion to a general quadratic form.

Problem 3.3. (general problem) Same as the previous problems, but (3.2) is
replaced by

r-i

£

t=0

(3.6)

where Q^ is a positive semidefmite symmetric quadratic form4 with ßyy &gt; 0.

We complete the problem formulation by stating a proposition that might
eliminate some doubts about the admissible control policies. The proposition
simply states that we will not get a better control law if we "remember all old
Xf and Uf: s"the formulation already made covers this possibility.

*Q(x,y,u)=[x* :y*:u*\



			x
Qxx	Qxy	Qxu	
Qyx	Qyy	Qyu	y
Qux	Quy	Quu	
			u

34

ÂKE WERNERSSON

-Ll



								X"'
	\		^		^1			t
-t		^()		f(^. u^)				|
			i					l
		* t	i	t				

Control law

Arbitrary pursuing system

Fig. 3.1. Illustration of the proposition. For classical information pattern nothing is gained
if we include the interaction- - -in the admissible control laws.

PROPOSITION 3.1. For the information pattern m Assumption 3.2 all sto-
chastic variables «y = Î? t(zt~d' ut~l  xt)s "OT be represented by an admissible
control law Uf = ^(z^, Xo).

Proof. If t &lt; d, the proposition is only a question of notation (z^ = 0 when
T &lt; 0). For t &gt; d we give only the main step of an induction-proof. Assume the
hypothesis u^ = ^.(z7"'', Xo) for T &lt; t - l. This implies that we can write
^r+i = XT+I (zr~ä', JCo) for T &lt; t - 1 there X is some Borel function. Let x^ etc.
denote the entire sequence, then we have

u, ^(z^V-1 ,^) =?f(^, ^-l)(zr-d,^), X^-^o))
^(z'-^o),

where ^ certainly exists as a Borel function due to Appendix 1 and Assumption
3.2. 

From the Proposition it follows that Assumption 3.2 is equivalent to assum-
ing a classical information pattern (as defined in Witsenhausen [3]). It can be
noted that the proof is based entirely on Assumption 3.2 (the pursuing system
can be arbitrary). We may further note that Uf = ^(z'^JCo) and u f = ^f[zt~d,
u1'1, x^ simply are two ways to represent the same stochastic variable. How-
ever the representation of the control law can affect the different "sensitivities"
very drastically.

4. A DETERMINISTIC PURSUIT PROBLEM

In our treatment of the original stochastic problem we will use the nice form
of the solution of the following deterministic problem.

''The initial value XQ is usually excluded from ipy(-) as xy is deterministic. We have also
left out the index ip and assumed y to be a Borel function.

OPTIMAL STOCHASTIC CONTROL                                   35

Problem 4.1. Given a (deterministic) sequence y^,... ,yf and a system

x^i =ArXT+B^.Ur''xtS.wen^&gt;t.               (4.1)
Find a sequence u,,.. ., u-p.^ that will minimize the cost

ô^r^+Z Q^Çx^y^u,),

T=t

where Q^ and (/^ are symmetric quadratic forms such that Q^, Q^ &gt; 0

andû^&gt;0-

It should be observed that we want to solve one problem for each JC(. and that

t is arbitrary. In the solution below, it should be noted that u, is a linear com-
bination ofXf and .y,,.. . ,y-r-

Define (the associated minimal cost)

W,(xy ... ,VT}-  min  (ö^r,^) + S Q^Çx^y^uÀ

Uf-UT-t    [                                        T=t                                         \

T-l

"r--"r-i l              T=t
and introduce the notations

Q'^Quu+B^P^B,                      (4.2)
Lt=(Q'ur\(Qu^BÎP^A,}.               (4.3)

THEOREM 4.1. The optimal sequence ut is generated by

^ = - (Û«)'1 [(Qux + W.i ^)^ + o.^t - Bîp^ ]      (4.4)
anrf /Ae minimal cost is given by

Wt(Xt,Vt,. .. ,VT)=xîPtXt- 2p^(y)x, +^(y),         (4.5)
where Xf, Pf, p,, q^ are given recursively by (4.1) and

PI ^Qxx^AÎP.^At-LÎQ'^L,
PT'Q^                               (4.6)

Pi =-4?Pt-n - ^WPr+i - ôuyJ'r) - QxyYt
PT=-Q(xTy)yT                                 (4.7)
Qt^Qt^l ^y^QyyYt- \\BtPt^l - Quyyt^Q)-^

OT^y'rO^YT-                             (4.8)
Furthermore, Pf is positive semidefinite and fif is unique.

Proof. The requirements for the use of dynamic programming are satisfied,
and only the essential steps are given. The functional equation is

36                                                 ÂKE WERNERSSON
Wf(Xt,yt,..-,yT)

=min {ß(o(^,.^;f,Ur)+ HVn 04,x,+5^,.y^i,. .. ,^r)}-
"r

We will now show that the solution of this functional equation is given by (4.4)
and (4.5). First, W^x-r^-p) is obviously given by (4.5). If we recursively use
(4.5) and (4.1), we will, after completing squares, get

Wt(Xt,yt,...,yT)=min {\\ u^ - ï, \\Q, + ^P^ - Ix^p^qi},
ut

where t^ is given by (4.4) and P(, pi, Q{ are given by (4.6)-(4.8). Only the first
term is affected by Uf, hence we will obtain the minimum (see below) by choos-
ing Ut = ut and get H^ according to (4.5).

To make the proof complete, we must verify that the stated quantities exists.
To do this rewrite P{ according to (indices are left out)

P, = (A - BLrPt., (A - BL) + Q^ - Q^L - L* Q^ +L*Q^L. (4.9)

We will now recursively show that Pf is positive semidefinite. If^+i &gt; 0 then it
is obvious that the first part of (4.9) is also positive semidefinite. For arbitrary
x, we have

x*(Q^ - Q^L - L*Q^+L*Q^L)x

Y

= x* ' -x*L* {Qxx Qxu] ..... &gt;0,
:      Jl.0^ Q^[-Lx

where the last inequality follows from the assumptions in problem 4.2. Thus
also the second part of (4.9) is positive semidefinite, hence ^ &gt; 0. From P, &gt; 0
and Quu &gt; 0 it follows that Q'u = Quu + BfF^i Bf &gt; 0. Thus, the proof is com-
plete, since the existence oîÇQ'uY1 guarantees the existence of H^ (the mini-
mum), Pf, Pi, and Qt. Furthermore u^ is unique. 

5. SOLUTION OF THE STOCHASTIC PURSUIT PROBLEM

To solve our original problem 3.3 (general formulation), consider a sample
function u £ Î2. If u is assumed given Vt(u), Zf(u) etc., can be treated as de-
terministic sequences. Thus, for a fixed sample function cu, we have a problem
that has been solved in the previous section. A control policy

"? (^- ^ = - Qu1 [(&amp;,. + W.i A^ (eu) + Quyy^ - Bîp^ (CJ)]6 (5.1)

is obtained, which is samplewise optimal. However, u?(x?, u) is not admissible
(it is not a function ofz^). But by forming the conditional expectation

equation (5.1) defines a ^-dependent mapping Uf (-, w) that will be used in the sequel.
The dot  stands for the x-variable.

OPTIMAL STOCHASTIC CONTROL                                      37

E[u^x^^)\zt-d}=W&lt;l)=^               (5.2)
we define a policy (p, which is optimal as stated in the following theorem.

THEOREM 5.1. The optimal policy (p for problem 3.3 {general formulation)
is given by the mappings

St = W"1} = - (o»)"1 [(Qux + BÎP^ A,)xf + Qay9t\t-d - BÎPt i t-d} (5.3)
together with xf^.^ = A^xf + B^üf and the mapping ^\t-d(.zt~d) where

Pr\t-d = ^rPr+llr-d - ^t [^rPr+^t-d ~ QuyYrM-d} ~ QxyVrït-d
PT\t-d=-Q(xy)yT\t-d                                          (5.4)

Pt-Qxx+AÎP^A.-LÎQiL,
PT=Q{S                                         (5.5)

Remark. The stochastic variable îl^ is linear in xf and 9r\t-d (T ^ 0. where
the coefficients are the same for all observed systems. The estimated quantities
9r\t-d wlu of course be non-linear functions ofz^. It should also be noted
u\3X^^t-d stc-, by no means are any "sufficient statistics."

Before we continue we will comment on the proof. Since the disturbances
are allowed to be sequentially dependent, the use of dynamic programming
would require a very large state space. Furthermore, from our proof we con-
clude that the functional equation would have been voluminous. The proof fol-
lows a method used by Zachrisson [4] for the time-continuous case. A pertinent
feature of the proof is that we compare different mappings-no recursive vari-
ational problem is solved.

Proof. Part 1: Consider a sample function CJ  Î2, that isy^), z,(o?) etc.,
can be considered as deterministic sequences. Consider also an arbitrary admis-
sible policy ip and the stochastic variables My(cu) = »^(z^ (cü)) and cost
V(xo, if, u) that correspond to u. If for the special samplefunction cu we apply
the solution of our previous deterministic pursuit problem, we obtain the opti-
mal non-admissible u^(x^, u) and cost

W^(u),y^),... ,J'rM) = 11^°(^)11^ - 2p,(cü)*x?(u;) + q^u). (5.6)

But (5.6) also defines a oï-dependent mapping H^(-, a?). We will now for the
special a? compare the costs VCxy, i^, 0?) and Wo(xo, cu) where

7(^o, ^ ^ W» (xo, ^) + ^ Q(xf, y ^(z^))

t=0

- ||Xo 11^ +2pî(c^o-&lt;?o(cu)
= Ho(^o, eu) + ^ {Q(x^,y ^(z^)) + H^i (x^ , co) - W^t ^)},

38                                              ÂKE WERNERSSON

where we have usedxf as an argument m H^(', tu) and defined WT*\ = O- Th0
last bracket { } can be most remarkably simplified. We summarize the rather
involved calculations: for the special u we use eq. (3.3)x!f+i = Afxf ^^t(zt~ ),
thereafter completing quadratic forms we find

{ } = || ^-d) + (Qi)-1 [(Q^ + BÎP^ A,)xÏ(u)

+ QuyYt - B^Pt^i ] HO +xf Zxf - 2^*(0;)4 + îr(o;)

where S, Ç, IT are equal to zero by equations (4.5)-(4.7), respectively. Using ^
in the mapping M?(', u) defmed by Eq. (5.1) gives

V(x ^ u) = W, (x o;) + ^ || ^{zt~&lt;i} - u? (xt ^)||^.    (5.7)

t'O

Part 2: We are now in the position to prove the optimality. First we average
(5.7) over w £ Î2 to obtain

E[V(x^, u)} =E[Q(x^,yT) + Z Q(xf,y ^-d))]

=E[Wo(xu)}+E['E ll^^)-"?^.")!!^]. (5.8)

This is the quantity to be minimized by choosing ip. By taking the conditional
expectation ofu?(x?, eu) m Eq. (5.1) we define the control law ^() according
to

(p^) = E [u? (X?, u-)\ ^t-d\ = ^.                (5.2)

Now by adding and subtracting suitable terms in (5.8), we get after taking con-
ditional expectations

f[7]=£[^o]+fZ£'[ll^(zrd)-^î,+t&lt;?(^,^)-«?(4,a,)

+^-U?(JC?,^)|lßJzr-&lt;î]

=E[Wo}+EZE[\\ût-uo(xiu)\^zt~d]
+E £ £[11^(2^) - ^ + u^xf, u) - iW, ^)||^ \zt-'i}
+ 2E £ E [ {^(zt-d) - û, - L,(xÏ - xÏ)}*  ß, {û, - u0, «, o;)} I z^}

where we used the function u^(-, a;) from (5.1) to simplify the difference

«?(4,^)-M?OC?,G;).

The last expression above is zero. This follows if we observe that ^(z^) -
ut - Lt(xf - xf) is z^-measurable and E [^ - u? (xf, u) \ z^] = 0 which fol-
lows by combining«^-, u) from Eq. (5.1) and Eq. (5.3). Hence we have

^[Fl^^ol+^Zfni^-M?^,")!!^!^]      (5.9)

with equality ifipt(') = ^rO- But the right side of (5.9) is unaffected by the
arbitrary ^, thus proving the optimality ofi^ (which is unique up to some suit-
ably choosen equivalence-class). 

The general case illustrated in Fig. 5.1 corresponds to delay between a deci-

OPTIMAL STOCHASTIC CONTROL

39



t-d zpredictor	^non-linear!										
^[t-d	M t-d				^	It	-d				
-a^ l-1Scy n.	"n			^	^						
T					A					'MODEL"	
"rit-d ^{^h-i	L^t-.d^	'-l^ I	°:			t	^	-^	+1-»	Delay -	/
	^It-d							l			
T S t									-		
										^ 	
(lin =. linear niatrix op	eration)										
								-^			
							"P	HySICAL	SÎ	ÏSTEM"	
			»	Delay			^n 1				^
			d	unit	S		Tt.	jr			
										^ (-J	


Fig. 5.1. Structure of the optimal solution to the stochastic pursuit problem. In the model
ut and Xf should be evaluated at time t - d and applied to the physical system.

sion made at time t-d and the time t that the resulting control excites the
system. Delays in measurements are trivially incorporated in the model. We re-
mind the reader that xf = ^(Model) in Eq. (5.3) is just a variable that gives iîy
a convenient representation. A method to reduce the sensitivity with respect to
imperfections in the model is suggested in [16].

6. APPLICATIONS TO STOCHASTIC FEEDBACK SYSTEMS

We will now apply the previous solution to obtain an explicit optimal policy
for a linear stochastic control system with incomplete state information. We
first state the stochastic feedback problem.

Problem 6.1. Find the admissible policy ^ that minimizes

S^W,^)]                 (6.1)
?=o                J

(Q&gt;0,Quu&gt;0)

^ll^llß^S^W^;1')'!
L          ?=o              J

40 ÂKE WERNERSSON

when

^i =A,X^ +ß^ +ü,; £-[^0] =^o
Z^H.X^w,

t/?' = ^(z^)

(6.2)

(6.3)

(6.4)

under the assumption E'




The main result m this section is Theorem 6.2, where our problem is solved.
The idea behind the solution is to show that the feedback problem is equivalent
to a pursuit problem. This equivalence seems perhaps to be obvious. However,
the equivalence is generally false if we leave the classical information pattern,
allow At etc., to be stochastic or consider non-linear systems (in these cases the
information is control-dependent). We will, in some steps, establish the equiva-
lence between the two problems.

We will now "separate the stochastic parts of the feedback loop." More pre-
cisely: Apart from that we use ^ instead ofip, let the pursuing system be

^ =A,x^B^(Zt-d), ^ =EW              (6.5)
which is the "controlled part oî Xf" Further, the "stochastic part of Xf" is

y^Xf-x^                        (6.6)

which will be the signal to be pursued. In the same way the "stochastic part of
Z^" is given by

z^Z^-H^,                       (6.7)

which is our information about y,. The stochastic parts are not affected by the
policy as stated in the following lemma.

LEMMA 6.1. The "stochastic parts" y t and Zf defined by respectively Eq.
{6.6) and Eq. (6.7) are not affected by ^. Hence we can write

y^=X*-x^=A,y,+u,                    (6.8)
Zt=Z^-H^=H^+Wt.                 (6.9)

Proof. As the initial state Xy is unaffected by 4' we have that y o = Xy -
E [XQ ] and ZQ = Ho Xy - H^E [Xo ] + Wo are also unaffected by 'î'. Recursively
it is now seen from Eq. (6.2) and Eq. (6.5) that 'I' does not affect y^. As we
have Zt = H^y^ + Wy the same is true for z^. 

''I.e., we allow the noise sequences {uy} and {w^} to be non-gaussian, mutually and se-
quentially dependent.

OPTIMAL STOCHASTIC CONTROL                                    41

Since our transition between a feedback- and a pursuit problem does not
critically depend on the special structure of the criterion function, we take the
opportunity to consider a more general problem.

Problem 6.2. Same as Problem 6.1, but Eq. (6.1) is replaced by

E[f(X^,...,X^;U^,...,U^)]           (6.10)

where/of course have to be such that this problem is well-defined.8
We will now state the corresponding pursuit problem.

Problem 6.3. Find the admissible policy ^ that minimizes

E[f(xo +^o, .. , ^T +yT' "Ï'    ' &lt;-i )]        (6.11)
when ^=^(2^) in

x^,=A^+B,uf;x^=E[X^             (6.12)
.y^i =/4^+!^;z^=//^+u^.             (6.13)

Our next step is to solve Problem 6.2 using !p (assumed to exist) from Problem
6.3. For this purpose we will use the following lemma.

LEMMA 6.2.

a(Zt^,)=a(zt)                       (6.14)

i.e., / and Z^ contains the same information irrespectively of^.

Proof. Consider a fixed but arbitrary policy ^. From Zy = Zy - Ho E [Xy] it
is seen that o(Zo)= a(zo) Assume the hypothesis o(Z1^,l) = a(zt~l ).

From Eq. (6.9), z, = Z? - H^ x*, it follows that 0(2') C ü(Z^ ) since Eq.
(6.5) gives that xf = X^Z^"1 ) for some Borel function X^(-)-

To prove the reverse inclusion we use x^' = \t(Zt^(l~\ ) above and the hy-
pothesis to obtain the representation x^ = ^(z^"' ). From Eq. (6.9) we will
get

Z^z^/Wz^-1)

from which aCZ^) C o^z') follows. By induction we have thus proved the in-
formation equivalence. 

THEOREM 6.1. /$ is an optimal solution to (pursuit) problem 6.3 then
^r defined recursively by

^(Z^^^Z^-^-")                 (6.15)
is an optimal solution to (feedback) Problem 6.2 (and vice versa).

^ "randomized policy" might give a lower cost, but this possibility is not considered
here.

42

ÂKE WERNERSSON

Proof. Take an arbitrary admissible ip (resp. ^), then there exists an equiva-
lent admissible 'p (resp. ^) in the sense that uf = Î/* for all u e Î2. This is seen
if we recursively define 'Ï' (resp. ^) by ^(Z^) = ^(Z^ - ^-d) resp.
1^(2^) = ^(z^ + Hx^), where the constructions are meaningful due to
Lemma 6.1 and 6.2.

If for a fixed sample function &lt;*; we use the equivalence above we obtain

f(Xo,... ,XÏ;UÏ,..., ^-i)=/^o +^o,.. . ,^+^r;^,.. . ,^-i).

Averaging over S2 and minimizing with respect to ^ (resp. ip) gives the desired
result (if we minimize with respect to '? or ip is immaterial due to the equiva-
lence above). 

The relations between the feedback and the pursuit problem is illustrated by
Fig. 6.1 and 6.2.




Fig. 6.1. Optimal solution of the stochastic feedback problem.

We can now state our main result in the following:

THEOREM 6.2. The optimal feedback policy to problem 6.1 is given by the
mapping

^ = ^(Z^) = - (Qir1 [(Qux + BÎP^ At)xf

+ Qux9t\t-cl - Bfpt^i \t-d} (6.16)

together with x*n = A^x^ + B^U^, the mapping y'r^-d^''1) andtne sample-
wise substitution z^ = Z* - H^x* where

PT\t-d ^-^ïPr-n \1-d ~ Lf [BrPr^i \t-d ~ QtixYr^-d} ~ QxxYr\t-d
PT^-d^-Q^yTM-d                                         (6.17)

OPTIMAL STOCHASTIC CONTROL

43



			Vfc 1 Y Y		,.	&lt;7					
		B^	.Â^JD.!^ \	"t		"t	^	" / t&lt;		.r^\	Delay j-
		L	y i	^				y^(z )	^t		
										T	
			| t 1 mût	t-t£*.ÏO							''t t
	^		/-?t+1, - - ^								
		"t		"t.							
			r i,,			x	t = "cont	rolled r	?art o	-t	
			11  -								
						y	t^t-	\ ~ """	icontp	olled	part of X
						^	t ° "t ^	+ w is	unaf	fected	by ip

Fig. 6.2. Equivalent optimal solution using the pursuit problem.

Pt-Q^+AÎP^At-LÎQiLf

P -n^
'r - Vxx

(6.18)

Proof. If we identify the criterion functions in Problem 3.3 and Problem 6.1,
the proof follows by a trivial combination of Theorem 5.1 and Theorem 6.1. 

A

The optimal U^ above does not m the general case fulfill the so-called "separa-
tion theorem," but can be seen as a generalization. The classical result can be
given the following useful formulation.

THEOREM 6.3. If the operational assumption

^rif-d^^r-l   -At9t\t-d
/\

is fulfilled, then U t is given by

/\      ^
Uf =-LtXt\t-d-

(6.19)

(6.20)

Proof. The proof follows from Eq. (6.19) and the previous theoremwe pre-
fer to leave out the rather long but simple calculations. 

If [Vt, Wf} is sequentially independent and has zero mean it is easily seen that
Eq. (6.19) is fulfilled, hence the classical result follows.

7. APPLICATION TO STOCHASTIC CONTROL

WITH THE NOISE PARAMETERS INCOMPLETELY KNOWN

A problem that has become classical is to find an optimal feedback policy
under a quadratic criterion to the system

44                                               ÂKE WERNERSSON

Xt^ = A,Xt+BtUt+Vt
Zt = HfXt + Wt,

where Vf, W( are "white" gaussian sequences with given mean and covariances.
In many applications it is unrealistic to assume A, B, H and the covariances to be
completely known. In this section we will allow the covariance matrices to be
incompletely known (i.e., we assume that there is a certain probability density
associated with the covariance matrices). We encounter several complications
when incompletely known noise parameters 6 appear in the system. A typical
example is when {üyO-i, er)}, for given mean ^ and variance a, is an independent
Gaussian sequence and y., a have the a priori distribution P(fi, a). Generally, we
want to find an optimal policy in the case where we have an a priori distribution
P(6) on the parameters 0 and require {üy(0), w^(ö)} to be sequentially indepen-
dent "when 6 is specified." No Gaussian assumptions will be needed to solve
the problem.

In the following, we restrict our treatment to at most a countable set of pa-
rameters ©. To allow a more general © will be of minor practical value and ob-
scure the results-at least if we want to be rigorous. Further, we hope that a
"discretizing of a" will not be more disturbing to our conscience then a discrete
time parameter. We formulate the problem below and add some pertinent
remarks.

Problem 7.1. For the criterion (6.1) find the optimal feedback policy ^
for

X^=AtXt+BtUt+v^                (7.1)

Z,=H,X^+Wt                       (7.2)

when the (non-gaussian) sequences {u,} and {\Vf} are sequentially independent
"for given 6 " (see Appendix 2 for a more precise formulation). Further let the
"unknown" parameter 6 have the a priori distribution P(6) on © and p., =
E[Vt\6,},&amp;ï[t.

Problem 7.2. Same as above but we require also

E[Vt\6] =0;E[Wt\6] =0                   (7.3)
for each 6.

Remark 7.1. If the sequence {uf(0)} (given 6) consists of independent vari-
ables, {u,} (only P(6) given) will be dependent with very few exceptions
(Gaussian distributions is no exception).

More details on the subject of the remark can be found on p. 82 of [9] and
in [10]. We will first solve Problem 7.2, a case where the "separation theorem"
is still valid.

OPTIMAL STOCHASTIC CONTROL                                   45

THEOREM 7.1. The optimal control policy for Problem 7.2 is given by

Uf=-L,X^                       (7.4)
where L i is given by Eq. (4.3).

Proof. From Eq. (6.8) we use the recursive relation J^+i = AfYt + i&gt;t to
obtain

Yr=A^ .. .AtYt-^-A^t At^Vt+.-.+Vr-ï.       (7.5)
Then taking expectations with respect to Z^ gives
'y^.^E\y,\Zt-'l\=E\A^...A,y,\Zt-d\

+E[A^...A^v^...+v^\Zt-d]
To calculate the last part, consider (r &gt; r):

£'[ü^|^f-d]=£'[£{^|0,H'r-d&gt;'H'o,"r-d-l' .,Uo}\Zt~c'}

but due to the sequential independence of {u,, w^] "for given 0" the inner con-
ditional expectation will reduce to E{u^ 16} = 0 according to Eq. (7.3). Thus we
have

^Tir-d^T-l   ^tVtit-d

i.e., the operational assumption in Theorem 6.3 and the proof is complete. 

For applications it will be more interesting to assume a randomly varying 6 y.
Due to Eq. (7.3), the theorem is still valid although the necessary estimation
problems will be more complicated. Summing up:

COROLLARY 7.1. The control policy in Theorem 7.1 is also optimal if6, is a
stochastic sequence taking values in Q.

Proof. First we replace 0 by the multiple (Oo,. .., 0,,..., 9 r). Then the
result trivially follows from Theorem 7.1. 

The previous results concerned arbitrary incompletely known disturbances
with zero mean. We will now weaken this restriction and assume the distur-
bances to have general mean values ^i, = E [ü, 10;]. A typical case is if we know
that Vf is biased, ± 1, with given a priori probabilities, but otherwise is the same
for different 6.

THEOREM 7.2. The optimal control policy for Problem 7.1 (general case) is
given by

Ù, = ^(Z^) = -L,X, - £, J 2: n,Qt(Ôi\ Z^X

l '             J

46                                              ÂKE WERNERSSON

where L t is given by Eq. (4.3)

m-E^e.]                          (7.7)
qt(6,\Zt-d)=Pr(6=6i\Zt-ci)                  (7.8)
and the matrix £^ is indicated on the proof.

Proof. To shorten the proof we put d = 0 and leave out some indices. From
Eq. (7.5) we obtain

îr\t =AT-t9^+E{E[AT-t~l v, + ... + u,-, \Zt,6} \Zt}.

If we use Eq. (7.7) and the same arguments as in the proof of theorem 7.1 we
obtain

E[Us\Zt,6=6i} =11, îois&gt;t.
Using Eq. (7.8) and some calculations we will have

9r\t=AT-t^+{AT-t-l + .. .+A +/}  Jl:/^(0,|ZOl     (7.9)

i '           J

To obtain Ut we will now use Eq. (7.9) and Theorem 6.2. If we make explicit
use of the linearity of Eq. (7.9), we can, by Theorem 6.3, conclude that the first
part in Eq. (7.9) contributes by - L^Xf to Uf The contribution of the second
part can in the same way as in the proof of Theorem 6.3 be written

-£r f £^(9,1^)1 

The proof is complete if we accept this implicit way to define £, (the computa-
tions are straight forward, but involved). 

The purpose of this section was mainly to illustrate the use of the previous
results-several generalizations can simply be attained. Simulations and more
detailed discussions of the contents in this section will appear in [11]. The pre-
diction problems that have been encountered in this section can be solved ex-
actly in the gaussian case (forthcoming [10] and extensions of [12]) and ap-
proximately in the non-gaussian case (extensions of [13]). However, it ought to
be realized that systematic approximation methods must be developed in order
to implement the control laws in this section to practical systems.

APPENDIX 1. REMARKS ON THE PROBABILISTIC SET-UP

The underlying probability space has already been indicated in Section 3. In
this paper, we will make repeated use of conditional expectations of the type
£'[^2^]. To be exact, zt is a convenient notation for the least o-algebra gener-

OPTIMAL STOCHASTIC CONTROL                                       47

ated by the stochastic variables zt. In the same way it is obvious how the state-
ment "Ç is z'-measurable" should be interpreted (or equivalently Ï, is a Borel
function ofz').

To eliminate control policies that are only mathematical pathologies, we
make the following natural probabilistic restriction.

Assumption A 1.1. Each ^() is a Borel function between the appropriate

Euclidian spaces.9

This assumption is no restriction from any practical point of view.
Further, the assumption guarantees us a mathematically well-posed problem,

as we now have to seek the optimal $ in a well defined set of policies {if}.

APPENDIX 2: CONDITIONAL EXPECTATION AND
STOCHASTIC NOISE PARAMETERS

In Section 3 we chose the natural probability space (Î2^, S, Pf) defined by
the Euclidian "primitive random variables" y o and the sequences {uJ, {vvJ.
The main consequence of our incompletely known noise parameters will be to
give the probability space a special structure. We hope that a closer look on this
structure will be illustrative. Further, we will certainly evaluate our conditional
expectations with greater confidence after that look.

We know exactly how to solve our problem if0 is known. Therefore it is ad-
vantageous to include 6 explicitly into the description of the probability space.
We can consider our stochastic variables as generated in the following way: First
a 6 is selected at random. Then, highly dependent on the outcome of 6, our
primitive Euclidian random variables are selected, where a joint event is denoted
by a; = (0, cog).

We can now state a natural probability space (Î2, §,P) in a constructive way:

(1) First chose Sî = UÎ2; (where Î2, are Euclidian spaces which have a family
SB; of "Borel sets (;')" and a probability measure P, on these).

(2) The o-algebra § is defined on Î2 by US, where 8, C Î2, and S, e S;.

(3) The probability on a measurable set in SÎ will be
Pr(US,)=^Pr(6=6,)Pi(S,).

To evade probabilistic difficulties, we exclude a non-countable ©.

To solve the problems in Section 3 we used the probability space
(P.E, S, '£) It is obvious that we also can use (S2, §,P) since S C §.

It is now more explicitly clear how we should interpret for example
£' [I; 10 = 61 ], i.e., as the average of I; over those co CE Î2 where the parameter
6 happens to be 61.

^ith this assumption we have also excluded "randomized policies."

48                                             ÂKEWERNERSSON

 wish to express my gratitude to professor L. E. Zachrisson who suggested
the method and gave valuable help during the course of this work. I would also
like to thank Dr. A. Lindquist for many stimulating discussions.

REFERENCES

1. J. G. Root, Optimal control of non-gaussian linear stochastic systems with inaccessible
state variables, SIAMJ. Control 7, 317-323 (1969).

2. D. L. Alspach, and H. W. Sorenson, Stochastic optimal control for linear but non-
gaussian systems,/nr. J. Control 13,1169-1181 (1971).

3. H. S. Witsenhausen, Separation of estimation and control for discrete time system,
Proc. IEEE 59,1557-1566 (1971).

4. L. E. Zachrisson, On a separation theorem for almost separated systems (to appear).

5. L. E. Zachrisson, A proof of the separation theorem in control theory, IOS Report No.
R 23, Royal Institute of Technology, Stockholm, Sweden, March 1968.

6. A. Lindquist, Optimal control of linear stochastic systems with applications to time lag
systems, Information Sciences 4, 81-126 (1972).

7. K. J. Aström, Introduction to Stochastic Control Theory, Academic Press, New York-
London (1970).

8. H. Kushner, Introduction to Stochastic Control, Holt, Rinehart and Winston (1971).

9. M. Aoki, Optimization of Stochastic Systems, Academic Press, New York-London
(1967).

10. A. Wernersson, On optimal estimation and prediction of "mixed processes" (tentative
title, to appear).

H.A. Wernersson, On optimal stochastic control with incompletely known noise parame-
ters (tentative title, to appear).

12. F. L. Sims and D. G. Lainiotis, Recursive algorithm for the calculations of the adaptive
Kalman filter weighting coefficients, IEEE Trans. Automatic Control, AC-14, 215-216
(1969).

13. H. W. Sorenson and D. L. Alspach, Recursive bayesian estimation using Gaussian sums,
Automatica 7,465-479 (1971).

14. R. A. Brooks, Linear stochastic control; an extended separation principle, J. Math.
Anal. andAppl. 38, 569-587 (1972).

15. A Lindquist, On feedback control of linear stochastic system, SIAMJ. Control 11,
323-343 (1973).

16. A. Wernersson, On pursuit and feedback in optimal stochastic control-explicit control
laws, TRITA-MAT-1972-23, Royal Institute of Technology, Stockholm, Sweden, April
1972.

Received December 18, 1972</dp:raw-text><dp:aggregation-type>Journals</dp:aggregation-type><dp:version-number>S350.1</dp:version-number></dp:document-properties><cja:converted-article version="4.5.2" docsubtype="fla" xml:lang="en" xmlns:cja="http://www.elsevier.com/xml/cja/schema">
		<cja:item-info>
			<cja:jid>INS</cja:jid>
			<cja:aid>74900048</cja:aid>
			<ce:pii xmlns:ce="http://www.elsevier.com/xml/common/schema">0020-0255(74)90004-8</ce:pii>
			<ce:doi xmlns:ce="http://www.elsevier.com/xml/common/schema">10.1016/0020-0255(74)90004-8</ce:doi>
			<ce:copyright type="unknown" year="1974" xmlns:ce="http://www.elsevier.com/xml/common/schema"/>
		</cja:item-info>
		<cja:head>
			<ce:title xmlns:ce="http://www.elsevier.com/xml/common/schema">On pursuit and feedback in optimal stochastic control-explicit control laws</ce:title>
			<ce:author-group xmlns:ce="http://www.elsevier.com/xml/common/schema">
				<ce:author>
					<ce:given-name>Åke</ce:given-name>
					<ce:surname>Wernersson</ce:surname>
				</ce:author>
				<ce:affiliation>
					<ce:textfn>Institute for Optimization and Systems Theory, Royal Institute of Technology, S-100 44 Stockholm 70, Sweden</ce:textfn>
				</ce:affiliation>
			</ce:author-group>
			<ce:date-received day="18" month="12" year="1972" xmlns:ce="http://www.elsevier.com/xml/common/schema"/>
			<ce:miscellaneous xmlns:ce="http://www.elsevier.com/xml/common/schema">Communicated by L.E. Zachrisson</ce:miscellaneous>
			<ce:abstract class="author" xmlns:ce="http://www.elsevier.com/xml/common/schema">
				<ce:section-title>Abstract</ce:section-title>
				<ce:abstract-sec>
					<ce:simple-para view="all">In this paper a non-gaussian discrete time stochastic pursuit problem is solved. Then this solution is applied to a class of linear stochastic feedback problems with arbitrarily generated disturbances and incomplete state information. As a by-product, we obtain a generalized version of the well-known “separation theorem.” In particular, the solution is applied to obtain explicit feedback laws for systems with imperfectly known disturbance parameters.</ce:simple-para>
				</ce:abstract-sec>
			</ce:abstract>
		</cja:head>
		<cja:tail>
			<ce:bibliography view="all" xmlns:ce="http://www.elsevier.com/xml/common/schema">
				<ce:section-title>References</ce:section-title>
				<ce:bibliography-sec>
					<ce:bib-reference id="BIB1">
						<ce:label>1.</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>J.G.</ce:given-name>
										<ce:surname>Root</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Optimal control of non-gaussian linear stochastic systems with inaccessible state variables</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>SIAM J. Control</sb:maintitle>
										</sb:title>
										<sb:volume-nr>7</sb:volume-nr>
									</sb:series>
									<sb:date>1969</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>317</sb:first-page>
									<sb:last-page>323</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="BIB2">
						<ce:label>2.</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>D.L.</ce:given-name>
										<ce:surname>Alspach</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>H.W.</ce:given-name>
										<ce:surname>Sorenson</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Stochastic optimal control for linear but non-gaussian systems</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>Int. J. Control</sb:maintitle>
										</sb:title>
										<sb:volume-nr>13</sb:volume-nr>
									</sb:series>
									<sb:date>1971</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>1169</sb:first-page>
									<sb:last-page>1181</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="BIB3">
						<ce:label>3.</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>H.S.</ce:given-name>
										<ce:surname>Witsenhausen</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Separation of estimation and control for discrete time system</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:edited-book>
									<sb:book-series>
										<sb:series>
											<sb:title>
												<sb:maintitle>Proc. IEEE</sb:maintitle>
											</sb:title>
											<sb:volume-nr>59</sb:volume-nr>
										</sb:series>
									</sb:book-series>
									<sb:date>1971</sb:date>
								</sb:edited-book>
								<sb:pages>
									<sb:first-page>1557</sb:first-page>
									<sb:last-page>1566</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="BIB4">
						<ce:label>4.</ce:label>
						<ce:other-ref>
							<ce:textref>L. E. Zachrisson, On a separation theorem for almost separated systems (to appear).</ce:textref>
						</ce:other-ref>
					</ce:bib-reference>
					<ce:bib-reference id="BIB5">
						<ce:label>5.</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>L.E.</ce:given-name>
										<ce:surname>Zachrisson</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>A proof of the separation theorem in control theory</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:edited-book>
									<sb:title>
										<sb:maintitle>IOS Report No. R 23</sb:maintitle>
									</sb:title>
									<sb:date>March 1968</sb:date>
									<sb:publisher>
										<sb:name>Royal Institute of Technology</sb:name>
										<sb:location>Stockholm</sb:location>
									</sb:publisher>
								</sb:edited-book>
							</sb:host>
							<sb:host>
								<sb:edited-book>
									<sb:title>
										<sb:maintitle>IOS Report No. R 23</sb:maintitle>
									</sb:title>
									<sb:date>March 1968</sb:date>
									<sb:publisher>
										<sb:name>Royal Institute of Technology</sb:name>
										<sb:location>Sweden</sb:location>
									</sb:publisher>
								</sb:edited-book>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="BIB6">
						<ce:label>6.</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>A.</ce:given-name>
										<ce:surname>Lindquist</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Optimal control of linear stochastic systems with applications to time lag systems</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>Information Sciences</sb:maintitle>
										</sb:title>
										<sb:volume-nr>4</sb:volume-nr>
									</sb:series>
									<sb:date>1972</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>81</sb:first-page>
									<sb:last-page>126</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="BIB7">
						<ce:label>7.</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>K.J.</ce:given-name>
										<ce:surname>Åström</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Introduction to Stochastic Control Theory</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:book>
									<sb:date>1970</sb:date>
									<sb:publisher>
										<sb:name>Academic Press</sb:name>
										<sb:location>New York-London</sb:location>
									</sb:publisher>
								</sb:book>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="BIB8">
						<ce:label>8.</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>H.</ce:given-name>
										<ce:surname>Kushner</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Introduction to Stochastic Control</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:book>
									<sb:date>1971</sb:date>
									<sb:publisher>
										<sb:name>Holt</sb:name>
										<sb:location>Rinehart and Winston</sb:location>
									</sb:publisher>
								</sb:book>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="BIB9">
						<ce:label>9.</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>M.</ce:given-name>
										<ce:surname>Aoki</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Optimization of Stochastic Systems</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:book>
									<sb:date>1967</sb:date>
									<sb:publisher>
										<sb:name>Academic Press</sb:name>
										<sb:location>New York-London</sb:location>
									</sb:publisher>
								</sb:book>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="BIB10">
						<ce:label>10.</ce:label>
						<ce:other-ref>
							<ce:textref>Å. Wernersson, On optimal estimation and prediction of “mixed processes” (tentative title, to appear).</ce:textref>
						</ce:other-ref>
					</ce:bib-reference>
					<ce:bib-reference id="BIB11">
						<ce:label>11.</ce:label>
						<ce:other-ref>
							<ce:textref>Å. Wernersson, On optimal stochastic control with incompletely known noise parameters (tentative title, to appear).</ce:textref>
						</ce:other-ref>
					</ce:bib-reference>
					<ce:bib-reference id="BIB12">
						<ce:label>12.</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>F.L.</ce:given-name>
										<ce:surname>Sims</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>D.G.</ce:given-name>
										<ce:surname>Lainiotis</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Recursive algorithm for the calculations of the adaptive Kalman filter weighting coefficients</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>IEEE Trans. Automatic Control</sb:maintitle>
										</sb:title>
										<sb:volume-nr>AC-14</sb:volume-nr>
									</sb:series>
									<sb:date>1969</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>215</sb:first-page>
									<sb:last-page>216</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="BIB13">
						<ce:label>13.</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>H.W.</ce:given-name>
										<ce:surname>Sorenson</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>D.L.</ce:given-name>
										<ce:surname>Alspach</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Recursive bayesian estimation using Gaussian sums</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>Automatica</sb:maintitle>
										</sb:title>
										<sb:volume-nr>7</sb:volume-nr>
									</sb:series>
									<sb:date>1971</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>465</sb:first-page>
									<sb:last-page>479</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="BIB14">
						<ce:label>14.</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>R.A.</ce:given-name>
										<ce:surname>Brooks</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Linear stochastic control; an extended separation principle</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>J. Math. Anal. and Appl.</sb:maintitle>
										</sb:title>
										<sb:volume-nr>38</sb:volume-nr>
									</sb:series>
									<sb:date>1972</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>569</sb:first-page>
									<sb:last-page>587</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="BIB15">
						<ce:label>15.</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>A</ce:given-name>
										<ce:surname>Lindquist</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>On feedback control of linear stochastic system</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>SIAM J. Control</sb:maintitle>
										</sb:title>
										<sb:volume-nr>11</sb:volume-nr>
									</sb:series>
									<sb:date>1973</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>323</sb:first-page>
									<sb:last-page>343</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="BIB16">
						<ce:label>16.</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>Å.</ce:given-name>
										<ce:surname>Wernersson</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>On pursuit and feedback in optimal stochastic control-explicit control laws</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:edited-book>
									<sb:book-series>
										<sb:series>
											<sb:title>
												<sb:maintitle>TRITA-MAT-1972-23</sb:maintitle>
											</sb:title>
										</sb:series>
									</sb:book-series>
									<sb:date>April 1972</sb:date>
									<sb:publisher>
										<sb:name>Royal Institute of Technology</sb:name>
										<sb:location>Stockholm, Sweden</sb:location>
									</sb:publisher>
								</sb:edited-book>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
				</ce:bibliography-sec>
			</ce:bibliography>
		</cja:tail>
	</cja:converted-article></doc:document>
