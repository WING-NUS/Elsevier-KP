<doc:document xmlns:doc="http://www.elsevier.com/xml/document/schema"><rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"><rdf:Description rdf:about="http://dx.doi.org/10.1016/0020-0255(74)90005-X"><dc:format xmlns:dc="http://purl.org/dc/elements/1.1/">application/xml</dc:format><dc:title xmlns:dc="http://purl.org/dc/elements/1.1/">Hierarchical structuring for system identification</dc:title><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/"><rdf:Seq><rdf:li>N.J. Smith</rdf:li><rdf:li>A.P. Sage</rdf:li></rdf:Seq></dc:creator><dc:description xmlns:dc="http://purl.org/dc/elements/1.1/">Information Sciences 7 (1974) 49-72. doi:10.1016/0020-0255(74)90005-X</dc:description><prism:aggregationType xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/">journal</prism:aggregationType><prism:publicationName xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/">Information Sciences</prism:publicationName><prism:copyright xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/">Copyright © unknown. Published by Elsevier Inc.</prism:copyright><dc:publisher xmlns:dc="http://purl.org/dc/elements/1.1/">Elsevier Inc.</dc:publisher><prism:issn xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/">0020-0255</prism:issn><prism:volume xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/">7</prism:volume><prism:coverDisplayDate xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/">1974</prism:coverDisplayDate><prism:coverDate xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/">1974</prism:coverDate><prism:pageRange xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/">49-72</prism:pageRange><prism:startingPage xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/">49</prism:startingPage><prism:endingPage xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/">72</prism:endingPage><prism:doi xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/">10.1016/0020-0255(74)90005-X</prism:doi><prism:url xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/">http://dx.doi.org/10.1016/0020-0255(74)90005-X</prism:url><dc:identifier xmlns:dc="http://purl.org/dc/elements/1.1/">doi:10.1016/0020-0255(74)90005-X</dc:identifier></rdf:Description></rdf:RDF><dp:document-properties xmlns:dp="http://www.elsevier.com/xml/common/doc-properties/schema"><dp:raw-text>INFORMA T10N SCIENCES 7,49-72 (1974) 49

Hierarchical Structuring for System Identification*

N. J. SMITH AND A. P. SAGE

Electrical Engineering Department,

SMV Institute of Technology, Dallas, Texas 57275

Communicated by D. G. Lainiotis

ABSTRACT

Hierarchical system theory deals with the decomposition of large or unwieldy systems
into smaller subsystems which are conceptually and computationally easier to manipulate.
System identification-the determination of unknown system parameters-is an area of sys-
tem theory in which hierarchical structuring may be particularly useful. For example, as
system identification techniques are applied to societal systems, the dimensionality of the
problem may become so large as to cause computational difficulties. For such problems,
hierarchical techniques may offer a significant reduction in computational requirements.

This research investigates hierarchical structuring for system identification. The max-
imum a posteriori (MAP) identification criterion yields a two point boundary value problem
(TPBVP) which is cast into a hierarchical structure. Two different methods-quasilinear-
ization and invariant imbedding-are used to solve the Subproblems which are then coor-
dinated to achieve the overall problem solution. Several examples are solved to demonstrate
the use of the developed algorithms.

1. INTRODUCTION

System Identification [1] the determination of unknown system parame-
ters-is currently being applied to a large and diverse class of systems. If these
systems have high dimensionality or have a natural hierarchical structure, there
may be advantages to the use of hierarchical system techniques in the identifica-
tion process.

This research addresses the problem of system identification using Hierarchi-
cal System Theory. Specifically, the equations associated with the identification
problem are decomposed into intimai problems which are coordinated using the
hierarchical theory. Two methods are presented for solving the intimai prob-
lemsinvariant imbedding and quasilinearization. Each of these is an excellent
method for solving a Two Point Boundary Value Problem (TPBVP). The result-
ing algorithms will be basically different, however; the quasilinearization solution

"This research was supported by the Air Force Office of Scientific Research under con-
tract F44620-68-C-0023 and the National Science Foundation under Grant GK 33348.

©American Eisevier Publishing Company, Inc., 1974

50                                          N. J. SMITH AND A. P. SAGE

is iterative, whereas the invariant imbedding solution is sequential. By compar-
ing these two approaches, we may gain more insight into the computational con-
straints imposed by the hierarchical structuring.

The outline of the research is as follows. Section 2 presents the deterministic
optimization problem which is equivalent to the stochastic identification prob-
lem. This is the result of using the maximum a posteriori (MAP) approach to
estimation. Section 3 discusses the solution to the resulting TPBVP via hierar-
chical structuring. Sections 4 and 5 present the incorporation of the invariant
imbedding and quasilinearization algorithms into the infimal identification
equations. An example is solved using both of the methods and the computa-
tional results are contained in Section 6. Some difficulties which may be en-
countered are discussed in Section 7 and some conclusions are drawn in
Section 8.

2. SYSTEM IDENTIFICATION VIA THE MAXIMUM
A POSTERIORI APPROACH

This section presents the maximum a posteriori (MAP) approach to system
identification and the associated two point boundary value problem (TPBVP).
The stochastic identification problem is essentially replaced by an equivalent
deterministic problem; the deterministic problem is then solved as an optimiza-
tion problem. This development is most easily carried out for a discrete time
system; the corresponding continuous-time results are then obtained by a limit-
ing argument. Since the development of this deterministic optimization problem
is well known [1-3], it will not be repeated here. The problem will be stated
and the results given for the discrete and continuous-time cases.

Consider the nth order non-linear discrete-time system

x(fc+ l)=&lt;!&gt;[x(k),k} +w(k)                  (2.1)
z(k)=h[x(k),k] +u(k)                  (2.2)
where

x(k)       is the n-dimensional state vector including parameters to be

identified.
&lt;p[x(k), k] is the «-dimensional vector-valued non-linear function which

describes the structure of the system and includes any known

inputs.

w(k)       is the «-dimensional plant noise vector.
z(k)        is the r-dimensional observation vector.
h [x(k), k] is the r-dimensional vector-valued non-linear function which

describes the relation between the system states and the

observations.
u(k)       is the r-dimensional measurement noise vector.

HIERARCHICAL STRUCTURING                                         51

The plant and measurement noises are assumed to be uncorrelated, zero mean,
white gaussian sequences with covariances

Cov M/), w(k)} = V^(k) OKU - k)              (2.3)
Cov {u(/), u(k)} = V^k) SKU - k),               (2.4)

where §^ is the Kronecker delta function. V^ has dimension n X n, Vy has di-
mension r X r and both are positive definite, symmetric covariance matrices.
The case where the plant and measurement noises are correlated or have un-
known moments is discussed in a later section.

Now let X(kf) and Z(kf) denote the sequences x (ko ),x(k^,.. . ,x(kf)md
z(k^},z(k'i},. . . ,z(kf). Then p [X(kf) \ Z(kf)\ represents the conditional prob-
ability density function of X (kf), given the observations Z(kf). The MAP esti-
mate ofx(k) over the interval [ko &lt; k &lt; kf\ is that estimate determined by
maximizing the density p[X(kf) \Z(kf)} with respect to (wrt} the sequence
X(kf). The well known result [1-3] of this procedure is that maximizing
p [X(kf) | Z(kf)} is equivalent to minimizing wrt w(k)

kf-l

yll^^-^oC-i^tS {\\z(k+l}-h[x(k+\\

L                 'x (KO)  - fc=fco

(/c+ l)] II2.!      + ||w(A;)||2 i   } (2.5)
\     " "^'(fc+i)   il v "^w'W

where k f is fixed, subject to the equality constraint

x(k + 1) = &lt;f&gt;[x(k}, k] + w(k),                  (2.1)
and where

z(k)=h[x(k),k] +v(k).                    (2.2)

This is the deterministic optimization problem which is equivalent to the sto-
chastic identification problem and is the desired result.

The corresponding continuous-time problem is obtained by taking the limit
as the samples become dense. That is, if we associate tic with sampling instant k
and let Tk = (tk - ffe-i), then as Tk -&gt;- 0, tk -&gt; t in the limit. We define

7[x(t),t] A Hm  {&lt;t&gt;[x(k),k] - x(k)}             (2.6)
7fc-»o Tk

h[x(t),t] A Um h[x(k),k]                  (2.7)

7fc-»0

Q(t) A lim TkV^{k)                   (2.8)
îfc^o

/?(f)A Um 7fcF(fc),                      (2.9)
T^O

52                                                 N. J. SMITH AND A. P. SAGE

with ticy -&gt; to and /fc,-&gt; ?y. The continuous time problem, then, is to minimize
wrt w(t)

^4Ko)-^o)|r^

^J/^ll^^^^'^lll-^o'll^ile-^r)^^ (210)

where t f is fixed, subject to the differential equation equality constraint ob-
tained from Eq. (2.1)

x(t)=T[x(t),t]+w(t).                    (2.11)
The continuous time observation equation is obtained from Eq. (2.2) as

z(t)=h[x(t),t]^u(t).                     (2.12)
The noise covariances are now

Cov{w(0,w(T)}=u(?)§oO-r)              (2.13)
Cov {u(t), u(t)} =R(t)6D(t- r),              (2.14)

where ÔD is the Dirac delta function.

We now use the Pontryagin Maximum Principle [2] to develop a TPBVP
whose solution will yield the MAP estimate ofx(t), denoted x(t). Define the
Hamiltonian

H[x(t), w(t), \(t), t] = \ \\z(f)- h[x(t), t] ll^.i^

+^llw(0|lç-l(,)+A'ró[7[^),?]+^)] (2.15)
The TPBVP, then, is given by

w=0=Q-l(t)w(t)-^A(t)                                      (2.16)
ow

so

î\H

^ =»(&gt;)= [î(t), t]-û(t)A(t)                                 (2.17)

- ^-^-^^W-^W..}} -^^AO,
ôx          9x(t)                           9x(t)

(2.18)

HIERARCHICAL STRUCTURING 53

with boundary conditions

(2.19)

A(^)=0.                       (2.20)

It is important to note that the solution to Eqs. (2.17) through (2.20) yields
the fixed interval smoothing solution for x(t), denoted x(t \ tf)', that is, the es-
timate ofx(t), ? [ty, tf\ is based upon the data contained in all of the obser-
vations z(/), t  [to, tf\. So the solution of the TPBVP must be performed off-
line after all of the observation data are available.

If the system dimension is large (say n &gt; 5) the TPBVP is computationally
difficult to solve. The TPBVP has dimension In, and this generally causes prob-
lems with numerical convergence and computer storage. We now apply the
hierarchical theory to this TPBVP in an attempt to lessen these difficulties.

3. SOLUTION TO THE TPBVP VIA HIERARCHICAL STRUCTURING

Hierarchical system theory may now be applied to the system identification
problem. The basic idea of the hierarchical theory is to decompose the original
problem into more easily solved Subproblems. These infimal problems are then
coordinated in such a way that their composite solution also solves the original
problem.

The first step is the decomposition of the integrated (original) «th order sys-
tem into TV subsystems each with dimension n

N

Z. ni=n
i=l

Model coordination parameters w,(f) are introduced into the subsystem equa-
tions to reflect coupling with other subsystems. The state equation for the ;'th
infimal unit then becomes.

Xi(t)=fi[x,(t), 7T,(0, t] + W,(t),                     (3.1)

where 7r,(?) represents the effects of the other infimal units upon infimal unit ;',
Correlated noises may cause difficulties in decomposing the cost functional since
Q(t) and R(t) may not be block diagonal [see Eq. (3.5)]. We now address this
problem briefly. Correlation between plant and measurement noises may be
handled by standard techniques [3, p. 280]. For plant noise correlation among
the subsystems, we may define a new noise input

w(t) = G(t) wi(t)

54
where

and

N. J. SMITH AND A. P. SAGE

G(t)G'(t)=Q(t)

(3.2)

Cov{wi(t),wi(T)}=Ko(t-T).
For measurement noise correlation, we define

ï(t)=A(f)z(t),

where A(t) is chosen so that A '(t) R-1 (t) A{t) is block diagonal [4, p. 296].
Thus we will assume that Q(t) and R(t) are block diagonal so that the perfor-
mance functional may be properly decomposed. Then 7r;(/) is a function only
of the other states, so that

(3.3)

Note that;c,(0 is the n,-dimensional vector of states associated with subsystem
i, not the ;'th component of the original state vector.

The performance functional for the integrated system, Eq. (2.10), may be de-
composed as follows. Let

7,4|k.(ro)-^,||^ +-

^ /Û       * ti

to

Qi

where

R=R'=

, Q=Q'=

ui

QN

(3.4)

(3.5)

so that

_   N _
/=^J,.

/=i

(3.6)

These infimal systems must now be coordinated in such a way that they solve
the overall identification problem. To accomplish this, we adjoin the intercon-
nection constraint, Eq. (3.3), to the Hamiltonian, Eq. (2.15) so that

(3.7)

HIERARCHICAL STRUCTURING                                            55

This yields

^'eUll^-^t^^ll'-l^llH'-ll-l^'.V.l^^^+H',)
;=1 [ -                   ";     '-       ^1

+ß;-(^-ftM|. (3.8)
Now if the system decomposition is carried out so that

Si(x,)=Zg(x,)                      (3.9)
i^i

and we note that

N         N                   N     N

£ ß', Z si,(x,)= E Z ß;^;)            (3.10)

;=!                    ^l'                                                      1=1         y^i'

then the ;th Hamiltonian may be written as
//,=1 |z,- h,[xt] ll'-i+^llH'fll'i+X',^,^,,^,?] +w,)

Z                                   K,          Z             ü,

+&lt;3^,- £0;^/,(^). (3.11)
i^i

Thus the optimization problem we formulate for the ;th infimal unit must have
Eq. (3.11) as its Hamiltonian. So the problem we pose for the /th infimal unit
is: minimize wrt Wi(r)

^4n^°)-^oii'^ ^UII^-M^II;^

z                     ^10   ^fo   I.                       '

+l||w,(0||2l +0;.7r,- f:0;^,(^-)l^ (3!2)

z         Yl            f-fc,          1

v'         l+i       }

subject to

Xi(t)=f,[xTTt] +W,(t)                      (3.13)

with

Zi(t)=h,[xt] +u;(0.                     (3.14)

Applying the maximum principle [2] yields

I^O^w.+A,
dH',

56
so

N. J. SMITH AND A. P. SAGE

W,=-Û,À,                         (3.15)

and
^=Xi=fi[xi,^,t}-Q,\,                                 (3.16)

 -,            -\ï ' r-^   ^i                                 -^-^r /\       -1.1          ^    -^

QHi      8/z, x,,?] _, r    , r- ,,-,  9/, [^ ^, n . +_°_ Vß'a..(y.)
-  = X, =  ^, {z, - /ï, [x /]} -  X, + -c 2. P/,?/iW

9x;        9x,                       9x,        óxi i^i

(3.17)
with

^(fo)=-^o^'&lt;f&lt;')-^-ol              &lt;3-18)
and

A,(^)=0.                        (3.19)

Equations (3.16) through (3.19) define the TPBVP that the tth infimal unit
must solve.

The infimal units must be coordinated so that they solve the overall identifi-
cation problem. This may be accomplished by using the Prediction Principle of
Mesarovic et al. [5]. Using the Prediction Principle, the supremal controller or
coordinator predicts a value for the model coordination variable v(t) and supplies
a value for the goal coordination variable ß(f}. The supremal then iterates ß(t)
and Ti(f) until a value is found for ß(t) which permits the correct prediction of
7i(f) so that the interconnection constraints are satisfied.

A realization of the Prediction Principle which has shown good convergence
properties is the equality method of Guinzy and Sage [6]. This method is de-
veloped by comparing the TPBVP for the coordinated and uncoordinated sys-
tems. For the uncoordinated system, the Hamiltonian is

//" =£ {ill2.- h,[xt]\\^ t^l^llo;1 +À'-(.[jc.'^(;c/)'r]+w.)}

(3.20)
Comparing the canonical equations for the two systems yields

^,(t)=g,[W                       (3-21)
and

f; ±- f i [x gf(x.), d ^ = - Z A- gji^i) ß,       (3.22)

i+i öxi                     f^i OX,

HIERARCHICAL STRUCTURING                                        57

for i~- 1, 2,.. . ,N. Thus, given explicit expressions for/and^, we may use past
values of x and À in Eqs. (3.21) and (3.22) to solve for new values of |3(f) and
ir(t).

Two methods for solving the infimal problemsinvariant imbedding and
quasilinearizationwill now be discussed and the infimal identification equa-
tions altered to incorporate these algorithms. As noted in Section 2, the solu-
tion of the TPBVP will yield the fixed interval smoothing estimate of x(t), and
this is the result we obtain using quasihnearization. The invariant imbedding
approach, however, leads to a sequential or filter solution because of the way
the solution is obtained.

The TPBVP and the proposed algorithms for its solution are for the con-
tinuous-time case. The TPBVP could have been defined as a discrete-time
problem as in [1] and discrete-time invariant imbedding and quasilinearization
algorithms [1-3] used for its solution. The results obtained would be equivalent
to those which will be obtained for the continuous-time case.

4. INVARIANT IMBEDDING IN HIERARCHICAL STRUCTURES

The name Two Point Boundary Value Problem and the difficulty involved
m its solution arise from the way its boundary conditions are specified. For
example, m a typical optimal control problem, the value ofx(to} and X(fy)
might be specified. The solution of the TPBVP, which is usually iterative, in-
volves a methodical search for a trajectory x(t) which starts at x(to) and an as-
sociated trajectory for \(t) which terminates at \(tf) and which satisfy the dif-
ferential equations comprising the TPBVP. The invariant imbedding approach
replaces this problem with another: that of determining additional boundary
conditions so that x(f} may be determined directly.

The basic idea of invariant imbedding is to replace a specific problem with a
more general one. Then once the general problem is solved, the solution of the
specific problem is also obtained. Surprisingly enough, it is often easier to ob-
tain the solution to the general problem than to the specific one.

We begin by imbedding X,(?y); that is, we let

\i(tf)=C,                              (4.1)

where C can take on any value including C = 0 and t f is now variable, rather than
fixed. Now assume that Xj{tf) can be expressed as a function of C and tf, say

x,(tf) = r(C, tf).                            (4.2)

Now, for convenience, let us represent the right side of Eqs. (3.16) and (3.17) by
T) and 7, respectively; that is

ri[r,C,tf]^f,[xTrt]-Q,\i                 (4.3)

58                                              N. J. SMITH AND A. P. SAGE

and

T[r, C, t,} A 9^ ^ {., - ,,[, ,]} - &lt;i|^ x, . - i ^.(.,).
9^,                          d^         9^/^,

(4.4)
Now following [1-3], a partial differential equation may be derived for r(C, tf)

9r(C, tf)   9r(C, tf)
^- + ^f- 7k. C, tf} = rJ[r, C, tf].             (4.5)

The solution of this equation yields the desired terminal condition x(tf). How-
ever, this is a non-linear, vector-matrix partial DE and a general solution is not
known. We will attempt to approximate the solution by

r(C,tf)=Xi(tf)-P.(tf)C.                   (4.6)

This substitution will lead to differential equations for x,(t) andP,(r) which will
yield the filter estimate ofx,(/). Substituting this approximation for r(C, tf)
into Eq. (4.5) yields

Xi(tf) - P,(tf) C + Pi(tf) y[Jc, - P,C, C, tf} =n[x, - P,C, C, tf]    (4.7)

Now since \j(tf) = 0.0, it is reasonable to assume that 17 and 7 can be expanded
m a Taylor series about C = 0. Retaining only terms up to first order in C and
replacing tf by the running time variable t, yields

x, - P,C+P,7[Jc 0, t] +4^ {-Y[x, - P.C, C, r]}ll    c

=r)[x,0,t]+\{r,[xi-P,C,C,t]}\\   C. (4.8)

L00                  J lc»o
Substituting for r? and 7 and equating like powers of C yields

î(t) =, [X TT,, t] +P, -8- f ß',g(Xi)

aXi ,^i

^,^/^^1{.,-MÎ.,0} (4.9)
Sx,

and

p tt\ - p ^'[^'7r..^ + y&gt; [^ ^. ^ p . p a f^(^. ^

^it.'} - ^i -^ + ^ ^i + fi -7~ -7:
àXi           Sx,           Sx, L 9^,

 Ri1 {z, - /!,(;? t)}}?, +P, -8- f^- f; ß;^(^,)'| P, + Qi. (4.10)
J       a^c, \,9xi i^i        J

HIERARCHICAL STRUCTURING                                         59

The initial conditions for these equations may be obtained from Eq. (3.18) as

^o)-^,o                       (4.11)

^o)=^,.                      (4-12)

Then once the supremal supplies ß and rr, the infimal units have well-defined
problems to solve. Even though it is not needed to solve for x,(t), A,(f) may
still have to be computed for use in updating (3 and TT. If this is the case, then
\i(t) is computed by integrating Eq. (3.17) backwards in time from A,(fy) = 0.0,
using the values of ;(;() just computed.

Thus, using invariant imbedding, a sequential solution procedure has been de-
veloped for the infimal problems. A summary of the algorithms for the ;'th
infimal unit is presented in Table 4.1.

TABLE 4.1
Hierarchical invariant imbedding identification algorithms for infimal Unit (

System model               Xj(t) = f, [x v t] + Wi(t)
Observation model           z,{t)= h,[x,, t] + u;(f)
Prior statistics               £'{^,Uo)} = ^,Q, Var {xi(to)} = Vxjo
E{w,(t)}=0=E{vi(t)}
Cov {wj(t}, Wj(T)} = Qj(t) &amp;o(t - T)
Cov {u;(0, U,(T)} =Ri(t) So(t - T)
Innovation                  z,(0 = z,(() - hj [Xj, t]
Definitions                  ß(t) and v(t) are coordination variables.

^.Wwl^ ^^î!h^tl

9x,(t)                9x{(t)

Futer algorithm               x;(/) = ; [x TT;, f] + /';(?) H',(t)R^(t) z,{t)

g f N           &gt;
-^(O-^ '^fij(t)Sji(Xi)\
^i l/^i          j

Error Variance algorithm      Pi(t) = /';(?) F,(r) + F,(t) Pi(t) + Qj(t)

+P,(t) -4- {H',(t) R]1 (t) Zi(t)}P,(t)
3x,

3 f 3 N          1
+PiW  1  Z ft'jWsji^i} \ P,(t)
Sx i [9Xi j^i         J

ax, [ax, 7,.
Initial conditions            Xj(to)=^^. , P,(to) = V^.

60                                             N. J. SMITH AND A. P. SAGE

The hierarchical invariant imbedding algorithms presented here are similar to
those developed by Guinzy and Sage [6]. Small differences arise because the
decomposition process was carried out in a slightly different manner in [6].
However, results using the two sets of algorithms were comparable.

5. QUASILINEARIZATION IN HIERARCHICAL STRUCTURES

The infimal TPBVP's may also be solved iteratively by using some appropri-
ate numerical method. This section discusses the incorporation of the quasi-
linearization (QL) [2] algorithms into the infimal problems.

In using the QL method, the boundary conditions and Hamiltonian minimi-
zation are satisfied and the solution is iterated until the canonical equations are
also satisfied. The basic idea of QL is as follows. Suppose, at the kth iteration,
x'[(t) and X^r) do not satisfy the canonical equations for the ;'th infimal unit,
that is

T?^,^]-;?(?) ^0                        (5.1)

and

vlx^X^t]- A^^O, (5.2)

where, as before, i? and y represent the right sides of the canonical equations,
Eqs. (3.16) and (3.17). We wish to choose

and

^(O^W+OJ^) (5.3)

^(^A^+ÔX,^), (5.4)

so that the new values of Jc,(r) and A,(f) satisfy the canonical equations; that is,
we wish to choose appropriate values oîSxfÇt) and SA,(?) so that

and

X'h+l,-,\     f-^k+l^k-^l.-î    rt                        fc r\

i W- -ï[Xi  ,\i ,t] =0.                (5.6)

Now substitute Eq. (5.3) and (5.4) into Eq. (5.5) to get

(x^ + Sx.) = ^ + 6x ^ + §A t]               (5.7)
and expand î] in a Taylor series about ^(x^, A,, t). This yields

J?fc+§^,=[;cXr]+.^-  0^+^- SXT+H.O.T.    (5.8)
9x, k      9A, fc

HIERARCHICAL STRUCTURING

61

If we drop H.O.T. then we obtain a set of equations that are linear in xk*\

and A^1

k fc

r "/t \ ft. .i ,
= T? [^; , À; , î] +

^

9x;

/ /^ ft. t-1      '" ft \   ,

(Xi   - Xi ) +

^
ax,

(A"1 - AÏ)

(5.9)

and similarly for A,

&lt;fe+i -

^_

9x,

\.k+

(/N n +1   /\ /t \ ,
X,    - Xi ) +

jh_

9À;

(A

fc+i

A;) (5.10)

These are the desired "quasilinearized" equations. Substituting for T] and 7
yields the desired results.

9/,

^fc+1    / r ^fc      i ,

^f    = f i [xi , îr t] +

ox;

//\fc+l      /^K\       ^/C+1

(x;  -^)-U,X;

(5.11)

.fc,i  ^-[^.f] _, r    , r fc n, ô  ^'.-  /-fc,
^  = -7^ R, {z, - h, [xi ,t]}+ -^ S ßigfi(xi )
ox,                       9x, ^i

. 9 r Sh'i [Xj, t]   i         ^fc

^ ^R' ^i~ hi^xi 't^

9x, L   ox,

9fi[Xi,TTt} ^    ^[Xi,TTt}'

^ A; - -

9x,

9x,

^fc+i
A;

(5.12)

So we make an initial guess for Jc,(?) and A((O and then iterate using Eqs. (5.11)
and (5.12) until the change between iterations is acceptably small.

The only difficulty remaining involves the boundary conditions. A,(^o) and
A,(fy) are specified, but since the equations are now coupled, we must integrate
both at once; hence, we need x,(to) if we are to integrate forward in time, or
Xj(tf), if we are to integrate backward from tf. Let us determine î,(?o) and in-
tegrate the equations forward in time from to. We proceed as follows:

(1) Integrate Eqs. (5.11) and (5.12) forward from to with
^'(^-^[^o)-^,,,]

and

(5.13)

(5.14)

Designate the value obtained for X;(fy) as \a and store.
(2) For each component of Jc,(f), integrate the homogeneous parts of Eqs.
(5.11) and (5.12) forward from to with that component set to 1.0 and
all other components of x,(to) set to zero, and with all the A,(fo) = 0.0.

62                                           N. J. SMITH AND A. P. SAGE

This is done «,. times, once for each component of Xj(to), and the values
of\i(tf) are designated Xi, \,2,. .., Xan, a"^ stored.

(3) Now since Eqs. (5.11) and (5.12) are linear m x^1 and X^'1'1, the
superposition principle holds so that

\i(tf) = 0.0 = \a + b, \ai +    + ^,^,        (5.15)

The values of A, may now be adjusted to yield the desired value of
\i(tf). That is

&amp;=[^l:^2::^,]l[0.0-X,].       (5.16)

(4) b is the desired value for^,(/o). The equations are integrated from /o
with

^^)=b

^Oo)-^^)-^,.,]             (5.17)
to obtain the trajectory for the (k + 1) iteration.

The procedure outlined above works only because the quasilinearized equations
are linear in x^1 and À^1. The non-homogeneous parts of these equations
consist of any terms which do not involve ^fe+1 and X^'1'1. The coordination
variables ß(t) and n(t) are treated as known forcing functions and, consequently,
are not a part of the homogeneous equations. A summary of the identification
algorithms for the ;th infimal unit is presented in Table 5.1.

Equations (5.11) and (5.12) are not as formidable as they appear. For sys-
tems that are "nearly linear," many terms will drop out when the partial deriva-
tives are taken. This is the case in the example which follows.

The QL method provides a convenient approach for solving the intimai iden-
tification TPBVP. The QL approach will be compared with the invariant
imbedding approach in the following example, which will be solved using each
method.

6. COMPUTATIONAL RESULTS

A simple example will now be solved to demonstrate the use of the invariant
imbedding and quasilinearization approaches to system identification in hierar-
chical structures. Consider the linear second order system

JCl =-diXi +JC2 + H'i
X-i =Xi - a^X-i +W-i

zi=xi+ui

Z-t =X-t +Ü2

HIERARCHICAL STRUCTURING

63

TABLE 5. l
Hierarchical quasilinearization identification algorithms for infimal Unit i'

System model                Xj(t) = ; [x,, îip t] + w,(f)
Observation model            z,(r) = /i, [x /] + v,(t)
Prior statistics                E {xj(to)} = ßx^ var {-^o)} = ^,g
/?{w;(r)}=0=f{u;(0}
Cov {M',(D, w;(r)} = ß;(r) 6o(f - r)
Cov {v,{t), v,(r)} = Ri(t) &amp;D(t - r)
Innovation                   z,(r) = z,(r) -/i/[5 f]
Definitions                   f3(t) and 7r(?) are coordination variables.

State estimation algorithm

Costate algorithm

ik-n

9fi{xvt]

a-î,U)

, //,0)-

Initial conditions

^,   = fi 1^, ^ 'I + W k (Xi   - x^ - Q, A;

t+i        I   -i -     \ 9   N         1 |
^ 1 =^W|^, ^^^ -- Z W^,)

L"!   /^1                   J I

9x,

\H\(t} R]' z,{t}-F\(t)\i

8    N              1

^Z^^
"i/^i      J

(x

fc+l  -k

,fc+l

^'(^-^[^Uo)-^]

-^i  (?o) =-[^all^aîl ' ' ' l^an,.]   ^a
where

\a = value of A((^) obtained from forced equations with
\i(to) set to its known value and all the Xj(to) = 0.0.

\ay = value of \j(tf) obtained from homogeneous equations
with A;(?o) = 0.0 and/th component ofJ(,(ro) set to
1.0, all other components of Xj(to) set to 0.0.

with

^(^-S.S, ^,(?o)=1.0
and

^(?o)=4.5, ^(/o)=1.0.

The parameters a^ and a^ are unknown and we wish to determine their respec-
tive values based upon the observations Zi and 22.

64                                               N. J. SMITH AND A. P. SAGE

We adjoin the unknown parameters as new states and introduce model co-
ordination values Tri and TT; to decompose the system into two infimal units:

Infimal Unit 1

Xu =-XitXii +7li +Wn

xn=Wi2

Zl =Xu +Ü1.

Infimal Unit 2

X2l ="2 - XitX-ti + W2i

X22 = w

Z2 =JC2i +Ü2.

The plant and measurement noises are assumed to be white, zero mean, gaussian
processes with

oi=

"un 0 1[1.0 O -

LO   012]  [o   1.0.

and

_[ö.i o -iri-o o -

Lu    022 J   LO   1.0.

Rt =R-t =0.01.

The parameters to be identified, ai andû2&gt; represented by x^ and^-22&gt; a1^ as-
sumed to be samples from a gaussian population with a mean of 2.0 and a vari-
ance of 1.0. This is not to imply that a\ and a^ are random. This is for con-
venience in making initial estimates and physically represents prior knowledge
of the approximate values offfi and a^.

The intimai cost functions for this example are given by Eq. (3.12)

JI =^^ll(^)-^,i(fo)]/ûll +-^[^12(?o)-A(xi2(?o)]/Û12

+ I   [^(zi-^i,)2^! +-Lwîl/ûn+lwÎ2/ûl2+ßl7rl -02^n1
^o L'              z         2                    J

dt

and

JI = \ [X2l(to) - ^,(?o)l /Ö21 + \ [x-tM - ^^O)] /Ö22

+     l(Z2-^2l)2/^2+lwil/ß21+lwj2/Û22+(32W2-ßl^21^^

To L"              z         L                    \

HIERARCHICAL STRUCTURING                                         65

The coordination variables were updated using the equality method [6] as given
by Eqs. (3.21) and (3.22)

^'(O^iO)
^'(O^i
ß^\t)=-\^(t)
^(t)=-\^(t}.
For the simulation, the actual values

^12(0 =fli =2.5

Xiî(t) =a-i = 1.5
x(/o)=6.0
^i(?o)=4.0

were used to generate the observations z i(Q andz^Q, ? [0, 5]. The initial
values for jS(t) were

0i(0=o.o=02(0.

To generate an initial trajectory for 7r(0, the system was simulated using the
mean values of a i, di, x 11 (0) and Xi i (0) with no noise. The initial guess for
7r(r) was then taken as

7Tl(0=^2l(0

^(O^iiró.

This is a reasonable choice for n(t), since it uses all the available information.
Choosing (3(0 = 0 means that the infimal units are initially uncoupled.

6.1 INVARIANT IMBEDDING (FILTERING) SOLUTION

For the invariant imbedding approach, the estimate x,(0 is given by Eqs.
(4.9) and (4.10).

Infimal Unit l

î\\ =-^12^11 +wi +pii(32 +pn(zi - Xn)lRi, xn(0)=5.5

Xi2 =Pi202 +Pn(.Zi - Xn)/Ri, ;&lt;-i2(0)=2.0

pn =-2xi2pn - 2J(npi2 -pÏilRi +ßn, pn(0)=1.0

Pl2 =-Pl2^12 - PlîXn - PllPllIRl, Pl2(0)=0.0
P22=-Pl2/^l +Û12, P22(0)=1.0

66

N. J. SMITH AND A. P. SAGE

Infimal Unit 2

X-ti =-Xi2X-ti +7:2 +Pußi +Pn(Z2 - Xti)lR-i, X2i(0)=4.5
X22=Pl2ßl +Pl2(Zî - X2i)IR2, ^22(0)= 2.0
Pll=-2XnPn - 2.X2lPi2 - PlllRl +021, Pll(0)= 1.0
Plî^ -Pl2^22 -P22^21 - Pl-tPll/Rï, Pl2(0)=0.0
P22=-PÎ2/^2+Û22, P22(0)=1.0

The pjj(t) represent the elements of the symmetrie matrix Pj(t) [see Eq. (4.10)]
and of course, are different for the two infimal units. Although not required for
estimating X((t), the costate variables An(0 and \2i(t) must be computed to
update ß(t). Equation (3.17) yields

^i =(zi - Xn)lRi +02+^1^2, ^n(5)=0.0

Â21 =(z-t - X2i)/^2 +01 +^21^22, W5)=0.0

Figure 6.1 presents the results of the invariant imbedding identification. Fig-
ure 6.2 shows the effects of increasing the noise variances for the parameters to
be identified to Qn = 022 = 4.0. For the higher noise variance case, the identi-
fication time is improved as is the overall quality of the estimate.

Rather than initializing the parameters to be identified to their mean values
at each iteration, they could be initialized at the final value they attained on the

True Value
ofai

2.50

2.25-

2.00

1.75-

1.50




True Value
of ay

Fig. 6.1. Invariant imbedding identification ofûi and a-i with Q^ = 1.0 = 022-

HIERARCHICAL STRUCTURING

2.50

2.25

2.00

1.75

1.50

True Value
of ai




Fig. 6.2. Invariant imbedding identification of ui anda^ with Q^^ = 4.0 = 022-

previous iteration. This corresponds to having the supremal controller supply
these initial conditions as well as the coordination variables to the infimal units.
The results for this case are presented in Fig. 6.3 for Qn = Q^ = 1.0 and Fig.
6.4 for 0,2 =022 =4.0.

The best estimate seems to be that obtained by reinitializing the parameter
equations and choosing the higher value for the identification parameter vari-
ances, as shown in Fig. 6.4. It is important to note that the process cannot be
carried out in real time since the coordination procedure is iterative.

6.2 QUASILINEARIZATION (SMOOTHING) SOLUTION

For the quasilinearization approach the estimate of x, (?) is given by
Eqs. (5.11) and (5.12).

Infimal Unit 1

^fc+l    ^k ^fc+l   ^k ^k+l   ,-. -fc+l , rr,   , "k ^k -,
Xu =-Xi2Xn -XnXi2 -ßnAll +H(ïïi+XitXi-i)

^fc+1 _ _f) \lc-n
Xlî - Ç/12A-12

fc+1 _ ^fc+l/n ,\k ^fc+l  cfc ^fc+l
"11 - -ïn IK\ '^n-'1^ '-'^u'Mi

+H(z,IR, +ß2 - ^AÏ,), X^O^O)- 5.5)
X^1 = ^i^i" + ^i ^l - H{x^ ÂÏJ, Xt2+l(0)= -(x^O) - 2.0)

68

N. J. SMITH AND A. P. SAGE

2.50

2.25-

2.00

1.75

1.50




True Value
of ao

Fig. 6.3. Invariant imbedding identification ofai and a^ with Q^ = 1.0 = 022. and with
reinitialization of parameter equations.

2.50

2.25

2.00

1.75-

1.50

True Value
ol ay




True Value
ofai

Fig. 6.4. Invariant imbedding identification ofai and 02 with Qii= 4.0 = Û22&gt; 'ird with
reinitialization of parameter equations.

HIERARCHICAL STRUCTURING

Infimal Unit 2

^k ^fc+i  ^fc ^fc+i   ^ ..fc+l i u/^k ^k ,   \
-XftX-n - X-nX-iî -022^21 +"0f21^22+ÎT2)

Çfc+1 -

^21 -

^fc+l - n \k&lt;'

xî^ ~ Uil ^lî

fe+l _ ^fc+l / , \k ^fc+i  ^fc -fc+l

^21   ~~~x^\ lt&lt;2 ' ^21 X-lî  T-)r22'^21

+H(z,lR, +(3i - x^i), X^l(0)=-(^l(0)- 4.5)
X22'1 -X^^+^Â^1-^^^,!), X^(0)=-(^(0)-2.0).

In these equations, H is set to 0 or 1 to obtain either the homogeneous or the
forced equations and Jc,^"1'1 (0) is determined as outlined in Section 5. The co-
state variables An(0 and \2i(0 are available for updating (3(0 and need not be
computed separately, as was the case for the invariant imbedding approach.

The infimal solutions via QL are iterative. The initial trajectory was chosen
by using the mean values ofûi and a-i, integrating the state equations forward
from HxW aKd integrating the costate equations backward from X(5) = 0.0.

The stopping rule used for the QL procedure requires the first variation in
Jj to be small and is given by

A./,

f1

-%

x^dt &lt;e

True Value
of ai




K°7

of a-)

Fig. 6.5. Quasilinearization identification ofai and a^ with Qii = 1.0 = Û22-

70                                                N. J. SMITH AND A. P. SAGE

The results of the quasilinearization identification are presented in Fig. 6.5.
These results compare favorably with the best case (Fig. 6.4) using invariant
imbedding.

7. SOME DIFFICULTIES AND EXTENSIONS

Several assumptions were made in the development presented here which may
not be valid for some practical problems. Probably the most significant of these
is the assumption that the noises are zero mean with known variances. We now
consider briefly the extension of the identification algorithms to include the
case where the noise moments are unknown.

Consider first the case in which the mean values of the noises are unknown.
This is equivalent to having unknown biases in the system and can result in
significant errors in the identification process. Sage and Lin [7] treat this prob-
lem using a maximum likelihood approach to determine the estimator gain di-
rectly and also include an associated error analysis. Sage and Husa [8] present
algorithms for adaptively identifying the noise mean values. These results can
be easily adapted to hierarchical systems.

A much more difficult problem arises when the noise covariances are un-
known, since their effects are not directly measurable. In this case, the use of
an adaptive estimator seems to be the best approach [1,9]. Sage and Husa [8]
also treat this problem, although their algorithms work best for unknown mea-
surement noise moments. Sage and Wakefield [10] use a maximum likelihood
approach to determine the estimator gain directly for the case with unknown
plant noise covariances. Also, it is possible to develop a probability density for
the covariance of the innovations process and use this to obtain the a posteriori
density of the estimator gain. Again, these results may be easily adapted for use
in hierarchical systems. Of course, any of these approaches will add complexity
to the identification process.

Difficulties may also arise because of what is known as the "model mismatch"
problem. In the example of Section 6, it was assumed that the model structure
was known exactly and that parameters within this structure were to be deter-
mined. This is not always the situation. In some cases, the exact system struc-
ture may simply not be known. In other cases, the structure is known but it is
desirable to approximate the actual system by a lower order model. If the
model and the actual system are dissimilar enough, the identification process
may break down completely. An example demonstrating this difficulty is dis-
cussed in [9]. Suppose the system we wish to model responds to a step input
with a damped oscillatory output. Further suppose that we propose to represent
the actual system by a first-order model and attempt to identify the correct time
constant, T, for our model. We would find, of course, that there was no value of
7- which caused our model to behave like the actual system. This simple example

HIERARCHICAL STRUCTURING                                         71

illustrates the difficulties which may arise by, either intentionally or uninten-
tionally, using an incorrect model. If the mismatch is great enough, it may ac-
tually cause the identification process to diverge.

The solution to the model mismatch problem is generally to find a more ac-
curate model structure. This usually means changing to a model of higher order.
A technique which may prevent divergence of the estimator is to adjoin the un-
known (constant) parameters asp = w, where w is white noise, rather than as
p = 0. This technique was used successfully in the example in Section 6. The
white noise w is usually chosen to have zero mean, but the variance may be set
at whatever value seems convenient. It was noted in the example that changing
this parameter noise variance changed the quality of the parameter estimate. In
a realistic problem, manipulation of this variance might be very useful and an
adaptive, or even optimal, technique for its selection might be found.

8. SUMMARY AND CONCLUSIONS

The maximum a posteriori (MAP) approach to identification has been pre-
sented and developed for hierarchical systems. The resulting Two Point Bound-
ary Value Problem (TPBVP) has been solved by two methods-quasilinearization
and invariant imbedding. The invariant imbedding approach yields the filter es-
timate, while the quasilinearization method gives the fixed interval smoothing
estimate of the states and parameters to be identified. The Prediction Principle
[5] with equality updating [6] was used to coordinate the infimal identification
processes because of its rapid convergence properties. Extensions to the case
with unknown noise moments were discussed.

Several simple examples were presented to demonstrate the algorithms. The
results obtained from the two methods were comparable, as may be seen from
Figs. 6.4 and 6.5. The quasilinearization identification results were slightly bet-
ter, but required more computation time. The QL approach required l min
10 sec on the Univac 1108, whereas the invariant imbedding method required
20 sec. In addition, the QL method required four times as much storage and was
more sensitive to computation step size. Thus, unless the amount of observation
data is limited, the invariant imbedding approach seems preferable.

9. REFERENCES

1. A. P. Sage and J. L. Melsa, System Identification, Academic Press, New York (1971).

2. A. P. Sage, Optimum Systems Control, Prentice Hall, Englewood Cliffs, N.Y. (1968).

3. A. P. Sage and J. L. Melsa, Estimation Theory with Applications to Communications
and Control, McGraw-HiU, New York (1971).

4. K. R. Gantmacher, The Theory of Matrices, l, Chelsea, New York (1959).

5. M. D. Mesarovic, D. Macko, and Y. Takahara, Theory of Hierarchical Multilevel Sys-
tems, Academie Press, New York (1970).

72                                          N. J. SMITH AND A. P. SAGE

6. N. J. Guinzy and A. P. Sage, System identification in large scale systems with hier-
archical structures. Computers Elec. Eng. l, 23-42 (1973).

7. A. P. Sage and J. L. Lin, Algorithms for continuous sequential maximum likelihood bias
estimation and associated error analysis, Information Sciences 3, 291-313 (October
1971).

8. A. P. Sage and G. W. Husa, Adaptive filtering with unknown prior statistics, Proc.
JACC, 760-769 (1969).

9. A. P. Sage, System identification: history, methodology, future prospects, Proc. 7972
ASME Sym. on System Identification m Shock and Vibration Systems (1972),
pp. 1-22.

10. A. P. Sage and C. D. Wakefield, Maximum likelihood identification of time varying and
random system parameters. Int. J. of Control 16, 1, 81-100 (July 1972).

Received December 22, 19 72</dp:raw-text><dp:aggregation-type>Journals</dp:aggregation-type><dp:version-number>S350.1</dp:version-number></dp:document-properties><cja:converted-article version="4.5.2" docsubtype="fla" xml:lang="en" xmlns:cja="http://www.elsevier.com/xml/cja/schema">
		<cja:item-info>
			<cja:jid>INS</cja:jid>
			<cja:aid>7490005X</cja:aid>
			<ce:pii xmlns:ce="http://www.elsevier.com/xml/common/schema">0020-0255(74)90005-X</ce:pii>
			<ce:doi xmlns:ce="http://www.elsevier.com/xml/common/schema">10.1016/0020-0255(74)90005-X</ce:doi>
			<ce:copyright type="unknown" year="1974" xmlns:ce="http://www.elsevier.com/xml/common/schema"/>
		</cja:item-info>
		<cja:head>
			<ce:article-footnote xmlns:ce="http://www.elsevier.com/xml/common/schema">
				<ce:label>☆</ce:label>
				<ce:note-para>This research was supported by the Air Force Office of Scientific Research under contract F44620-68-C-0023 and the National Science Foundation under Grant GK 33348.</ce:note-para>
			</ce:article-footnote>
			<ce:title xmlns:ce="http://www.elsevier.com/xml/common/schema">Hierarchical structuring for system identification</ce:title>
			<ce:author-group xmlns:ce="http://www.elsevier.com/xml/common/schema">
				<ce:author>
					<ce:given-name>N.J.</ce:given-name>
					<ce:surname>Smith</ce:surname>
				</ce:author>
				<ce:author>
					<ce:given-name>A.P.</ce:given-name>
					<ce:surname>Sage</ce:surname>
				</ce:author>
				<ce:affiliation>
					<ce:textfn>Electrical Engineering Department, SMU Institute of Technology, Dallas, Texas 57275 USA</ce:textfn>
				</ce:affiliation>
			</ce:author-group>
			<ce:date-received day="22" month="12" year="1972" xmlns:ce="http://www.elsevier.com/xml/common/schema"/>
			<ce:miscellaneous xmlns:ce="http://www.elsevier.com/xml/common/schema">Communicated by D.G. Lainiotis</ce:miscellaneous>
			<ce:abstract class="author" xmlns:ce="http://www.elsevier.com/xml/common/schema">
				<ce:section-title>Abstract</ce:section-title>
				<ce:abstract-sec>
					<ce:simple-para view="all">Hierarchical system theory deals with the decomposition of large or unwieldy systems into smaller subsystems which are conceptually and computationally easier to manipulate. System identification-the determination of unknown system parameters-is an area of system theory in which hierarchical structuring may be particularly useful. For example, as system identification techniques are applied to societal systems, the dimensionality of the problem may become so large as to cause computational difficulties. For such problems, hierarchical techniques may offer a significant reduction in computational requirements.</ce:simple-para>
					<ce:simple-para view="all">This research investigates hierarchical structuring for system identification. The maximum 
						<ce:italic>a posteriori</ce:italic> (MAP) identification criterion yields a two point boundary value problem (TPBVP) which is cast into a hierarchical structure. Two different methods-quasilinearization and invariant imbedding-are used to solve the subproblems which are then coordinated to achieve the overall problem solution. Several examples are solved to demonstrate the use of the developed algorithms.
					</ce:simple-para>
				</ce:abstract-sec>
			</ce:abstract>
		</cja:head>
		<cja:tail>
			<ce:bibliography view="all" xmlns:ce="http://www.elsevier.com/xml/common/schema">
				<ce:section-title>References</ce:section-title>
				<ce:bibliography-sec>
					<ce:bib-reference id="BIB1">
						<ce:label>1.</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>A.P.</ce:given-name>
										<ce:surname>Sage</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>J.L.</ce:given-name>
										<ce:surname>Melsa</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>System Identification</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:book>
									<sb:date>1971</sb:date>
									<sb:publisher>
										<sb:name>Academic Press</sb:name>
										<sb:location>New York</sb:location>
									</sb:publisher>
								</sb:book>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="BIB2">
						<ce:label>2.</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>A.P.</ce:given-name>
										<ce:surname>Sage</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Optimum Systems Control</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:book>
									<sb:date>1968</sb:date>
									<sb:publisher>
										<sb:name>Prentice Hall</sb:name>
										<sb:location>Englewood Cliffs, N.Y</sb:location>
									</sb:publisher>
								</sb:book>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="BIB3">
						<ce:label>3.</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>A.P.</ce:given-name>
										<ce:surname>Sage</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>J.L.</ce:given-name>
										<ce:surname>Melsa</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Estimation Theory with Applications to Communications and Control</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:book>
									<sb:date>1971</sb:date>
									<sb:publisher>
										<sb:name>McGraw-Hill</sb:name>
										<sb:location>New York</sb:location>
									</sb:publisher>
								</sb:book>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="BIB4">
						<ce:label>4.</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>F.R.</ce:given-name>
										<ce:surname>Gantmacher</ce:surname>
									</sb:author>
								</sb:authors>
							</sb:contribution>
							<sb:host>
								<sb:edited-book>
									<sb:book-series>
										<sb:series>
											<sb:title>
												<sb:maintitle>The Theory of Matrices</sb:maintitle>
											</sb:title>
											<sb:volume-nr>1</sb:volume-nr>
										</sb:series>
									</sb:book-series>
									<sb:date>1959</sb:date>
									<sb:publisher>
										<sb:name>Chelsea</sb:name>
										<sb:location>New York</sb:location>
									</sb:publisher>
								</sb:edited-book>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="BIB5">
						<ce:label>5.</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>M.D.</ce:given-name>
										<ce:surname>Mesarovic</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>D.</ce:given-name>
										<ce:surname>Macko</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>Y.</ce:given-name>
										<ce:surname>Takahara</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Theory of Hierarchical Multilevel Systems</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:book>
									<sb:date>1970</sb:date>
									<sb:publisher>
										<sb:name>Academic Press</sb:name>
										<sb:location>New York</sb:location>
									</sb:publisher>
								</sb:book>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="BIB6">
						<ce:label>6.</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>N.J.</ce:given-name>
										<ce:surname>Guinzy</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>A.P.</ce:given-name>
										<ce:surname>Sage</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>System identification in large scale systems with hierarchical structures</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>Computers Elec. Eng.</sb:maintitle>
										</sb:title>
										<sb:volume-nr>1</sb:volume-nr>
									</sb:series>
									<sb:date>1973</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>23</sb:first-page>
									<sb:last-page>42</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="BIB7">
						<ce:label>7.</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>A.P.</ce:given-name>
										<ce:surname>Sage</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>J.L.</ce:given-name>
										<ce:surname>Lin</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Algorithms for continuous sequential maximum likelihood bias estimation and associated error analysis</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>Information Sciences</sb:maintitle>
										</sb:title>
										<sb:volume-nr>3</sb:volume-nr>
									</sb:series>
									<sb:date>October 1971</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>291</sb:first-page>
									<sb:last-page>313</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="BIB8">
						<ce:label>8.</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>A.P.</ce:given-name>
										<ce:surname>Sage</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>G.W.</ce:given-name>
										<ce:surname>Husa</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Adaptive filtering with unknown prior statistics</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:edited-book>
									<sb:title>
										<sb:maintitle>Proc. JACC</sb:maintitle>
									</sb:title>
									<sb:date>1969</sb:date>
								</sb:edited-book>
								<sb:pages>
									<sb:first-page>760</sb:first-page>
									<sb:last-page>769</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="BIB9">
						<ce:label>9.</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>A.P.</ce:given-name>
										<ce:surname>Sage</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>System identification: history, methodology, future prospects</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:edited-book>
									<sb:title>
										<sb:maintitle>Proc. 1972 ASME Sym. on System Identification in Shock and Vibration Systems</sb:maintitle>
									</sb:title>
									<sb:date>1972</sb:date>
								</sb:edited-book>
								<sb:pages>
									<sb:first-page>1</sb:first-page>
									<sb:last-page>22</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="BIB10">
						<ce:label>10.</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>A.P.</ce:given-name>
										<ce:surname>Sage</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>C.D.</ce:given-name>
										<ce:surname>Wakefield</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Maximum likelihood identification of time varying and random system parameters</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>Int. J. of Control</sb:maintitle>
										</sb:title>
										<sb:volume-nr>16</sb:volume-nr>
									</sb:series>
									<sb:issue-nr>1</sb:issue-nr>
									<sb:date>July 1972</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>81</sb:first-page>
									<sb:last-page>100</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
				</ce:bibliography-sec>
			</ce:bibliography>
		</cja:tail>
	</cja:converted-article></doc:document>
