<doc:document xmlns:doc="http://www.elsevier.com/xml/document/schema"><rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"><rdf:Description rdf:about="http://dx.doi.org/10.1016/j.ins.2011.04.001"><dc:format xmlns:dc="http://purl.org/dc/elements/1.1/">application/xml</dc:format><dc:title xmlns:dc="http://purl.org/dc/elements/1.1/">Nonlinear dimensionality reduction using a temporal coherence principle</dc:title><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/"><rdf:Seq><rdf:li>YaPing Huang</rdf:li><rdf:li>JiaLi Zhao</rdf:li><rdf:li>YunHui Liu</rdf:li><rdf:li>SiWei Luo</rdf:li><rdf:li>Qi Zou</rdf:li><rdf:li>Mei Tian</rdf:li></rdf:Seq></dc:creator><dc:subject xmlns:dc="http://purl.org/dc/elements/1.1/"><rdf:Bag><rdf:li>Dimensionality reduction</rdf:li><rdf:li>Feature extraction</rdf:li><rdf:li>Temporal coherence principle</rdf:li><rdf:li>Temporal slowness principle</rdf:li><rdf:li>Manifold learning</rdf:li><rdf:li>Pattern classification</rdf:li><rdf:li>Character recognition</rdf:li></rdf:Bag></dc:subject><dc:description xmlns:dc="http://purl.org/dc/elements/1.1/">Information Sciences 181 (2011) 3284-3307. doi:10.1016/j.ins.2011.04.001</dc:description><prism:aggregationType xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/">journal</prism:aggregationType><prism:publicationName xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/">Information Sciences</prism:publicationName><prism:copyright xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/">Copyright © 2011 Elsevier Inc. All rights reserved.</prism:copyright><dc:publisher xmlns:dc="http://purl.org/dc/elements/1.1/">Elsevier Inc.</dc:publisher><prism:issn xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/">0020-0255</prism:issn><prism:volume xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/">181</prism:volume><prism:number xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/">16</prism:number><prism:coverDisplayDate xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/">2011</prism:coverDisplayDate><prism:coverDate xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/">2011</prism:coverDate><prism:pageRange xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/">3284-3307</prism:pageRange><prism:startingPage xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/">3284</prism:startingPage><prism:endingPage xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/">3307</prism:endingPage><prism:doi xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/">10.1016/j.ins.2011.04.001</prism:doi><prism:url xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/">http://dx.doi.org/10.1016/j.ins.2011.04.001</prism:url><dc:identifier xmlns:dc="http://purl.org/dc/elements/1.1/">doi:10.1016/j.ins.2011.04.001</dc:identifier></rdf:Description></rdf:RDF><dp:document-properties xmlns:dp="http://www.elsevier.com/xml/common/doc-properties/schema"><dp:aggregation-type>Journals</dp:aggregation-type><dp:version-number>S300.1</dp:version-number></dp:document-properties><ja:article docsubtype="fla" xml:lang="en" version="5.1" xmlns:ja="http://www.elsevier.com/xml/ja/schema">
		<ja:item-info>
			<ja:jid>INS</ja:jid>
			<ja:aid>9052</ja:aid>
			<ce:pii xmlns:ce="http://www.elsevier.com/xml/common/schema">S0020-0255(11)00169-1</ce:pii>
			<ce:doi xmlns:ce="http://www.elsevier.com/xml/common/schema">10.1016/j.ins.2011.04.001</ce:doi>
			<ce:copyright type="full-transfer" year="2011" xmlns:ce="http://www.elsevier.com/xml/common/schema">Elsevier Inc.</ce:copyright>
		</ja:item-info>
		<ce:floats xmlns:ce="http://www.elsevier.com/xml/common/schema">
			<ce:figure id="f0005">
				<ce:label>Fig. 1</ce:label>
				<ce:caption>
					<ce:simple-para id="sp015" view="all">Example duck images from the COIL-100 database.</ce:simple-para>
				</ce:caption>
				<ce:link locator="gr1"/>
			</ce:figure>
			<ce:figure id="f0010">
				<ce:label>Fig. 2</ce:label>
				<ce:caption>
					<ce:simple-para id="sp020" view="all">Two image sequences generated from the COIL-100 database are mapped into a two-dimensional space using NNP-1: (a) the mapping results on the first image sequence which includes a duck object; (b) the mapping results on the second image sequence which includes two objects. We see in (a) and (b) that the embedded manifold (one circle corresponds to one object) can be obtained successfully.</ce:simple-para>
				</ce:caption>
				<ce:link locator="gr2"/>
			</ce:figure>
			<ce:figure id="f0015">
				<ce:label>Fig. 3</ce:label>
				<ce:caption>
					<ce:simple-para id="sp025" view="all">The Vista analog clock image sequence is mapped into a two-dimensional space using NNP-1. It is clear that the second hand is moving in the clock images, and that the first frame and the last frame are very similar. Therefore, the embedded manifold is not a complete circle. Obviously, if the last frame were the same as the first one, the mapping representations would also be a circle.</ce:simple-para>
				</ce:caption>
				<ce:link locator="gr3"/>
			</ce:figure>
			<ce:figure id="f0020">
				<ce:label>Fig. 4</ce:label>
				<ce:caption>
					<ce:simple-para id="sp030" view="all">The two-dimensional representations of the face image sequence using NNP-1. From the results, we see that the face images are clearly divided into two clusters: The left cluster includes the faces with an open mouth, and the right cluster are the faces with a closed mouth.</ce:simple-para>
				</ce:caption>
				<ce:link locator="gr4"/>
			</ce:figure>
			<ce:figure id="f0025">
				<ce:label>Fig. 5</ce:label>
				<ce:caption>
					<ce:simple-para id="sp035" view="all">The two-dimensional representations of synthetic image data sets.</ce:simple-para>
				</ce:caption>
				<ce:link locator="gr5ac"/>
				<ce:link locator="gr5df"/>
				<ce:link locator="gr5gi"/>
				<ce:link locator="gr5j"/>
			</ce:figure>
			<ce:figure id="f0030">
				<ce:label>Fig. 6</ce:label>
				<ce:caption>
					<ce:simple-para id="sp040" view="all">The “Gaussian randomly sampled” is mapped into a two-dimensional space. The left figure is the original data points. The middle figure shows the results using NNP-2. The right figure shows the results using NNP-3.</ce:simple-para>
				</ce:caption>
				<ce:link locator="gr6"/>
			</ce:figure>
			<ce:figure id="f0035">
				<ce:label>Fig. 7</ce:label>
				<ce:caption>
					<ce:simple-para id="sp045" view="all">Experimental results on some sparse data sets: (a) the mapping results on Toroidal helix with 
						<ce:italic>sample rate</ce:italic>
						<ce:hsp sp="0.25"/>=
						<ce:hsp sp="0.25"/>0.8; (b) the mapping results on Swiss roll when only 400 points are sampled from the original data space; (c) the results on S curve when only 200 points are sampled from the original data space.
					</ce:simple-para>
				</ce:caption>
				<ce:link locator="gr7"/>
			</ce:figure>
			<ce:figure id="f0040">
				<ce:label>Fig. 8</ce:label>
				<ce:caption>
					<ce:simple-para id="sp050" view="all">Comparison between NNP-2 and NNP-3 on duck images: (a) the mapping results using NNP-2; (b) the mapping results using NNP-3.</ce:simple-para>
				</ce:caption>
				<ce:link locator="gr8"/>
			</ce:figure>
			<ce:figure id="f0045">
				<ce:label>Fig. 9</ce:label>
				<ce:caption>
					<ce:simple-para id="sp055" view="all">The duck images are mapped into a two-dimensional space using Isomap, LLE, Hessian LLE, Laplacian, Diffusion Map, LTSA, and NNP-2.</ce:simple-para>
				</ce:caption>
				<ce:link locator="gr9"/>
			</ce:figure>
			<ce:figure id="f0050">
				<ce:label>Fig. 10</ce:label>
				<ce:caption>
					<ce:simple-para id="sp060" view="all">The two-dimensional representations of face images: (a) the mapping results on the data set #1 
						<ce:cross-ref refid="b0220">[44]</ce:cross-ref>; (b) the mapping results on the face image data set #2 
						<ce:cross-ref refid="b0175">[35]</ce:cross-ref>; (c) the mapping results on the data set #3, which is selected randomly from the data set #2. Obviously, in (a), the pose of each face changes smoothly from left to right, and the view angle alters gradually from bottom to top. In addition, in (b) and (c), we see that the NNP-2 algorithm can successfully divide the original face images into two separated clusters: One corresponds to the faces with a closed mouth, and the other corresponds to the faces with an open mouth.
					</ce:simple-para>
				</ce:caption>
				<ce:link locator="gr10"/>
			</ce:figure>
			<ce:figure id="f0055">
				<ce:label>Fig. 11</ce:label>
				<ce:caption>
					<ce:simple-para id="sp065" view="all">Recognition rates for experiments performed with polynomials of second degree (input dimensions from 10 to 75) and third degree (input dimensions from 10 to 35). The best performance 98.58% is achieved with a polynomial of third degree and 35 input dimensions.</ce:simple-para>
				</ce:caption>
				<ce:link locator="gr11"/>
			</ce:figure>
			<ce:figure id="f0060">
				<ce:label>Fig. 12</ce:label>
				<ce:caption>
					<ce:simple-para id="sp070" view="all">Schematic comparison of the SFA with the NNP framework. Take the COIL-100 duck object as an example, we apply NNP-1 to the duck image sequence. Meanwhile, we apply NNP-2 and NNP-3 to the duck images. From the results, we see that NNP-1 and NNP-2 can obtain a good mapping result when dealing with uniform sampling duck images, in contrast, the results of NNP-3 are not satisfying. This is because NNP-3 is suitable for non-uniform data set.</ce:simple-para>
				</ce:caption>
				<ce:link locator="gr12"/>
			</ce:figure>
			<ce:table frame="topbot" id="t0005" rowsep="0" colsep="0">
				<ce:label>Table 1</ce:label>
				<ce:caption>
					<ce:simple-para id="sp075" view="all">Summary of experiments.</ce:simple-para>
				</ce:caption>
				<cals:tgroup cols="6" xmlns:cals="http://www.elsevier.com/xml/common/cals/schema">
					<cals:colspec colname="col1" align="left"/>
					<cals:colspec colname="col2" align="left"/>
					<cals:colspec colname="col3" align="left"/>
					<cals:colspec colname="col4" align="left"/>
					<cals:colspec colname="col5" align="left"/>
					<cals:colspec colname="col6" align="left"/>
					<cals:thead>
						<cals:row rowsep="1" valign="top">
							<ce:entry>Tasks</ce:entry>
							<ce:entry namest="col2" nameend="col4">Data set</ce:entry>
							<ce:entry>Algorithm</ce:entry>
							<ce:entry>Results</ce:entry>
						</cals:row>
					</cals:thead>
					<cals:tbody>
						<cals:row valign="top">
							<ce:entry morerows="13">Visualization</ce:entry>
							<ce:entry morerows="2">Image sequence</ce:entry>
							<ce:entry namest="col3" nameend="col4">COIL-100</ce:entry>
							<ce:entry>NNP-1</ce:entry>
							<ce:entry>
								<ce:cross-ref refid="f0010">Fig. 2</ce:cross-ref>
							</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry namest="col3" nameend="col4">Vista analog clock</ce:entry>
							<ce:entry>NNP-1</ce:entry>
							<ce:entry>
								<ce:cross-ref refid="f0015">Fig. 3</ce:cross-ref>
							</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry namest="col3" nameend="col4">Face images</ce:entry>
							<ce:entry>NNP-1</ce:entry>
							<ce:entry>
								<ce:cross-ref refid="f0020">Fig. 4</ce:cross-ref>
							</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry morerows="10">Image data set</ce:entry>
							<ce:entry namest="col3" nameend="col4">COIL-100</ce:entry>
							<ce:entry>NNP-2, NNP-3</ce:entry>
							<ce:entry>
								<ce:cross-ref refid="f0040">Fig. 8</ce:cross-ref>
								<ce:br/>
								<ce:cross-ref refid="f0045">Fig. 9</ce:cross-ref>
							</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry morerows="8">Synthetic data set</ce:entry>
							<ce:entry>Swiss roll</ce:entry>
							<ce:entry morerows="7">NNP-2</ce:entry>
							<ce:entry morerows="7">
								<ce:cross-ref refid="f0025">Fig. 5</ce:cross-ref>
								<ce:br/>
								<ce:cross-ref refid="f0035">Fig. 7</ce:cross-ref>
							</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>S curve</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>3D cluster</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>Punctured sphere</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>Twin peaks</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>Occluded disks</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>Corner planes</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>Toroidal helix</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>Gaussian randomly sampled</ce:entry>
							<ce:entry>NNP-2, NNP-3</ce:entry>
							<ce:entry>
								<ce:cross-ref refid="f0030">Fig. 6</ce:cross-ref>
							</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry namest="col3" nameend="col4">Face images</ce:entry>
							<ce:entry>NNP-2</ce:entry>
							<ce:entry>
								<ce:cross-ref refid="f0050">Fig. 10</ce:cross-ref>
							</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry namest="col1" nameend="col6">
								<ce:vsp sp="0.5"/>
							</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>Classification</ce:entry>
							<ce:entry namest="col2" nameend="col4">MNIST handwritten digit database</ce:entry>
							<ce:entry>Supervised NNP-2 and NNP-3</ce:entry>
							<ce:entry>
								<ce:cross-ref refid="t0010">Table 2</ce:cross-ref>
							</ce:entry>
						</cals:row>
					</cals:tbody>
				</cals:tgroup>
			</ce:table>
			<ce:table frame="topbot" id="t0010" rowsep="0" colsep="0">
				<ce:label>Table 2</ce:label>
				<ce:caption>
					<ce:simple-para id="sp080" view="all">Accuracy comparison on the MNIST database.</ce:simple-para>
				</ce:caption>
				<cals:tgroup cols="3" xmlns:cals="http://www.elsevier.com/xml/common/cals/schema">
					<cals:colspec colname="col1" align="left"/>
					<cals:colspec colname="col2" align="left"/>
					<cals:colspec colname="col3" align="char" char="."/>
					<cals:thead>
						<cals:row rowsep="1" valign="top">
							<ce:entry>Method</ce:entry>
							<ce:entry>Preprocessing</ce:entry>
							<ce:entry>Test error (%)</ce:entry>
						</cals:row>
					</cals:thead>
					<cals:tbody>
						<cals:row valign="top">
							<ce:entry>K-Nearest Classifier 
								<ce:cross-ref refid="b0135">[27]</ce:cross-ref>
							</ce:entry>
							<ce:entry>None</ce:entry>
							<ce:entry align="char" char=".">5.0</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>RBF 
								<ce:cross-ref refid="b0135">[27]</ce:cross-ref>
							</ce:entry>
							<ce:entry>None</ce:entry>
							<ce:entry align="char" char=".">3.6</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>3-Layer NN, 500
								<ce:hsp sp="0.25"/>+
								<ce:hsp sp="0.25"/>150 hidden units 
								<ce:cross-ref refid="b0135">[27]</ce:cross-ref>
							</ce:entry>
							<ce:entry>None</ce:entry>
							<ce:entry align="char" char=".">2.95</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>LeNet-1 
								<ce:cross-ref refid="b0135">[27]</ce:cross-ref>
							</ce:entry>
							<ce:entry>None</ce:entry>
							<ce:entry align="char" char=".">1.7</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>
								<ce:bold>Supervised NNP-2 [this paper]</ce:bold>
							</ce:entry>
							<ce:entry>
								<ce:bold>None</ce:bold>
							</ce:entry>
							<ce:entry align="char" char=".">
								<ce:bold>1.51</ce:bold>
							</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>SFA 
								<ce:cross-ref refid="b0035">[7]</ce:cross-ref>
							</ce:entry>
							<ce:entry>None</ce:entry>
							<ce:entry align="char" char=".">1.5</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>
								<ce:bold>Supervised NNP-3 [this paper]</ce:bold>
							</ce:entry>
							<ce:entry>
								<ce:bold>None</ce:bold>
							</ce:entry>
							<ce:entry align="char" char=".">
								<ce:bold>1.42</ce:bold>
							</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>K-NN, Tangent Distance 
								<ce:cross-ref refid="b0135">[27]</ce:cross-ref>
							</ce:entry>
							<ce:entry>Subsampling</ce:entry>
							<ce:entry align="char" char=".">1.1</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>Reduced Set SVM
								<ce:hsp sp="0.25"/>+
								<ce:hsp sp="0.25"/>deskewing 
								<ce:cross-ref refid="b0135">[27]</ce:cross-ref>
							</ce:entry>
							<ce:entry>None</ce:entry>
							<ce:entry align="char" char=".">1.0</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>LeNet-5 
								<ce:cross-ref refid="b0135">[27]</ce:cross-ref>
							</ce:entry>
							<ce:entry>None</ce:entry>
							<ce:entry align="char" char=".">0.95</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>Trainable feature extractor
								<ce:hsp sp="0.25"/>+
								<ce:hsp sp="0.25"/>SVM 
								<ce:cross-ref refid="b0130">[26]</ce:cross-ref>
							</ce:entry>
							<ce:entry>None</ce:entry>
							<ce:entry align="char" char=".">0.83</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>Large conv. net 
								<ce:cross-ref refid="b0170">[34]</ce:cross-ref>
							</ce:entry>
							<ce:entry>None</ce:entry>
							<ce:entry align="char" char=".">0.6</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry namest="col1" nameend="col3">
								<ce:vsp sp="0.5"/>
							</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>Virtual SVM 
								<ce:cross-ref refid="b0135">[27]</ce:cross-ref>
							</ce:entry>
							<ce:entry>Affine</ce:entry>
							<ce:entry align="char" char=".">0.8</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>LeNet-5 
								<ce:cross-ref refid="b0135">[27]</ce:cross-ref>
							</ce:entry>
							<ce:entry>Affine</ce:entry>
							<ce:entry align="char" char=".">0.8</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>Boosted LeNet-4 
								<ce:cross-ref refid="b0135">[27]</ce:cross-ref>
							</ce:entry>
							<ce:entry>Affine</ce:entry>
							<ce:entry align="char" char=".">0.7</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>TFE-SVM 
								<ce:cross-ref refid="b0130">[26]</ce:cross-ref>
							</ce:entry>
							<ce:entry>Affine</ce:entry>
							<ce:entry align="char" char=".">0.54</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>K-NN with nonlinear deformation (IDM) 
								<ce:cross-ref refid="b0115">[23]</ce:cross-ref>
							</ce:entry>
							<ce:entry>Shiftable edges</ce:entry>
							<ce:entry align="char" char=".">0.54</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>K-NN with nonlinear deformation (P2DHMDM) 
								<ce:cross-ref refid="b0115">[23]</ce:cross-ref>
							</ce:entry>
							<ce:entry>Shiftable edges</ce:entry>
							<ce:entry align="char" char=".">0.52</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>Convolutional NN 
								<ce:cross-ref refid="b0195">[39]</ce:cross-ref>
							</ce:entry>
							<ce:entry>Elastic</ce:entry>
							<ce:entry align="char" char=".">0.4</ce:entry>
						</cals:row>
					</cals:tbody>
				</cals:tgroup>
			</ce:table>
			<ce:table frame="topbot" id="t0015" rowsep="0" colsep="0">
				<ce:label>Table 3</ce:label>
				<ce:caption>
					<ce:simple-para id="sp085" view="all">Mapping quality comparison on synthetic image data sets.</ce:simple-para>
				</ce:caption>
				<cals:tgroup cols="8" xmlns:cals="http://www.elsevier.com/xml/common/cals/schema">
					<cals:colspec colname="col1" align="left"/>
					<cals:colspec colname="col2" align="left"/>
					<cals:colspec colname="col3" align="left"/>
					<cals:colspec colname="col4" align="left"/>
					<cals:colspec colname="col5" align="left"/>
					<cals:colspec colname="col6" align="left"/>
					<cals:colspec colname="col7" align="left"/>
					<cals:colspec colname="col8" align="left"/>
					<cals:thead>
						<cals:row rowsep="1" valign="top">
							<ce:entry>Data set</ce:entry>
							<ce:entry>Isomap</ce:entry>
							<ce:entry>LLE</ce:entry>
							<ce:entry>Hessian LLE</ce:entry>
							<ce:entry>Laplacian</ce:entry>
							<ce:entry>Diffusion Map</ce:entry>
							<ce:entry>LTSA</ce:entry>
							<ce:entry>NNP-2</ce:entry>
						</cals:row>
					</cals:thead>
					<cals:tbody>
						<cals:row valign="top">
							<ce:entry>Swiss roll</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>×</ce:entry>
							<ce:entry>×</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>×</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>S curve</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>×</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>√</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>3D cluster (cluster
								<ce:hsp sp="0.25"/>=
								<ce:hsp sp="0.25"/>3)
							</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>×
								<ce:cross-ref refid="tblfn1">
									<ce:sup loc="post">a</ce:sup>
								</ce:cross-ref>
							</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>×
								<ce:cross-ref refid="tblfn1">
									<ce:sup loc="post">a</ce:sup>
								</ce:cross-ref>
							</ce:entry>
							<ce:entry>√</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>3D cluster (cluster
								<ce:hsp sp="0.25"/>=
								<ce:hsp sp="0.25"/>8)
							</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>×
								<ce:cross-ref refid="tblfn1">
									<ce:sup loc="post">a</ce:sup>
								</ce:cross-ref>
							</ce:entry>
							<ce:entry>×</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>×
								<ce:cross-ref refid="tblfn1">
									<ce:sup loc="post">a</ce:sup>
								</ce:cross-ref>
							</ce:entry>
							<ce:entry>√</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>Punctured sphere</ce:entry>
							<ce:entry>×</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>×</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>×</ce:entry>
							<ce:entry>×</ce:entry>
							<ce:entry>√</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>Twin peaks</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>×</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>√</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>Occluded disks</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>×</ce:entry>
							<ce:entry>×</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>√</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>Corner planes</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>×</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>√</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>Toroidal helix (sample rate
								<ce:hsp sp="0.25"/>=
								<ce:hsp sp="0.25"/>1.0)
							</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>×</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>√</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>Gaussian randomly sampled</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>×</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>√
								<ce:cross-ref refid="tblfn2">
									<ce:sup loc="post">b</ce:sup>
								</ce:cross-ref>
							</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>Toroidal helix (sample rate
								<ce:hsp sp="0.25"/>=
								<ce:hsp sp="0.25"/>0.8)
							</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>×</ce:entry>
							<ce:entry>×</ce:entry>
							<ce:entry>×</ce:entry>
							<ce:entry>×</ce:entry>
							<ce:entry>√</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>Swiss roll (
								<ce:italic>N</ce:italic>
								<ce:hsp sp="0.25"/>=
								<ce:hsp sp="0.25"/>400)
							</ce:entry>
							<ce:entry>×</ce:entry>
							<ce:entry>×</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>×</ce:entry>
							<ce:entry>×</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>×</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>S curve (
								<ce:italic>N</ce:italic>
								<ce:hsp sp="0.25"/>=
								<ce:hsp sp="0.25"/>200)
							</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>×</ce:entry>
							<ce:entry>×</ce:entry>
							<ce:entry>×</ce:entry>
							<ce:entry>×</ce:entry>
							<ce:entry>√</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>COIL-100 duck object</ce:entry>
							<ce:entry>√</ce:entry>
							<ce:entry>×</ce:entry>
							<ce:entry>×</ce:entry>
							<ce:entry>×</ce:entry>
							<ce:entry>×</ce:entry>
							<ce:entry>×</ce:entry>
							<ce:entry>√</ce:entry>
						</cals:row>
					</cals:tbody>
				</cals:tgroup>
				<ce:legend>
					<ce:simple-para id="sp010" view="all">Note: √ and × represent that the good or bad mapping results obtained by each method respectively.</ce:simple-para>
				</ce:legend>
				<ce:table-footnote id="tblfn1">
					<ce:label>a</ce:label>
					<ce:note-para>Each cluster is compressed into a single point.</ce:note-para>
				</ce:table-footnote>
				<ce:table-footnote id="tblfn2">
					<ce:label>b</ce:label>
					<ce:note-para>NNP-3 is used, as shown in 
						<ce:cross-ref refid="f0030">Fig. 6</ce:cross-ref>.
					</ce:note-para>
				</ce:table-footnote>
			</ce:table>
			<ce:table frame="topbot" id="t0020" rowsep="0" colsep="0">
				<ce:label>Table 4</ce:label>
				<ce:caption>
					<ce:simple-para id="sp090" view="all">Efficiency comparison on synthetic image data sets.</ce:simple-para>
				</ce:caption>
				<cals:tgroup cols="8" xmlns:cals="http://www.elsevier.com/xml/common/cals/schema">
					<cals:colspec colname="col1" align="left"/>
					<cals:colspec colname="col2" align="char" char="."/>
					<cals:colspec colname="col3" align="char" char="."/>
					<cals:colspec colname="col4" align="char" char="."/>
					<cals:colspec colname="col5" align="char" char="."/>
					<cals:colspec colname="col6" align="char" char="."/>
					<cals:colspec colname="col7" align="char" char="."/>
					<cals:colspec colname="col8" align="char" char="."/>
					<cals:thead>
						<cals:row rowsep="1" valign="top">
							<ce:entry>Data set</ce:entry>
							<ce:entry>Isomap (s)</ce:entry>
							<ce:entry>LLE (s)</ce:entry>
							<ce:entry>Hessian LLE (s)</ce:entry>
							<ce:entry>Laplacian (s)</ce:entry>
							<ce:entry>Diffusion Map (s)</ce:entry>
							<ce:entry>LTSA (s)</ce:entry>
							<ce:entry>NNP-2 (s)</ce:entry>
						</cals:row>
					</cals:thead>
					<cals:tbody>
						<cals:row valign="top">
							<ce:entry>Swiss soll</ce:entry>
							<ce:entry align="char" char=".">32.5</ce:entry>
							<ce:entry align="char" char=".">
								<ce:bold>0.6</ce:bold>
							</ce:entry>
							<ce:entry align="char" char=".">9.1</ce:entry>
							<ce:entry align="char" char=".">
								<ce:bold>0.6</ce:bold>
							</ce:entry>
							<ce:entry align="char" char=".">2.0</ce:entry>
							<ce:entry align="char" char=".">0.8</ce:entry>
							<ce:entry align="char" char=".">13.6</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>S curve</ce:entry>
							<ce:entry align="char" char=".">28.5</ce:entry>
							<ce:entry align="char" char=".">
								<ce:bold>0.6</ce:bold>
							</ce:entry>
							<ce:entry align="char" char=".">9.9</ce:entry>
							<ce:entry align="char" char=".">
								<ce:bold>0.6</ce:bold>
							</ce:entry>
							<ce:entry align="char" char=".">1.5</ce:entry>
							<ce:entry align="char" char=".">0.7</ce:entry>
							<ce:entry align="char" char=".">12.4</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>3D cluster (cluster
								<ce:hsp sp="0.25"/>=
								<ce:hsp sp="0.25"/>3)
							</ce:entry>
							<ce:entry align="char" char=".">31.5</ce:entry>
							<ce:entry align="char" char=".">
								<ce:bold>0.7</ce:bold>
							</ce:entry>
							<ce:entry align="char" char=".">10.2</ce:entry>
							<ce:entry align="char" char=".">
								<ce:bold>0.7</ce:bold>
							</ce:entry>
							<ce:entry align="char" char=".">1.7</ce:entry>
							<ce:entry align="char" char=".">0.8</ce:entry>
							<ce:entry align="char" char=".">14.0</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>Punctured sphere</ce:entry>
							<ce:entry align="char" char=".">29.8</ce:entry>
							<ce:entry align="char" char=".">0.7</ce:entry>
							<ce:entry align="char" char=".">11.3</ce:entry>
							<ce:entry align="char" char=".">
								<ce:bold>0.6</ce:bold>
							</ce:entry>
							<ce:entry align="char" char=".">1.8</ce:entry>
							<ce:entry align="char" char=".">0.9</ce:entry>
							<ce:entry align="char" char=".">15.0</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>Twin peaks</ce:entry>
							<ce:entry align="char" char=".">28.1</ce:entry>
							<ce:entry align="char" char=".">0.7</ce:entry>
							<ce:entry align="char" char=".">9.4</ce:entry>
							<ce:entry align="char" char=".">
								<ce:bold>0.6</ce:bold>
							</ce:entry>
							<ce:entry align="char" char=".">1.5</ce:entry>
							<ce:entry align="char" char=".">0.7</ce:entry>
							<ce:entry align="char" char=".">13.7</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>Occluded disks</ce:entry>
							<ce:entry align="char" char=".">29.2</ce:entry>
							<ce:entry align="char" char=".">Crashed</ce:entry>
							<ce:entry align="char" char=".">13.7</ce:entry>
							<ce:entry align="char" char=".">
								<ce:bold>0.9</ce:bold>
							</ce:entry>
							<ce:entry align="char" char=".">3.0</ce:entry>
							<ce:entry align="char" char=".">10.6</ce:entry>
							<ce:entry align="char" char=".">12.3</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>Corner planes</ce:entry>
							<ce:entry align="char" char=".">28.3</ce:entry>
							<ce:entry align="char" char=".">
								<ce:bold>0.6</ce:bold>
							</ce:entry>
							<ce:entry align="char" char=".">11.3</ce:entry>
							<ce:entry align="char" char=".">
								<ce:bold>0.6</ce:bold>
							</ce:entry>
							<ce:entry align="char" char=".">2.4</ce:entry>
							<ce:entry align="char" char=".">0.8</ce:entry>
							<ce:entry align="char" char=".">13.9</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>Toroidal helix (sample rate
								<ce:hsp sp="0.25"/>=
								<ce:hsp sp="0.25"/>1.0)
							</ce:entry>
							<ce:entry align="char" char=".">28.4</ce:entry>
							<ce:entry align="char" char=".">
								<ce:bold>0.4</ce:bold>
							</ce:entry>
							<ce:entry align="char" char=".">9.1</ce:entry>
							<ce:entry align="char" char=".">0.5</ce:entry>
							<ce:entry align="char" char=".">1.5</ce:entry>
							<ce:entry align="char" char=".">0.6</ce:entry>
							<ce:entry align="char" char=".">12.1</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>Gaussian randomly sampled</ce:entry>
							<ce:entry align="char" char=".">28.2</ce:entry>
							<ce:entry align="char" char=".">0.7</ce:entry>
							<ce:entry align="char" char=".">9.0</ce:entry>
							<ce:entry align="char" char=".">
								<ce:bold>0.6</ce:bold>
							</ce:entry>
							<ce:entry align="char" char=".">1.5</ce:entry>
							<ce:entry align="char" char=".">0.8</ce:entry>
							<ce:entry align="char" char=".">10.4</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>COIL-100 duck object</ce:entry>
							<ce:entry align="char" char=".">1.3</ce:entry>
							<ce:entry align="char" char=".">
								<ce:bold>0.02</ce:bold>
							</ce:entry>
							<ce:entry align="char" char=".">0.5</ce:entry>
							<ce:entry align="char" char=".">
								<ce:bold>0.02</ce:bold>
							</ce:entry>
							<ce:entry align="char" char=".">0.2</ce:entry>
							<ce:entry align="char" char=".">0.03</ce:entry>
							<ce:entry align="char" char=".">0.3</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry namest="col1" nameend="col8">
								<ce:vsp sp="0.5"/>
							</ce:entry>
						</cals:row>
						<cals:row valign="top">
							<ce:entry>Average</ce:entry>
							<ce:entry align="char" char=".">26.6</ce:entry>
							<ce:entry align="char" char=".">
								<ce:bold>0.5</ce:bold>
							</ce:entry>
							<ce:entry align="char" char=".">9.4</ce:entry>
							<ce:entry align="char" char=".">0.6</ce:entry>
							<ce:entry align="char" char=".">1.7</ce:entry>
							<ce:entry align="char" char=".">1.7</ce:entry>
							<ce:entry align="char" char=".">11.8</ce:entry>
						</cals:row>
					</cals:tbody>
				</cals:tgroup>
			</ce:table>
		</ce:floats>
		<ja:head>
			<ce:title xmlns:ce="http://www.elsevier.com/xml/common/schema">Nonlinear dimensionality reduction using a temporal coherence principle</ce:title>
			<ce:author-group xmlns:ce="http://www.elsevier.com/xml/common/schema">
				<ce:author>
					<ce:given-name>YaPing</ce:given-name>
					<ce:surname>Huang</ce:surname>
					<ce:cross-ref refid="cor1">
						<ce:sup loc="post">⁎</ce:sup>
					</ce:cross-ref>
					<ce:e-address type="email">yphuang@bjtu.edu.cn</ce:e-address>
					<ce:e-address type="email">yphuang0613@hotmail.com</ce:e-address>
				</ce:author>
				<ce:author>
					<ce:given-name>JiaLi</ce:given-name>
					<ce:surname>Zhao</ce:surname>
					<ce:e-address type="email">jlzhao@bjtu.edu.cn</ce:e-address>
				</ce:author>
				<ce:author>
					<ce:given-name>YunHui</ce:given-name>
					<ce:surname>Liu</ce:surname>
					<ce:e-address type="email">yhliu@bjtu.edu.cn</ce:e-address>
				</ce:author>
				<ce:author>
					<ce:given-name>SiWei</ce:given-name>
					<ce:surname>Luo</ce:surname>
					<ce:e-address type="email">swluo@bjtu.edu.cn</ce:e-address>
				</ce:author>
				<ce:author>
					<ce:given-name>Qi</ce:given-name>
					<ce:surname>Zou</ce:surname>
					<ce:e-address type="email">qzou@bjtu.edu.cn</ce:e-address>
				</ce:author>
				<ce:author>
					<ce:given-name>Mei</ce:given-name>
					<ce:surname>Tian</ce:surname>
					<ce:e-address type="email">mtian@bjtu.edu.cn</ce:e-address>
				</ce:author>
				<ce:affiliation>
					<ce:textfn>Dept. of Computer Science and Technology, Beijing Jiaotong University, China</ce:textfn>
				</ce:affiliation>
				<ce:correspondence id="cor1">
					<ce:label>⁎</ce:label>
					<ce:text>Corresponding author.</ce:text>
				</ce:correspondence>
			</ce:author-group>
			<ce:date-received day="4" month="6" year="2009" xmlns:ce="http://www.elsevier.com/xml/common/schema"/>
			<ce:date-revised day="17" month="9" year="2010" xmlns:ce="http://www.elsevier.com/xml/common/schema"/>
			<ce:date-accepted day="2" month="4" year="2011" xmlns:ce="http://www.elsevier.com/xml/common/schema"/>
			<ce:abstract class="author" xml:lang="en" xmlns:ce="http://www.elsevier.com/xml/common/schema">
				<ce:section-title>Abstract</ce:section-title>
				<ce:abstract-sec>
					<ce:simple-para id="sp005" view="all">Temporal coherence principle is an attractive biologically inspired learning rule to extract slowly varying features from quickly varying input data. In this paper we develop a new Nonlinear Neighborhood Preserving (NNP) technique, by utilizing the temporal coherence principle to find an optimal low dimensional representation from the original high dimensional data. NNP is based on a nonlinear expansion of the original input data, such as polynomials of a given degree. It can be solved by the eigenvalue problem without using gradient descent and is guaranteed to find the global optimum. NNP can be viewed as a nonlinear dimensionality reduction framework which takes into consideration both time series and data sets without an obvious temporal structure. According to different situations, we introduce three algorithms of NNP, named NNP-1, NNP-2, and NNP-3. The objective function of NNP-1 is equal to Slow Feature Analysis (SFA), and it works well for time series such as image sequences. NNP-2 artificially constructs time series consisting of neighboring points for data sets without a clear temporal structure such as image data. NNP-3 is proposed for classification tasks, which can minimize the distances of neighboring points in the embedding space and ensure that the remaining points are as far apart as possible simultaneously. Furthermore, the kernel extension of NNP is also discussed in this paper. The proposed algorithms work very well on some image sequences and image data sets compared to other methods. Meanwhile, we perform the classification task on the MNIST handwritten digit database using the supervised NNP algorithms. The experimental results demonstrate that NNP is an effective technique for nonlinear dimensionality reduction tasks.</ce:simple-para>
				</ce:abstract-sec>
			</ce:abstract>
			<ce:keywords class="keyword" xmlns:ce="http://www.elsevier.com/xml/common/schema">
				<ce:section-title>Keywords</ce:section-title>
				<ce:keyword>
					<ce:text>Dimensionality reduction</ce:text>
				</ce:keyword>
				<ce:keyword>
					<ce:text>Feature extraction</ce:text>
				</ce:keyword>
				<ce:keyword>
					<ce:text>Temporal coherence principle</ce:text>
				</ce:keyword>
				<ce:keyword>
					<ce:text>Temporal slowness principle</ce:text>
				</ce:keyword>
				<ce:keyword>
					<ce:text>Manifold learning</ce:text>
				</ce:keyword>
				<ce:keyword>
					<ce:text>Pattern classification</ce:text>
				</ce:keyword>
				<ce:keyword>
					<ce:text>Character recognition</ce:text>
				</ce:keyword>
			</ce:keywords>
		</ja:head>
		<ja:body view="all">
			<ce:sections xmlns:ce="http://www.elsevier.com/xml/common/schema">
				<ce:section id="s0005" view="all">
					<ce:label>1</ce:label>
					<ce:section-title>Introduction</ce:section-title>
					<ce:para id="p0005" view="all">Dimensionality reduction is a fundamental and challenging task in many machine learning problems and pattern recognition applications. There are many impressive approaches for dimensionality reduction based on different assumptions. These approaches can be broadly divided into two categories: linear and nonlinear. The most popular linear techniques are Principle Component Analysis (PCA) and Linear Discriminant Analysis (LDA). A nonlinear variant of PCA, called Kernel Principle Component Analysis (KPCA) 
						<ce:cross-ref refid="b0185">[37]</ce:cross-ref>, is a representative approach using a kernel method to implicitly expand the input data space into a high dimensional feature space. Recently, there has been a great interest in algorithms for manifold learning. It attempts to discover the low dimensional representations embedded in a high dimensional observation space. The Self Organizing Maps (SOM) 
						<ce:cross-ref refid="b0120">[24]</ce:cross-ref> is one of the oldest manifold learning methods. The Curvilinear Component Analysis (CCA) algorithm 
						<ce:cross-ref refid="b0060">[12]</ce:cross-ref> was proposed as an improvement to the SOM and has been used in many applications 
						<ce:cross-ref refid="b0085">[17]</ce:cross-ref>, such as audio–visual speech recognition 
						<ce:cross-ref refid="b0215">[43]</ce:cross-ref>, scene classification 
						<ce:cross-ref refid="b0160">[32]</ce:cross-ref>, and software cost estimation 
						<ce:cross-ref refid="b0180">[36]</ce:cross-ref>. Isometric Feature Mapping (Isomap) 
						<ce:cross-refs refid="b0220 b0010">[44,2]</ce:cross-refs> and Locally Linear Embedding (LLE) 
						<ce:cross-ref refid="b0175">[35]</ce:cross-ref> are two famous algorithms proposed in the manifold learning domain. Isomap 
						<ce:cross-refs refid="b0220 b0010">[44,2]</ce:cross-refs> can be regarded as an extension to Multidimensional Scaling (MDS), which estimates the geodesic distances instead of Euclidean distances and then uses MDS to find points in a low dimensional Euclidean space. LLE 
						<ce:cross-ref refid="b0175">[35]</ce:cross-ref> was developed at the same time with Isomap, however its idea is to find a mapping in a low dimensional space in order to preserve the local geometry. Followed by the first two famous approaches, Laplacian Eigenmaps 
						<ce:cross-refs refid="b0015 b0020">[3,4]</ce:cross-refs> was developed based on the spectral graph theory, and Hessian LLE 
						<ce:cross-ref refid="b0065">[13]</ce:cross-ref> is closely related to these algorithms, but replaces the graph Laplacian with a Hessian operator. Another algorithm proposed for manifold learning is Local Tangent Space Alignment (LTSA) 
						<ce:cross-ref refid="b0260">[52]</ce:cross-ref>. LTSA estimates the tangent space at each point by performing PCA on its neighborhood set, and then aligns these tangent spaces to find global coordinates for each point. Diffusion Maps 
						<ce:cross-refs refid="b0055 b0165">[11,33]</ce:cross-refs> finds a normalized Gaussian kernel to construct the graph diffusion procedure. Semidefinite embedding 
						<ce:cross-ref refid="b0235">[47]</ce:cross-ref> uses a semidefinite program to find an appropriate Gram matrix so as to maximize the distances between non-neighboring points. The additional constraint of this program is that distances between neighboring points remain the same. In recent years, some linear manifold learning approaches were proposed, such as Local Preserving Projections (LPP) 
						<ce:cross-ref refid="b0090">[18]</ce:cross-ref>, Unsupervised Discriminant Projection (UDP) 
						<ce:cross-ref refid="b0245">[49]</ce:cross-ref>, and Class-wise Locality Preserving Projection 
						<ce:cross-ref refid="b0140">[28]</ce:cross-ref>. Some supervised and semi-supervised manifold learning algorithms were also developed for visualization 
						<ce:cross-ref refid="b0225">[45]</ce:cross-ref> and classification tasks 
						<ce:cross-refs refid="b0080 b0025 b0200 b0255">[16,5,40,51]</ce:cross-refs>. Moreover, Yan et al. 
						<ce:cross-ref refid="b0250">[50]</ce:cross-ref> proposed a unified framework, called graph embedding, for explaining many of the current popular dimensionality reduction algorithms.
					</ce:para>
					<ce:para id="p0010" view="all">Although manifold learning techniques for dimensionality reduction have been proposed for more than 10
						<ce:hsp sp="0.25"/>years, Seung and Lee 
						<ce:cross-ref refid="b0190">[38]</ce:cross-ref> pointed out that “manifolds are fundamental to perception”. Some neurophysiological experimental results also indicated that the firing rates of the neurons can be represented by a function which only contains several variables, such as eye movement 
						<ce:cross-ref refid="b0150">[30]</ce:cross-ref> and head position 
						<ce:cross-ref refid="b0210">[42]</ce:cross-ref>. These research results may imply that the neuron group activities can be restricted on a low dimensional manifold. Thus, applying biologically inspired techniques to the problem of dimensionality reduction may yield promising results.
					</ce:para>
					<ce:para id="p0015" view="all">Over the years, many studies have tried to apply the biologically motivated model to complex information processing tasks. Among them the temporal coherence principle has been an attractive biologically inspired learning rule. It is based on the idea of extracting the slowly varying features while ignoring fast variations according to the time scale. These extracted slowly varying features are “likely to reflect the properties of the environment and are in addition invariant to frequent transformations of the sensory input, such as visual translation, rotation, or scale”
						<ce:cross-ref refid="b0030">[6]</ce:cross-ref>. Since the temporal coherence principle explains important aspects of invariant properties, it has become a possible computational principle for the visual cortex.
					</ce:para>
					<ce:para id="p0020" view="all">Temporal coherence principle has been given in various forms by different researchers. The first description was given by Hinton 
						<ce:cross-ref refid="b0095">[19]</ce:cross-ref> as a learning rule in back-propagation neural networks, and it was implemented by Mitchison 
						<ce:cross-ref refid="b0155">[31]</ce:cross-ref> and Földiák 
						<ce:cross-ref refid="b0075">[15]</ce:cross-ref>. Földiák 
						<ce:cross-ref refid="b0075">[15]</ce:cross-ref> proposed a modified Hebbian trace rule to obtain translation invariance in complex cells. Mitchison 
						<ce:cross-ref refid="b0155">[31]</ce:cross-ref> defined an objective function to make the output of a network unit vary as slowly as possible. Stone and Bray 
						<ce:cross-ref refid="b0205">[41]</ce:cross-ref> also proposed an alternative objective function. A number of recent studies exploited such a principle using different implements, such as temporal slowness 
						<ce:cross-ref refid="b0240">[48]</ce:cross-ref> and temporal stability 
						<ce:cross-refs refid="b0110 b0125">[22,25]</ce:cross-refs>. Slow Feature Analysis (SFA) was proposed by Wiskott and Sejnowski 
						<ce:cross-ref refid="b0240">[48]</ce:cross-ref>, which defines an implementation of the temporal coherence principle, called temporal slowness. It extracts slowly varying features from fast varying time series by finding proper functions, e.g., spaces of polynomials given degree 
						<ce:italic>d</ce:italic>.
					</ce:para>
					<ce:para id="p0025" view="all">Temporal coherence principle has also been used to learn the properties of the primary visual cortex. Kayser et al. 
						<ce:cross-ref refid="b0110">[22]</ce:cross-ref> are the first to apply a definition of the temporal coherence principle, called stability, to natural image sequences in order to yield the properties of receptive fields in the visual cortex. Hurri and Hyvärinen 
						<ce:cross-ref refid="b0100">[20]</ce:cross-ref>, and Hyvärinen et al. 
						<ce:cross-ref refid="b0105">[21]</ce:cross-ref> also provided a definition of temporal coherence to natural image sequences that leads to the emergence of properties of the primary visual cortex. It seeks to make the energy of the output signal vary as little as possible over time. Einhäuser et al. 
						<ce:cross-ref refid="b0070">[14]</ce:cross-ref> learned a viewpoint invariant object representation using the temporal coherence learning rule.
					</ce:para>
					<ce:para id="p0030" view="all">In fact, there have been many exciting approaches by utilizing the temporal coherence principle to achieve invariant representations and to explain some properties of the visual system. In addition, a similar idea is also provided in other fields. For example, Smooth Orthogonal Decomposition (SOD) 
						<ce:cross-refs refid="b0040 b0045 b0050">[8–10]</ce:cross-refs> is used to analyze the feature space on time series analysis. These attractive related works on different domains can further confirm that the temporal coherence principle is a promising approach for future research.
					</ce:para>
					<ce:para id="p0035" view="all">Motivated by the temporal coherence principle, we propose a new nonlinear dimensionality reduction framework, called Nonlinear Neighborhood Preserving (NNP). It attempts to preserve the distances between nearby points in the embedding space to as small as possible. It must be pointed out that we consider the nearby points not only in Euclidean space but also in the time scale for time series. Under the proposed framework, we can deal with not only data without a temporal structure such as image data, but also temporal data such as image sequences. In order to distinct different applications, three algorithm variants generated from the proposed NNP framework are developed. NNP-1 deals with time series. NNP-2 artificially constructs time series consisting of neighboring points for data sets without a clear temporal structure. Furthermore, NNP-3 is suitable for classification tasks, which can minimize the distances of neighboring points in the embedding space and keep the remainder points as far apart as possible simultaneously.</ce:para>
					<ce:para id="p0040" view="all">We perform several experiments to verify the efficiency of the proposed algorithms. First, we test NNP-1 on two image sequences. Then, several image data sets are also considered compared to other algorithms. Subsequently, we execute the classification task on the MNIST handwritten digit database using the supervised algorithms. Our experimental results demonstrate that NNP has several advantages: First, it can be used on both image sequences and image data sets. Second, it is defined not only on training points but also on test points. Finally, it combines local and class discriminant information so as to be suitable for classification tasks.</ce:para>
					<ce:para id="p0045" view="all">This paper is organized as follows. Section 
						<ce:cross-ref refid="s0010">2</ce:cross-ref> introduces the traditional SFA algorithm. Section 
						<ce:cross-ref refid="s0015">3</ce:cross-ref> describes the general NNP framework, including three different implementations to satisfy different tasks. The kernel extension is given in Section 
						<ce:cross-ref refid="s0065">4</ce:cross-ref>. Results and analysis of the experiments are provided in Section 
						<ce:cross-ref refid="s0070">5</ce:cross-ref>. Finally, Section 
						<ce:cross-ref refid="s0130">6</ce:cross-ref> summarizes the results and future work.
					</ce:para>
				</ce:section>
				<ce:section id="s0010" view="all">
					<ce:label>2</ce:label>
					<ce:section-title>Traditional Slow Feature Analysis</ce:section-title>
					<ce:para id="p0050" view="all">Slow Feature Analysis (SFA) was originally proposed by Wiskott and Sejnowski 
						<ce:cross-ref refid="b0240">[48]</ce:cross-ref>. Its learning task is described as follows.
					</ce:para>
					<ce:para id="p0055" view="all">For a multidimensional time series 
						<ce:bold>x</ce:bold>
						<ce:inf loc="post">
							<ce:italic>t</ce:italic>
						</ce:inf>
						<ce:hsp sp="0.25"/>=
						<ce:hsp sp="0.25"/>(
						<ce:italic>x</ce:italic>
						<ce:inf loc="post">1,
							<ce:italic>t</ce:italic>
						</ce:inf>,
						<ce:hsp sp="0.12"/>
						<ce:italic>x</ce:italic>
						<ce:inf loc="post">2,
							<ce:italic>t</ce:italic>
						</ce:inf>,
						<ce:hsp sp="0.12"/>…
						<ce:hsp sp="0.12"/>,
						<ce:hsp sp="0.12"/>
						<ce:italic>x</ce:italic>
						<ce:inf loc="post">
							<ce:italic>n</ce:italic>,
							<ce:italic>t</ce:italic>
						</ce:inf>)
						<ce:sup loc="post">
							<ce:italic>T</ce:italic>
						</ce:sup>, 
						<ce:italic>t</ce:italic>
						<ce:hsp sp="0.25"/>∈
						<ce:hsp sp="0.25"/>[0,
						<ce:hsp sp="0.12"/>
						<ce:italic>T</ce:italic>], the objective of SFA is to find a set of transformations 
						<ce:italic>g</ce:italic>
						<ce:inf loc="post">1</ce:inf>(
						<ce:bold>x</ce:bold>
						<ce:inf loc="post">
							<ce:italic>t</ce:italic>
						</ce:inf>),
						<ce:hsp sp="0.12"/>
						<ce:italic>g</ce:italic>
						<ce:inf loc="post">2</ce:inf>(
						<ce:bold>x</ce:bold>
						<ce:inf loc="post">
							<ce:italic>t</ce:italic>
						</ce:inf>),
						<ce:hsp sp="0.12"/>…
						<ce:hsp sp="0.12"/>,
						<ce:hsp sp="0.12"/>
						<ce:italic>g</ce:italic>
						<ce:inf loc="post">
							<ce:italic>m</ce:italic>
						</ce:inf>(
						<ce:bold>x</ce:bold>
						<ce:inf loc="post">
							<ce:italic>t</ce:italic>
						</ce:inf>) that generate the output time series 
						<ce:bold>y</ce:bold>
						<ce:inf loc="post">
							<ce:italic>t</ce:italic>
						</ce:inf>
						<ce:hsp sp="0.25"/>=
						<ce:hsp sp="0.25"/>
						<ce:bold>g</ce:bold>(
						<ce:bold>x</ce:bold>
						<ce:inf loc="post">
							<ce:italic>t</ce:italic>
						</ce:inf>) such that
						<ce:display>
							<ce:formula id="e0005">
								<ce:label>(1)</ce:label>
								<mml:math altimg="si1.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:mi mathvariant="normal">Δ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi>y</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>k</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:mo stretchy="false">)</mml:mo>
									<mml:mo>=</mml:mo>
									<mml:mo stretchy="false">〈</mml:mo>
									<mml:mover accent="true">
										<mml:mrow>
											<mml:msub>
												<mml:mrow>
													<mml:mi>y</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>k</mml:mi>
													<mml:mtext>,</mml:mtext>
													<mml:mi>t</mml:mi>
												</mml:mrow>
											</mml:msub>
										</mml:mrow>
										<mml:mrow>
											<mml:mo>˙</mml:mo>
										</mml:mrow>
									</mml:mover>
									<mml:msup>
										<mml:mrow>
											<mml:mo stretchy="false">〉</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mn>2</mml:mn>
										</mml:mrow>
									</mml:msup>
									<mml:mtext>,</mml:mtext>
									<mml:mspace width="1em"/>
									<mml:mi>k</mml:mi>
									<mml:mo>=</mml:mo>
									<mml:mn>1</mml:mn>
									<mml:mtext>,</mml:mtext>
									<mml:mn>2</mml:mn>
									<mml:mtext>,</mml:mtext>
									<mml:mo>…</mml:mo>
									<mml:mtext>,</mml:mtext>
									<mml:mi>m</mml:mi>
								</mml:math>
							</ce:formula>
						</ce:display>is minimized under the constraints of zero mean and unit variance
						<ce:display>
							<ce:formula id="e0010">
								<ce:label>(2)</ce:label>
								<mml:math altimg="si2.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:mtable columnspacing="0em">
										<mml:mtr>
											<mml:mtd columnalign="right"/>
											<mml:mtd columnalign="left">
												<mml:mrow>
													<mml:mo stretchy="false">〈</mml:mo>
													<mml:msub>
														<mml:mrow>
															<mml:mi>y</mml:mi>
														</mml:mrow>
														<mml:mrow>
															<mml:mi>k</mml:mi>
															<mml:mtext>,</mml:mtext>
															<mml:mi>t</mml:mi>
														</mml:mrow>
													</mml:msub>
													<mml:mo stretchy="false">〉</mml:mo>
													<mml:mo>=</mml:mo>
													<mml:mn>0</mml:mn>
												</mml:mrow>
											</mml:mtd>
										</mml:mtr>
										<mml:mtr>
											<mml:mtd columnalign="right"/>
											<mml:mtd columnalign="left">
												<mml:mrow>
													<mml:mo stretchy="false">〈</mml:mo>
													<mml:msubsup>
														<mml:mrow>
															<mml:mi>y</mml:mi>
														</mml:mrow>
														<mml:mrow>
															<mml:mi>k</mml:mi>
															<mml:mtext>,</mml:mtext>
															<mml:mi>t</mml:mi>
														</mml:mrow>
														<mml:mrow>
															<mml:mn>2</mml:mn>
														</mml:mrow>
													</mml:msubsup>
													<mml:mo stretchy="false">〉</mml:mo>
													<mml:mo>=</mml:mo>
													<mml:mn>1</mml:mn>
												</mml:mrow>
											</mml:mtd>
										</mml:mtr>
										<mml:mtr>
											<mml:mtd columnalign="right"/>
											<mml:mtd columnalign="left">
												<mml:mrow>
													<mml:mo>∀</mml:mo>
													<mml:mi>i</mml:mi>
													<mml:mo>&lt;</mml:mo>
													<mml:mi>k</mml:mi>
													<mml:mtext>,</mml:mtext>
													<mml:mspace width="1em"/>
													<mml:mo stretchy="false">〈</mml:mo>
													<mml:msub>
														<mml:mrow>
															<mml:mi>y</mml:mi>
														</mml:mrow>
														<mml:mrow>
															<mml:mi>i</mml:mi>
															<mml:mtext>,</mml:mtext>
															<mml:mi>t</mml:mi>
														</mml:mrow>
													</mml:msub>
													<mml:msub>
														<mml:mrow>
															<mml:mi>y</mml:mi>
														</mml:mrow>
														<mml:mrow>
															<mml:mi>k</mml:mi>
															<mml:mtext>,</mml:mtext>
															<mml:mi>t</mml:mi>
														</mml:mrow>
													</mml:msub>
													<mml:mo stretchy="false">〉</mml:mo>
													<mml:mo>=</mml:mo>
													<mml:mn>0</mml:mn>
												</mml:mrow>
											</mml:mtd>
										</mml:mtr>
									</mml:mtable>
								</mml:math>
							</ce:formula>
						</ce:display>where 〈·〉 and 
						<mml:math altimg="si3.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
							<mml:mrow>
								<mml:mover accent="true">
									<mml:mrow>
										<mml:msub>
											<mml:mrow>
												<mml:mi>y</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:mi>k</mml:mi>
												<mml:mtext>,</mml:mtext>
												<mml:mi>t</mml:mi>
											</mml:mrow>
										</mml:msub>
									</mml:mrow>
									<mml:mrow>
										<mml:mo>˙</mml:mo>
									</mml:mrow>
								</mml:mover>
							</mml:mrow>
						</mml:math> indicate the time average and the temporal variation of 
						<ce:italic>y</ce:italic>
						<ce:inf loc="post">
							<ce:italic>k</ce:italic>,
							<ce:italic>t</ce:italic>
						</ce:inf>, respectively
						<ce:display>
							<ce:formula id="e0015">
								<ce:label>(3)</ce:label>
								<mml:math altimg="si4.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:mtable columnspacing="0em">
										<mml:mtr>
											<mml:mtd columnalign="right"/>
											<mml:mtd columnalign="left">
												<mml:mrow>
													<mml:mo stretchy="false">〈</mml:mo>
													<mml:mover accent="true">
														<mml:mrow>
															<mml:msub>
																<mml:mrow>
																	<mml:mi>y</mml:mi>
																</mml:mrow>
																<mml:mrow>
																	<mml:mi>k</mml:mi>
																	<mml:mtext>,</mml:mtext>
																	<mml:mi>t</mml:mi>
																</mml:mrow>
															</mml:msub>
														</mml:mrow>
														<mml:mrow>
															<mml:mo>˙</mml:mo>
														</mml:mrow>
													</mml:mover>
													<mml:mo stretchy="false">〉</mml:mo>
													<mml:mo>≔</mml:mo>
													<mml:msubsup>
														<mml:mo>∫</mml:mo>
														<mml:mrow>
															<mml:mn>0</mml:mn>
														</mml:mrow>
														<mml:mrow>
															<mml:mi>T</mml:mi>
														</mml:mrow>
													</mml:msubsup>
													<mml:mover accent="true">
														<mml:mrow>
															<mml:msub>
																<mml:mrow>
																	<mml:mi>y</mml:mi>
																</mml:mrow>
																<mml:mrow>
																	<mml:mi>k</mml:mi>
																	<mml:mtext>,</mml:mtext>
																	<mml:mi>t</mml:mi>
																</mml:mrow>
															</mml:msub>
														</mml:mrow>
														<mml:mrow>
															<mml:mo>˙</mml:mo>
														</mml:mrow>
													</mml:mover>
													<mml:mspace width="0.12em"/>
													<mml:mi mathvariant="italic">dt</mml:mi>
												</mml:mrow>
											</mml:mtd>
										</mml:mtr>
										<mml:mtr>
											<mml:mtd columnalign="right"/>
											<mml:mtd columnalign="left">
												<mml:mrow>
													<mml:mover accent="true">
														<mml:mrow>
															<mml:msub>
																<mml:mrow>
																	<mml:mi>y</mml:mi>
																</mml:mrow>
																<mml:mrow>
																	<mml:mi>k</mml:mi>
																	<mml:mtext>,</mml:mtext>
																	<mml:mi>t</mml:mi>
																</mml:mrow>
															</mml:msub>
														</mml:mrow>
														<mml:mrow>
															<mml:mo>˙</mml:mo>
														</mml:mrow>
													</mml:mover>
													<mml:mo>≔</mml:mo>
													<mml:mfrac>
														<mml:mrow>
															<mml:mi>∂</mml:mi>
															<mml:msub>
																<mml:mrow>
																	<mml:mi>y</mml:mi>
																</mml:mrow>
																<mml:mrow>
																	<mml:mi>k</mml:mi>
																	<mml:mtext>,</mml:mtext>
																	<mml:mi>t</mml:mi>
																</mml:mrow>
															</mml:msub>
														</mml:mrow>
														<mml:mrow>
															<mml:mi>∂</mml:mi>
															<mml:mi>t</mml:mi>
														</mml:mrow>
													</mml:mfrac>
												</mml:mrow>
											</mml:mtd>
										</mml:mtr>
									</mml:mtable>
								</mml:math>
							</ce:formula>
						</ce:display>Temporal variation can be approximated by a finite difference:
						<ce:display>
							<ce:formula id="e0020">
								<ce:label>(4)</ce:label>
								<mml:math altimg="si5.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:mover accent="true">
										<mml:mrow>
											<mml:msub>
												<mml:mrow>
													<mml:mi>y</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>k</mml:mi>
													<mml:mtext>,</mml:mtext>
													<mml:mi>t</mml:mi>
												</mml:mrow>
											</mml:msub>
										</mml:mrow>
										<mml:mrow>
											<mml:mo>˙</mml:mo>
										</mml:mrow>
									</mml:mover>
									<mml:mspace width="0.25em"/>
									<mml:mover>
										<mml:mrow>
											<mml:mo>≈</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi mathvariant="normal">Δ</mml:mi>
											<mml:mi>t</mml:mi>
											<mml:mo>=</mml:mo>
											<mml:mn>1</mml:mn>
										</mml:mrow>
									</mml:mover>
									<mml:mspace width="0.25em"/>
									<mml:msub>
										<mml:mrow>
											<mml:mi>y</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>k</mml:mi>
											<mml:mtext>,</mml:mtext>
											<mml:mi>t</mml:mi>
											<mml:mo>+</mml:mo>
											<mml:mi mathvariant="normal">Δ</mml:mi>
											<mml:mi>t</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:mo>-</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi>y</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>k</mml:mi>
											<mml:mtext>,</mml:mtext>
											<mml:mi>t</mml:mi>
										</mml:mrow>
									</mml:msub>
								</mml:math>
							</ce:formula>
						</ce:display>In the case of linear functions 
						<mml:math altimg="si6.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
							<mml:mrow>
								<mml:msub>
									<mml:mrow>
										<mml:mi>y</mml:mi>
									</mml:mrow>
									<mml:mrow>
										<mml:mi>k</mml:mi>
										<mml:mtext>,</mml:mtext>
										<mml:mi>t</mml:mi>
									</mml:mrow>
								</mml:msub>
								<mml:mo>=</mml:mo>
								<mml:msubsup>
									<mml:mrow>
										<mml:mi mathvariant="bold">w</mml:mi>
									</mml:mrow>
									<mml:mrow>
										<mml:mi>k</mml:mi>
									</mml:mrow>
									<mml:mrow>
										<mml:mi>T</mml:mi>
									</mml:mrow>
								</mml:msubsup>
								<mml:msub>
									<mml:mrow>
										<mml:mi mathvariant="bold">x</mml:mi>
									</mml:mrow>
									<mml:mrow>
										<mml:mi>t</mml:mi>
									</mml:mrow>
								</mml:msub>
							</mml:mrow>
						</mml:math>, Eq. 
						<ce:cross-ref refid="e0005">(1)</ce:cross-ref> can be written as
						<ce:display>
							<ce:formula id="e0025">
								<ce:label>(5)</ce:label>
								<mml:math altimg="si7.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:mi mathvariant="normal">Δ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi>y</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>k</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:mo stretchy="false">)</mml:mo>
									<mml:mo>=</mml:mo>
									<mml:mo stretchy="false">〈</mml:mo>
									<mml:msubsup>
										<mml:mrow>
											<mml:mover accent="true">
												<mml:mrow>
													<mml:mi>y</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mo>˙</mml:mo>
												</mml:mrow>
											</mml:mover>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>k</mml:mi>
											<mml:mtext>,</mml:mtext>
											<mml:mi>t</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mn>2</mml:mn>
										</mml:mrow>
									</mml:msubsup>
									<mml:mo stretchy="false">〉</mml:mo>
									<mml:mo>=</mml:mo>
									<mml:msubsup>
										<mml:mrow>
											<mml:mi mathvariant="bold">w</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>k</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msubsup>
									<mml:mo stretchy="false">〈</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mover accent="true">
												<mml:mrow>
													<mml:mi mathvariant="bold">x</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mo>˙</mml:mo>
												</mml:mrow>
											</mml:mover>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>t</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:msubsup>
										<mml:mrow>
											<mml:mover accent="true">
												<mml:mrow>
													<mml:mi mathvariant="bold">x</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mo>˙</mml:mo>
												</mml:mrow>
											</mml:mover>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>t</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msubsup>
									<mml:mo stretchy="false">〉</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">w</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>k</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:mo>=</mml:mo>
									<mml:msubsup>
										<mml:mrow>
											<mml:mi mathvariant="bold">w</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>k</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msubsup>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">Aw</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>k</mml:mi>
										</mml:mrow>
									</mml:msub>
								</mml:math>
							</ce:formula>
						</ce:display>
						<ce:display>
							<ce:formula id="e0030">
								<ce:label>(6)</ce:label>
								<mml:math altimg="si8.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:mi mathvariant="normal">Δ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi>y</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:msub>
										<mml:mrow>
											<mml:mi>y</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>k</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:mo stretchy="false">)</mml:mo>
									<mml:mo>=</mml:mo>
									<mml:msubsup>
										<mml:mrow>
											<mml:mi mathvariant="bold">w</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>k</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msubsup>
									<mml:mo stretchy="false">〈</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">x</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>t</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:msubsup>
										<mml:mrow>
											<mml:mi mathvariant="bold">x</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>t</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msubsup>
									<mml:mo stretchy="false">〉</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">w</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>k</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:mo>=</mml:mo>
									<mml:msubsup>
										<mml:mrow>
											<mml:mi mathvariant="bold">w</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>k</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msubsup>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">Bw</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>k</mml:mi>
										</mml:mrow>
									</mml:msub>
								</mml:math>
							</ce:formula>
						</ce:display>The constrained minimization leading to the generalized eigenproblem can be solved by the following equation
						<ce:display>
							<ce:formula id="e0175">
								<ce:label>(7)</ce:label>
								<mml:math altimg="si9.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:mtable columnspacing="0em">
										<mml:mtr>
											<mml:mtd columnalign="right"/>
											<mml:mtd columnalign="left">
												<mml:mrow>
													<mml:mi mathvariant="normal">min</mml:mi>
													<mml:mspace width="2em"/>
													<mml:mi mathvariant="italic">tr</mml:mi>
													<mml:mo stretchy="false">(</mml:mo>
													<mml:msup>
														<mml:mrow>
															<mml:mi mathvariant="bold">W</mml:mi>
														</mml:mrow>
														<mml:mrow>
															<mml:mi>T</mml:mi>
														</mml:mrow>
													</mml:msup>
													<mml:mi mathvariant="bold">AW</mml:mi>
													<mml:mo stretchy="false">)</mml:mo>
												</mml:mrow>
											</mml:mtd>
										</mml:mtr>
										<mml:mtr>
											<mml:mtd columnalign="right"/>
											<mml:mtd columnalign="left">
												<mml:mrow>
													<mml:mtext>s.t.</mml:mtext>
													<mml:mspace width="2em"/>
													<mml:mspace width="0.35em"/>
													<mml:msup>
														<mml:mrow>
															<mml:mi mathvariant="bold">W</mml:mi>
														</mml:mrow>
														<mml:mrow>
															<mml:mi>T</mml:mi>
														</mml:mrow>
													</mml:msup>
													<mml:mi mathvariant="bold">BW</mml:mi>
													<mml:mo>=</mml:mo>
													<mml:mi mathvariant="bold">I</mml:mi>
												</mml:mrow>
											</mml:mtd>
										</mml:mtr>
									</mml:mtable>
								</mml:math>
							</ce:formula>
						</ce:display>where 
						<ce:bold>W</ce:bold> is the matrix of the generalized eigenvectors. The slowest feature corresponds to the smallest eigenvalue, the second slowest feature corresponds to the second smallest eigenvalue, and so on.
					</ce:para>
					<ce:para id="p0060" view="all">In the more general nonlinear case, the input time series 
						<ce:bold>x</ce:bold>
						<ce:inf loc="post">
							<ce:italic>t</ce:italic>
						</ce:inf> can be expanded into 
						<mml:math altimg="si10.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
							<mml:mrow>
								<mml:msub>
									<mml:mrow>
										<mml:mover accent="true">
											<mml:mrow>
												<mml:mi mathvariant="bold">x</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:mo>˜</mml:mo>
											</mml:mrow>
										</mml:mover>
									</mml:mrow>
									<mml:mrow>
										<mml:mi>t</mml:mi>
									</mml:mrow>
								</mml:msub>
							</mml:mrow>
						</mml:math>, and the slow features can be calculated in the expanded space 
						<mml:math altimg="si11.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
							<mml:mrow>
								<mml:mi mathvariant="script">F</mml:mi>
							</mml:mrow>
						</mml:math>. For example, the fixed polynomial space of degree 
						<ce:italic>d</ce:italic> (
						<ce:italic>d</ce:italic>
						<ce:hsp sp="0.25"/>=
						<ce:hsp sp="0.25"/>2, 
						<ce:italic>d</ce:italic>
						<ce:hsp sp="0.25"/>=
						<ce:hsp sp="0.25"/>3) was used to perform pattern recognition tasks in 
						<ce:cross-ref refid="b0035">[7]</ce:cross-ref>.
					</ce:para>
				</ce:section>
				<ce:section id="s0015" view="all">
					<ce:label>3</ce:label>
					<ce:section-title>Nonlinear Neighborhood Preserving framework</ce:section-title>
					<ce:para id="p0065" view="all">In human primary early vision, we can observe the following principle: If people want to extract the meaningful description of a scene, it is obvious that the sensory input signals vary on short time scales whereas the scene description varies on much longer time scales. A number of recent studies try to utilize such a principle. The popular one among them is the temporal coherence principle. In fact, the purpose of dimensionality reduction algorithms is also to find a suitable low dimensional representation for the original high dimensional data. Such a principle would certainly be ideal to perform dimensionality reduction tasks. Therefore it is attractive to deal with nonlinear dimensionality reduction problems using the temporal coherence principle. We follow this idea and propose a Nonlinear Neighborhood Preserving (NNP) framework in this section. As we know, the human visual system always concerns itself with image sequences not random image data sets. Motivated by the rapid processing ability of the human visual system, we first consider temporal data using the temporal coherence principle, in contrast to many classic manifold learning algorithms which are proposed for image data sets. The input data of the human visual system does not change rapidly over time; instead they at different times are highly correlated and it is apparent that when they are reduced to the low dimensional space, the embedding representations are still highly correlated. Thus, the objective function of our algorithm is set to minimize the “distance” of the embedding coordinates of two frames if they are sequential frames in the original high dimensional space. When the principle is applied to image data sets, we replace sequential frames by nearby images in the Euclidean space. Then we can deal with not only data sets without a temporal structure but also time series under a unified framework. According to different types of data, we propose three algorithm variants, NNP-1, NNP-2 and NNP-3. NNP-1 deals with time series such as image sequences. NNP-2 deals with data without an obvious temporal structure such as image data. NNP-3 is proposed for classification tasks.</ce:para>
					<ce:section id="s0020" view="all">
						<ce:label>3.1</ce:label>
						<ce:section-title>Algorithm NNP-1</ce:section-title>
						<ce:para id="p0070" view="all">Most manifold learning algorithms can deal with time series, however, they use similar principles with image data, while ignoring the temporal coherence between sequential frames. In fact, the temporal coherence provides useful information about the neighborhood structure and the local geometry of the low dimensional manifold. So we propose a novel approach, named NNP-1, which considers the temporal coherence principle to perform dimensionality reduction tasks.</ce:para>
						<ce:para id="p0075" view="all">In order to extract the embedding representations for time series, the objective function of NNP-1 is set to find the optimal output signals exhibiting a temporal change which is as smooth as possible given the quickly varying input data. This objective function is similar to that of SFA 
							<ce:cross-ref refid="b0240">[48]</ce:cross-ref>. It can be solved by the eigenvalue problem without gradient descent and is guaranteed to find the global optimum. Thus we directly use SFA to handle time series.
						</ce:para>
						<ce:section id="s0025" view="all">
							<ce:label>3.1.1</ce:label>
							<ce:section-title>Definition</ce:section-title>
							<ce:para id="p0080" view="all">Given a high 
								<ce:italic>D</ce:italic>-dimensional time series 
								<ce:bold>x</ce:bold>
								<ce:inf loc="post">
									<ce:italic>t</ce:italic>
								</ce:inf>
								<ce:hsp sp="0.25"/>=
								<ce:hsp sp="0.25"/>(
								<ce:italic>x</ce:italic>
								<ce:inf loc="post">1,
									<ce:italic>t</ce:italic>
								</ce:inf>,
								<ce:hsp sp="0.12"/>
								<ce:italic>x</ce:italic>
								<ce:inf loc="post">2,
									<ce:italic>t</ce:italic>
								</ce:inf>,
								<ce:hsp sp="0.12"/>…
								<ce:hsp sp="0.12"/>,
								<ce:hsp sp="0.12"/>
								<ce:italic>x</ce:italic>
								<ce:inf loc="post">
									<ce:italic>D</ce:italic>,
									<ce:italic>t</ce:italic>
								</ce:inf>)
								<ce:sup loc="post">
									<ce:italic>T</ce:italic>
								</ce:sup>, 
								<ce:italic>t</ce:italic>
								<ce:hsp sp="0.25"/>∈
								<ce:hsp sp="0.25"/>[
								<ce:italic>t</ce:italic>
								<ce:inf loc="post">1</ce:inf>,
								<ce:hsp sp="0.12"/>
								<ce:italic>t</ce:italic>
								<ce:inf loc="post">
									<ce:italic>n</ce:italic>
								</ce:inf>], the objective function of NNP-1 is to find a low 
								<ce:italic>d</ce:italic>-dimensional (
								<ce:italic>d</ce:italic>
								<ce:hsp sp="0.25"/>≪
								<ce:hsp sp="0.25"/>
								<ce:italic>D</ce:italic>) coordinates 
								<ce:bold>y</ce:bold>
								<ce:inf loc="post">
									<ce:italic>t</ce:italic>
								</ce:inf>
								<ce:hsp sp="0.25"/>=
								<ce:hsp sp="0.25"/>(
								<ce:italic>y</ce:italic>
								<ce:inf loc="post">1,
									<ce:italic>t</ce:italic>
								</ce:inf>,
								<ce:hsp sp="0.12"/>
								<ce:italic>y</ce:italic>
								<ce:inf loc="post">2,
									<ce:italic>t</ce:italic>
								</ce:inf>,
								<ce:hsp sp="0.12"/>…
								<ce:hsp sp="0.12"/>,
								<ce:hsp sp="0.12"/>
								<ce:italic>y</ce:italic>
								<ce:inf loc="post">
									<ce:italic>d</ce:italic>,
									<ce:italic>t</ce:italic>
								</ce:inf>)
								<ce:sup loc="post">
									<ce:italic>T</ce:italic>
								</ce:sup>, 
								<ce:italic>t</ce:italic>
								<ce:hsp sp="0.25"/>∈
								<ce:hsp sp="0.25"/>[
								<ce:italic>t</ce:italic>
								<ce:inf loc="post">1</ce:inf>,
								<ce:hsp sp="0.12"/>
								<ce:italic>t</ce:italic>
								<ce:inf loc="post">
									<ce:italic>n</ce:italic>
								</ce:inf>] so as to ensure that 
								<mml:math altimg="si12.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:mrow>
										<mml:msub>
											<mml:mrow>
												<mml:mi mathvariant="bold">y</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:msub>
													<mml:mrow>
														<mml:mi>t</mml:mi>
													</mml:mrow>
													<mml:mrow>
														<mml:mi>i</mml:mi>
														<mml:mo>+</mml:mo>
														<mml:mn>1</mml:mn>
													</mml:mrow>
												</mml:msub>
											</mml:mrow>
										</mml:msub>
									</mml:mrow>
								</mml:math> and 
								<mml:math altimg="si13.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:mrow>
										<mml:msub>
											<mml:mrow>
												<mml:mi mathvariant="bold">y</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:msub>
													<mml:mrow>
														<mml:mi>t</mml:mi>
													</mml:mrow>
													<mml:mrow>
														<mml:mi>i</mml:mi>
													</mml:mrow>
												</mml:msub>
											</mml:mrow>
										</mml:msub>
									</mml:mrow>
								</mml:math> change as little as possible if 
								<mml:math altimg="si14.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:mrow>
										<mml:msub>
											<mml:mrow>
												<mml:mi mathvariant="bold">x</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:msub>
													<mml:mrow>
														<mml:mi>t</mml:mi>
													</mml:mrow>
													<mml:mrow>
														<mml:mi>i</mml:mi>
														<mml:mo>+</mml:mo>
														<mml:mn>1</mml:mn>
													</mml:mrow>
												</mml:msub>
											</mml:mrow>
										</mml:msub>
									</mml:mrow>
								</mml:math> and 
								<mml:math altimg="si15.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:mrow>
										<mml:msub>
											<mml:mrow>
												<mml:mi mathvariant="bold">x</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:msub>
													<mml:mrow>
														<mml:mi>t</mml:mi>
													</mml:mrow>
													<mml:mrow>
														<mml:mi>i</mml:mi>
													</mml:mrow>
												</mml:msub>
											</mml:mrow>
										</mml:msub>
									</mml:mrow>
								</mml:math> are sequential frames. Thus we can obtain a “good” mapping by minimizing the following objective function
								<ce:display>
									<ce:formula id="e0035">
										<ce:label>(8)</ce:label>
										<mml:math altimg="si16.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
											<mml:mi mathvariant="normal">Δ</mml:mi>
											<mml:mi mathvariant="bold">y</mml:mi>
											<mml:mo>=</mml:mo>
											<mml:munderover>
												<mml:mrow>
													<mml:mo>∑</mml:mo>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>i</mml:mi>
													<mml:mo>=</mml:mo>
													<mml:mn>1</mml:mn>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>n</mml:mi>
													<mml:mo>-</mml:mo>
													<mml:mn>1</mml:mn>
												</mml:mrow>
											</mml:munderover>
											<mml:mo stretchy="false">(</mml:mo>
											<mml:msub>
												<mml:mrow>
													<mml:mi mathvariant="bold">y</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:msub>
														<mml:mrow>
															<mml:mi>t</mml:mi>
														</mml:mrow>
														<mml:mrow>
															<mml:mi>i</mml:mi>
															<mml:mo>+</mml:mo>
															<mml:mn>1</mml:mn>
														</mml:mrow>
													</mml:msub>
												</mml:mrow>
											</mml:msub>
											<mml:mo>-</mml:mo>
											<mml:msub>
												<mml:mrow>
													<mml:mi mathvariant="bold">y</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:msub>
														<mml:mrow>
															<mml:mi>t</mml:mi>
														</mml:mrow>
														<mml:mrow>
															<mml:mi>i</mml:mi>
														</mml:mrow>
													</mml:msub>
												</mml:mrow>
											</mml:msub>
											<mml:msup>
												<mml:mrow>
													<mml:mo stretchy="false">)</mml:mo>
												</mml:mrow>
												<mml:mrow>
													<mml:mn>2</mml:mn>
												</mml:mrow>
											</mml:msup>
										</mml:math>
									</ce:formula>
								</ce:display>In order to get an appropriate mapping, we first expand 
								<mml:math altimg="si17.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:mrow>
										<mml:mi mathvariant="bold">X</mml:mi>
										<mml:mo>=</mml:mo>
										<mml:mo stretchy="false">(</mml:mo>
										<mml:msub>
											<mml:mrow>
												<mml:mi mathvariant="bold">x</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:msub>
													<mml:mrow>
														<mml:mi>t</mml:mi>
													</mml:mrow>
													<mml:mrow>
														<mml:mn>1</mml:mn>
													</mml:mrow>
												</mml:msub>
											</mml:mrow>
										</mml:msub>
										<mml:mtext>,</mml:mtext>
										<mml:msub>
											<mml:mrow>
												<mml:mi mathvariant="bold">x</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:msub>
													<mml:mrow>
														<mml:mi>t</mml:mi>
													</mml:mrow>
													<mml:mrow>
														<mml:mn>2</mml:mn>
													</mml:mrow>
												</mml:msub>
											</mml:mrow>
										</mml:msub>
										<mml:mtext>,</mml:mtext>
										<mml:mo>…</mml:mo>
										<mml:mtext>,</mml:mtext>
										<mml:msub>
											<mml:mrow>
												<mml:mi mathvariant="bold">x</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:msub>
													<mml:mrow>
														<mml:mi>t</mml:mi>
													</mml:mrow>
													<mml:mrow>
														<mml:mi>n</mml:mi>
													</mml:mrow>
												</mml:msub>
											</mml:mrow>
										</mml:msub>
										<mml:mo stretchy="false">)</mml:mo>
									</mml:mrow>
								</mml:math> into a nonlinear expanded space, e.g., spaces of polynomials of a given degree 
								<ce:italic>d</ce:italic>, to obtain the expanded data 
								<mml:math altimg="si18.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:mrow>
										<mml:mover accent="true">
											<mml:mrow>
												<mml:mi mathvariant="bold">X</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:mo stretchy="true">∼</mml:mo>
											</mml:mrow>
										</mml:mover>
										<mml:mo>=</mml:mo>
										<mml:mo stretchy="false">(</mml:mo>
										<mml:msub>
											<mml:mrow>
												<mml:mover accent="true">
													<mml:mrow>
														<mml:mi mathvariant="bold">x</mml:mi>
													</mml:mrow>
													<mml:mrow>
														<mml:mo>˜</mml:mo>
													</mml:mrow>
												</mml:mover>
											</mml:mrow>
											<mml:mrow>
												<mml:msub>
													<mml:mrow>
														<mml:mi>t</mml:mi>
													</mml:mrow>
													<mml:mrow>
														<mml:mn>1</mml:mn>
													</mml:mrow>
												</mml:msub>
											</mml:mrow>
										</mml:msub>
										<mml:mtext>,</mml:mtext>
										<mml:msub>
											<mml:mrow>
												<mml:mover accent="true">
													<mml:mrow>
														<mml:mi mathvariant="bold">x</mml:mi>
													</mml:mrow>
													<mml:mrow>
														<mml:mo>˜</mml:mo>
													</mml:mrow>
												</mml:mover>
											</mml:mrow>
											<mml:mrow>
												<mml:msub>
													<mml:mrow>
														<mml:mi>t</mml:mi>
													</mml:mrow>
													<mml:mrow>
														<mml:mn>2</mml:mn>
													</mml:mrow>
												</mml:msub>
											</mml:mrow>
										</mml:msub>
										<mml:mtext>,</mml:mtext>
										<mml:mo>…</mml:mo>
										<mml:mtext>,</mml:mtext>
										<mml:msub>
											<mml:mrow>
												<mml:mover accent="true">
													<mml:mrow>
														<mml:mi mathvariant="bold">x</mml:mi>
													</mml:mrow>
													<mml:mrow>
														<mml:mo>˜</mml:mo>
													</mml:mrow>
												</mml:mover>
											</mml:mrow>
											<mml:mrow>
												<mml:msub>
													<mml:mrow>
														<mml:mi>t</mml:mi>
													</mml:mrow>
													<mml:mrow>
														<mml:mi>n</mml:mi>
													</mml:mrow>
												</mml:msub>
											</mml:mrow>
										</mml:msub>
										<mml:mo stretchy="false">)</mml:mo>
									</mml:mrow>
								</mml:math>, and then estimate a linear transformation 
								<mml:math altimg="si19.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:mrow>
										<mml:mi mathvariant="bold">Y</mml:mi>
										<mml:mo>=</mml:mo>
										<mml:msup>
											<mml:mrow>
												<mml:mi mathvariant="bold">W</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:mi>T</mml:mi>
											</mml:mrow>
										</mml:msup>
										<mml:mover accent="true">
											<mml:mrow>
												<mml:mi mathvariant="bold">X</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:mo stretchy="true">∼</mml:mo>
											</mml:mrow>
										</mml:mover>
									</mml:mrow>
								</mml:math> to minimize the objective function 
								<ce:cross-ref refid="e0035">(8)</ce:cross-ref>.
							</ce:para>
							<ce:para id="p0085" view="all">Given the matrix 
								<mml:math altimg="si20.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:mrow>
										<mml:mi mathvariant="normal">Δ</mml:mi>
										<mml:mover accent="true">
											<mml:mrow>
												<mml:mi mathvariant="bold">X</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:mo stretchy="true">∼</mml:mo>
											</mml:mrow>
										</mml:mover>
									</mml:mrow>
								</mml:math>, where 
								<mml:math altimg="si21.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:mrow>
										<mml:mi mathvariant="normal">Δ</mml:mi>
										<mml:mover accent="true">
											<mml:mrow>
												<mml:msub>
													<mml:mrow>
														<mml:mi mathvariant="bold">x</mml:mi>
													</mml:mrow>
													<mml:mrow>
														<mml:mi>i</mml:mi>
													</mml:mrow>
												</mml:msub>
											</mml:mrow>
											<mml:mrow>
												<mml:mo>˜</mml:mo>
											</mml:mrow>
										</mml:mover>
										<mml:mo>=</mml:mo>
										<mml:msub>
											<mml:mrow>
												<mml:mover accent="true">
													<mml:mrow>
														<mml:mi mathvariant="bold">x</mml:mi>
													</mml:mrow>
													<mml:mrow>
														<mml:mo>˜</mml:mo>
													</mml:mrow>
												</mml:mover>
											</mml:mrow>
											<mml:mrow>
												<mml:msub>
													<mml:mrow>
														<mml:mi>t</mml:mi>
													</mml:mrow>
													<mml:mrow>
														<mml:mi>i</mml:mi>
														<mml:mo>+</mml:mo>
														<mml:mn>1</mml:mn>
													</mml:mrow>
												</mml:msub>
											</mml:mrow>
										</mml:msub>
										<mml:mo>-</mml:mo>
										<mml:msub>
											<mml:mrow>
												<mml:mover accent="true">
													<mml:mrow>
														<mml:mi mathvariant="bold">x</mml:mi>
													</mml:mrow>
													<mml:mrow>
														<mml:mo>˜</mml:mo>
													</mml:mrow>
												</mml:mover>
											</mml:mrow>
											<mml:mrow>
												<mml:msub>
													<mml:mrow>
														<mml:mi>t</mml:mi>
													</mml:mrow>
													<mml:mrow>
														<mml:mi>i</mml:mi>
													</mml:mrow>
												</mml:msub>
											</mml:mrow>
										</mml:msub>
										<mml:mspace width="0.35em"/>
										<mml:mo stretchy="false">(</mml:mo>
										<mml:mi>i</mml:mi>
										<mml:mo>=</mml:mo>
										<mml:mn>1</mml:mn>
										<mml:mtext>,</mml:mtext>
										<mml:mn>2</mml:mn>
										<mml:mtext>,</mml:mtext>
										<mml:mo>…</mml:mo>
										<mml:mtext>,</mml:mtext>
										<mml:mi>n</mml:mi>
										<mml:mo>-</mml:mo>
										<mml:mn>1</mml:mn>
										<mml:mo stretchy="false">)</mml:mo>
									</mml:mrow>
								</mml:math>, the objective function 
								<ce:cross-ref refid="e0035">(8)</ce:cross-ref> can be reformulated as
								<ce:display>
									<ce:formula id="e0040">
										<ce:label>(9)</ce:label>
										<mml:math altimg="si22.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
											<mml:mi mathvariant="normal">Δ</mml:mi>
											<mml:mi mathvariant="bold">y</mml:mi>
											<mml:mo>=</mml:mo>
											<mml:munderover>
												<mml:mrow>
													<mml:mo>∑</mml:mo>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>i</mml:mi>
													<mml:mo>=</mml:mo>
													<mml:mn>1</mml:mn>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>n</mml:mi>
													<mml:mo>-</mml:mo>
													<mml:mn>1</mml:mn>
												</mml:mrow>
											</mml:munderover>
											<mml:mo stretchy="false">(</mml:mo>
											<mml:msub>
												<mml:mrow>
													<mml:mi mathvariant="bold">y</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:msub>
														<mml:mrow>
															<mml:mi>t</mml:mi>
														</mml:mrow>
														<mml:mrow>
															<mml:mi>i</mml:mi>
															<mml:mo>+</mml:mo>
															<mml:mn>1</mml:mn>
														</mml:mrow>
													</mml:msub>
												</mml:mrow>
											</mml:msub>
											<mml:mo>-</mml:mo>
											<mml:msub>
												<mml:mrow>
													<mml:mi mathvariant="bold">y</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:msub>
														<mml:mrow>
															<mml:mi>t</mml:mi>
														</mml:mrow>
														<mml:mrow>
															<mml:mi>i</mml:mi>
														</mml:mrow>
													</mml:msub>
												</mml:mrow>
											</mml:msub>
											<mml:msup>
												<mml:mrow>
													<mml:mo stretchy="false">)</mml:mo>
												</mml:mrow>
												<mml:mrow>
													<mml:mn>2</mml:mn>
												</mml:mrow>
											</mml:msup>
											<mml:mo>=</mml:mo>
											<mml:mi mathvariant="italic">tr</mml:mi>
											<mml:mrow>
												<mml:mfenced open="(" close=")">
													<mml:mrow>
														<mml:munderover>
															<mml:mrow>
																<mml:mo>∑</mml:mo>
															</mml:mrow>
															<mml:mrow>
																<mml:mi>i</mml:mi>
																<mml:mo>=</mml:mo>
																<mml:mn>1</mml:mn>
															</mml:mrow>
															<mml:mrow>
																<mml:mi>n</mml:mi>
																<mml:mo>-</mml:mo>
																<mml:mn>1</mml:mn>
															</mml:mrow>
														</mml:munderover>
														<mml:mo stretchy="false">(</mml:mo>
														<mml:msup>
															<mml:mrow>
																<mml:mi mathvariant="bold">W</mml:mi>
															</mml:mrow>
															<mml:mrow>
																<mml:mi>T</mml:mi>
															</mml:mrow>
														</mml:msup>
														<mml:msub>
															<mml:mrow>
																<mml:mover accent="true">
																	<mml:mrow>
																		<mml:mi mathvariant="bold">x</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:mo>˜</mml:mo>
																	</mml:mrow>
																</mml:mover>
															</mml:mrow>
															<mml:mrow>
																<mml:msub>
																	<mml:mrow>
																		<mml:mi>t</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:mi>i</mml:mi>
																		<mml:mo>+</mml:mo>
																		<mml:mn>1</mml:mn>
																	</mml:mrow>
																</mml:msub>
															</mml:mrow>
														</mml:msub>
														<mml:mo>-</mml:mo>
														<mml:msup>
															<mml:mrow>
																<mml:mi mathvariant="bold">W</mml:mi>
															</mml:mrow>
															<mml:mrow>
																<mml:mi>T</mml:mi>
															</mml:mrow>
														</mml:msup>
														<mml:msub>
															<mml:mrow>
																<mml:mover accent="true">
																	<mml:mrow>
																		<mml:mi mathvariant="bold">x</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:mo>˜</mml:mo>
																	</mml:mrow>
																</mml:mover>
															</mml:mrow>
															<mml:mrow>
																<mml:msub>
																	<mml:mrow>
																		<mml:mi>t</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:mi>i</mml:mi>
																	</mml:mrow>
																</mml:msub>
															</mml:mrow>
														</mml:msub>
														<mml:msup>
															<mml:mrow>
																<mml:mo stretchy="false">)</mml:mo>
															</mml:mrow>
															<mml:mrow>
																<mml:mn>2</mml:mn>
															</mml:mrow>
														</mml:msup>
													</mml:mrow>
												</mml:mfenced>
											</mml:mrow>
											<mml:mo>=</mml:mo>
											<mml:mi mathvariant="italic">tr</mml:mi>
											<mml:mrow>
												<mml:mfenced open="(" close=")">
													<mml:mrow>
														<mml:munderover>
															<mml:mrow>
																<mml:mo>∑</mml:mo>
															</mml:mrow>
															<mml:mrow>
																<mml:mi>i</mml:mi>
																<mml:mo>=</mml:mo>
																<mml:mn>1</mml:mn>
															</mml:mrow>
															<mml:mrow>
																<mml:mi>n</mml:mi>
																<mml:mo>-</mml:mo>
																<mml:mn>1</mml:mn>
															</mml:mrow>
														</mml:munderover>
														<mml:mo stretchy="false">(</mml:mo>
														<mml:msup>
															<mml:mrow>
																<mml:mi mathvariant="bold">W</mml:mi>
															</mml:mrow>
															<mml:mrow>
																<mml:mi>T</mml:mi>
															</mml:mrow>
														</mml:msup>
														<mml:mo stretchy="false">(</mml:mo>
														<mml:msub>
															<mml:mrow>
																<mml:mover accent="true">
																	<mml:mrow>
																		<mml:mi mathvariant="bold">x</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:mo>˜</mml:mo>
																	</mml:mrow>
																</mml:mover>
															</mml:mrow>
															<mml:mrow>
																<mml:msub>
																	<mml:mrow>
																		<mml:mi>t</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:mi>i</mml:mi>
																		<mml:mo>+</mml:mo>
																		<mml:mn>1</mml:mn>
																	</mml:mrow>
																</mml:msub>
															</mml:mrow>
														</mml:msub>
														<mml:mo>-</mml:mo>
														<mml:msub>
															<mml:mrow>
																<mml:mover accent="true">
																	<mml:mrow>
																		<mml:mi mathvariant="bold">x</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:mo>˜</mml:mo>
																	</mml:mrow>
																</mml:mover>
															</mml:mrow>
															<mml:mrow>
																<mml:msub>
																	<mml:mrow>
																		<mml:mi>t</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:mi>i</mml:mi>
																	</mml:mrow>
																</mml:msub>
															</mml:mrow>
														</mml:msub>
														<mml:mo stretchy="false">)</mml:mo>
														<mml:msup>
															<mml:mrow>
																<mml:mo stretchy="false">)</mml:mo>
															</mml:mrow>
															<mml:mrow>
																<mml:mn>2</mml:mn>
															</mml:mrow>
														</mml:msup>
													</mml:mrow>
												</mml:mfenced>
											</mml:mrow>
											<mml:mo>=</mml:mo>
											<mml:mi mathvariant="italic">tr</mml:mi>
											<mml:mrow>
												<mml:mfenced open="(" close=")">
													<mml:mrow>
														<mml:msup>
															<mml:mrow>
																<mml:mi mathvariant="bold">W</mml:mi>
															</mml:mrow>
															<mml:mrow>
																<mml:mi>T</mml:mi>
															</mml:mrow>
														</mml:msup>
														<mml:munderover>
															<mml:mrow>
																<mml:mo>∑</mml:mo>
															</mml:mrow>
															<mml:mrow>
																<mml:mi>i</mml:mi>
																<mml:mo>=</mml:mo>
																<mml:mn>1</mml:mn>
															</mml:mrow>
															<mml:mrow>
																<mml:mi>n</mml:mi>
																<mml:mo>-</mml:mo>
																<mml:mn>1</mml:mn>
															</mml:mrow>
														</mml:munderover>
														<mml:mo stretchy="false">(</mml:mo>
														<mml:msub>
															<mml:mrow>
																<mml:mover accent="true">
																	<mml:mrow>
																		<mml:mi mathvariant="bold">x</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:mo>˜</mml:mo>
																	</mml:mrow>
																</mml:mover>
															</mml:mrow>
															<mml:mrow>
																<mml:msub>
																	<mml:mrow>
																		<mml:mi>t</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:mi>i</mml:mi>
																		<mml:mo>+</mml:mo>
																		<mml:mn>1</mml:mn>
																	</mml:mrow>
																</mml:msub>
															</mml:mrow>
														</mml:msub>
														<mml:mo>-</mml:mo>
														<mml:msub>
															<mml:mrow>
																<mml:mover accent="true">
																	<mml:mrow>
																		<mml:mi mathvariant="bold">x</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:mo>˜</mml:mo>
																	</mml:mrow>
																</mml:mover>
															</mml:mrow>
															<mml:mrow>
																<mml:msub>
																	<mml:mrow>
																		<mml:mi>t</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:mi>i</mml:mi>
																	</mml:mrow>
																</mml:msub>
															</mml:mrow>
														</mml:msub>
														<mml:msup>
															<mml:mrow>
																<mml:mo stretchy="false">)</mml:mo>
															</mml:mrow>
															<mml:mrow>
																<mml:mn>2</mml:mn>
															</mml:mrow>
														</mml:msup>
														<mml:mi mathvariant="bold">W</mml:mi>
													</mml:mrow>
												</mml:mfenced>
											</mml:mrow>
											<mml:mo>=</mml:mo>
											<mml:mi mathvariant="italic">tr</mml:mi>
											<mml:mo stretchy="false">(</mml:mo>
											<mml:msup>
												<mml:mrow>
													<mml:mi mathvariant="bold">W</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>T</mml:mi>
												</mml:mrow>
											</mml:msup>
											<mml:mi mathvariant="normal">Δ</mml:mi>
											<mml:mover accent="true">
												<mml:mrow>
													<mml:mi mathvariant="bold">X</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mo stretchy="true">∼</mml:mo>
												</mml:mrow>
											</mml:mover>
											<mml:mi mathvariant="normal">Δ</mml:mi>
											<mml:msup>
												<mml:mrow>
													<mml:mover accent="true">
														<mml:mrow>
															<mml:mi mathvariant="bold">X</mml:mi>
														</mml:mrow>
														<mml:mrow>
															<mml:mo stretchy="true">∼</mml:mo>
														</mml:mrow>
													</mml:mover>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>T</mml:mi>
												</mml:mrow>
											</mml:msup>
											<mml:mi mathvariant="bold">W</mml:mi>
											<mml:mo stretchy="false">)</mml:mo>
										</mml:math>
									</ce:formula>
								</ce:display>We can solve this problem under the constraints of zero mean and unit variance, which can keep significant information as much as possible
								<ce:display>
									<ce:formula id="e0045">
										<ce:label>(10)</ce:label>
										<mml:math altimg="si23.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
											<mml:mtable columnspacing="0em">
												<mml:mtr>
													<mml:mtd columnalign="right"/>
													<mml:mtd columnalign="left">
														<mml:mrow>
															<mml:mi>E</mml:mi>
															<mml:mo stretchy="false">(</mml:mo>
															<mml:mi mathvariant="bold">Y</mml:mi>
															<mml:mo stretchy="false">)</mml:mo>
															<mml:mo>=</mml:mo>
															<mml:mn>0</mml:mn>
														</mml:mrow>
													</mml:mtd>
												</mml:mtr>
												<mml:mtr>
													<mml:mtd columnalign="right"/>
													<mml:mtd columnalign="left">
														<mml:mrow>
															<mml:mi>E</mml:mi>
															<mml:mo stretchy="false">(</mml:mo>
															<mml:msup>
																<mml:mrow>
																	<mml:mi mathvariant="bold">YY</mml:mi>
																</mml:mrow>
																<mml:mrow>
																	<mml:mi>T</mml:mi>
																</mml:mrow>
															</mml:msup>
															<mml:mo stretchy="false">)</mml:mo>
															<mml:mo>=</mml:mo>
															<mml:mi mathvariant="bold">I</mml:mi>
														</mml:mrow>
													</mml:mtd>
												</mml:mtr>
											</mml:mtable>
										</mml:math>
									</ce:formula>
								</ce:display>The covariance matrix of 
								<ce:bold>Y</ce:bold> can be calculated by
								<ce:display>
									<ce:formula id="e0050">
										<ce:label>(11)</ce:label>
										<mml:math altimg="si24.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
											<mml:msup>
												<mml:mrow>
													<mml:mi mathvariant="bold">YY</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>T</mml:mi>
												</mml:mrow>
											</mml:msup>
											<mml:mo>=</mml:mo>
											<mml:msup>
												<mml:mrow>
													<mml:mi mathvariant="bold">W</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>T</mml:mi>
												</mml:mrow>
											</mml:msup>
											<mml:mover accent="true">
												<mml:mrow>
													<mml:mi mathvariant="bold">X</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mo stretchy="true">∼</mml:mo>
												</mml:mrow>
											</mml:mover>
											<mml:msup>
												<mml:mrow>
													<mml:mover accent="true">
														<mml:mrow>
															<mml:mi mathvariant="bold">X</mml:mi>
														</mml:mrow>
														<mml:mrow>
															<mml:mo stretchy="true">∼</mml:mo>
														</mml:mrow>
													</mml:mover>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>T</mml:mi>
												</mml:mrow>
											</mml:msup>
											<mml:mi mathvariant="bold">W</mml:mi>
										</mml:math>
									</ce:formula>
								</ce:display>Finally, the minimization problem is reduced to find
								<ce:display>
									<ce:formula id="e0055">
										<ce:label>(12)</ce:label>
										<mml:math altimg="si25.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
											<mml:munder>
												<mml:mrow>
													<mml:mi mathvariant="normal">arg</mml:mi>
													<mml:mspace width="0.12em"/>
													<mml:mi mathvariant="normal">min</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mi mathvariant="bold">W</mml:mi>
												</mml:mrow>
											</mml:munder>
											<mml:mfrac>
												<mml:mrow>
													<mml:msup>
														<mml:mrow>
															<mml:mi mathvariant="bold">W</mml:mi>
														</mml:mrow>
														<mml:mrow>
															<mml:mi>T</mml:mi>
														</mml:mrow>
													</mml:msup>
													<mml:mi mathvariant="bold">AW</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:msup>
														<mml:mrow>
															<mml:mi mathvariant="bold">W</mml:mi>
														</mml:mrow>
														<mml:mrow>
															<mml:mi>T</mml:mi>
														</mml:mrow>
													</mml:msup>
													<mml:mi mathvariant="bold">BW</mml:mi>
												</mml:mrow>
											</mml:mfrac>
										</mml:math>
									</ce:formula>
								</ce:display>where
								<ce:display>
									<ce:formula id="e0185">
										<ce:label>(13)</ce:label>
										<mml:math altimg="si26.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
											<mml:mi mathvariant="bold">A</mml:mi>
											<mml:mo>=</mml:mo>
											<mml:mi mathvariant="normal">Δ</mml:mi>
											<mml:mover accent="true">
												<mml:mrow>
													<mml:mi mathvariant="bold">X</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mo stretchy="true">∼</mml:mo>
												</mml:mrow>
											</mml:mover>
											<mml:mi mathvariant="normal">Δ</mml:mi>
											<mml:msup>
												<mml:mrow>
													<mml:mover accent="true">
														<mml:mrow>
															<mml:mi mathvariant="bold">X</mml:mi>
														</mml:mrow>
														<mml:mrow>
															<mml:mo stretchy="true">∼</mml:mo>
														</mml:mrow>
													</mml:mover>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>T</mml:mi>
												</mml:mrow>
											</mml:msup>
										</mml:math>
									</ce:formula>
								</ce:display>
								<ce:display>
									<ce:formula id="e0190">
										<ce:label>(14)</ce:label>
										<mml:math altimg="si27.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
											<mml:mi mathvariant="bold">B</mml:mi>
											<mml:mo>=</mml:mo>
											<mml:mover accent="true">
												<mml:mrow>
													<mml:mi mathvariant="bold">X</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mo stretchy="true">∼</mml:mo>
												</mml:mrow>
											</mml:mover>
											<mml:msup>
												<mml:mrow>
													<mml:mover accent="true">
														<mml:mrow>
															<mml:mi mathvariant="bold">X</mml:mi>
														</mml:mrow>
														<mml:mrow>
															<mml:mo stretchy="true">∼</mml:mo>
														</mml:mrow>
													</mml:mover>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>T</mml:mi>
												</mml:mrow>
											</mml:msup>
										</mml:math>
									</ce:formula>
								</ce:display>It is a version of Rayleigh quotient and the problem to be solved is the generalized eigenproblem
								<ce:display>
									<ce:formula id="e0060">
										<ce:label>(15)</ce:label>
										<mml:math altimg="si28.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
											<mml:mi mathvariant="bold">AW</mml:mi>
											<mml:mo>=</mml:mo>
											<mml:mi mathvariant="bold">Λ</mml:mi>
											<mml:mi mathvariant="bold">BW</mml:mi>
										</mml:math>
									</ce:formula>
								</ce:display>where 
								<ce:bold>W</ce:bold>
								<ce:hsp sp="0.25"/>=
								<ce:hsp sp="0.25"/>(
								<ce:bold>w</ce:bold>
								<ce:inf loc="post">1</ce:inf>,
								<ce:hsp sp="0.12"/>
								<ce:bold>w</ce:bold>
								<ce:inf loc="post">2</ce:inf>,
								<ce:hsp sp="0.12"/>…
								<ce:hsp sp="0.12"/>,
								<ce:hsp sp="0.12"/>
								<ce:bold>w</ce:bold>
								<ce:inf loc="post">
									<ce:italic>D</ce:italic>
								</ce:inf>) is the matrix of the generalized eigenvectors whose columns are ordered according to the eigenvalues and 
								<ce:bold>Λ</ce:bold> is the diagonal matrix of the generalized eigenvalues. Since 
								<ce:bold>A</ce:bold> and 
								<ce:bold>B</ce:bold> are covariance matrices which are positive semidefinite and symmetric, all eigenvalues are real and greater than or equal to zero. We choose 
								<ce:italic>d</ce:italic> smallest non-zero eigenvalues and the associated 
								<ce:italic>d</ce:italic> eigenvectors, and then the low 
								<ce:italic>d</ce:italic>-dimensional embedding coordinates 
								<mml:math altimg="si29.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:mrow>
										<mml:msub>
											<mml:mrow>
												<mml:mi mathvariant="bold">y</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:msub>
													<mml:mrow>
														<mml:mi>t</mml:mi>
													</mml:mrow>
													<mml:mrow>
														<mml:mi>i</mml:mi>
													</mml:mrow>
												</mml:msub>
											</mml:mrow>
										</mml:msub>
									</mml:mrow>
								</mml:math> for the input data 
								<mml:math altimg="si30.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:mrow>
										<mml:msub>
											<mml:mrow>
												<mml:mi mathvariant="bold">x</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:msub>
													<mml:mrow>
														<mml:mi>t</mml:mi>
													</mml:mrow>
													<mml:mrow>
														<mml:mi>i</mml:mi>
													</mml:mrow>
												</mml:msub>
											</mml:mrow>
										</mml:msub>
									</mml:mrow>
								</mml:math> are estimated by 
								<mml:math altimg="si31.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:mrow>
										<mml:msub>
											<mml:mrow>
												<mml:mi mathvariant="bold">y</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:msub>
													<mml:mrow>
														<mml:mi>t</mml:mi>
													</mml:mrow>
													<mml:mrow>
														<mml:mi>i</mml:mi>
													</mml:mrow>
												</mml:msub>
											</mml:mrow>
										</mml:msub>
										<mml:mo>=</mml:mo>
										<mml:msup>
											<mml:mrow>
												<mml:mi mathvariant="bold">U</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:mi>T</mml:mi>
											</mml:mrow>
										</mml:msup>
										<mml:msub>
											<mml:mrow>
												<mml:mi mathvariant="bold">x</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:msub>
													<mml:mrow>
														<mml:mi>t</mml:mi>
													</mml:mrow>
													<mml:mrow>
														<mml:mi>i</mml:mi>
													</mml:mrow>
												</mml:msub>
											</mml:mrow>
										</mml:msub>
									</mml:mrow>
								</mml:math>, where 
								<ce:bold>U</ce:bold>
								<ce:hsp sp="0.25"/>=
								<ce:hsp sp="0.25"/>(
								<ce:bold>w</ce:bold>
								<ce:inf loc="post">1</ce:inf>,
								<ce:hsp sp="0.12"/>
								<ce:bold>w</ce:bold>
								<ce:inf loc="post">2</ce:inf>,
								<ce:hsp sp="0.12"/>…
								<ce:hsp sp="0.12"/>,
								<ce:hsp sp="0.12"/>
								<ce:bold>w</ce:bold>
								<ce:inf loc="post">
									<ce:italic>d</ce:italic>
								</ce:inf>).
							</ce:para>
						</ce:section>
						<ce:section id="s0030" view="all">
							<ce:label>3.1.2</ce:label>
							<ce:section-title>Algorithm summarization</ce:section-title>
							<ce:para id="p0090" view="all">The NNP-1 algorithm for temporal data is summarized as follows.
								<ce:display>
									<ce:table frame="topbot" id="t0025" rowsep="0" colsep="0">
										<cals:tgroup cols="1" xmlns:cals="http://www.elsevier.com/xml/common/cals/schema">
											<cals:colspec colname="col1" align="left"/>
											<cals:thead>
												<cals:row rowsep="1" valign="top">
													<ce:entry>
														<ce:bold>Algorithm NNP-1</ce:bold>
													</ce:entry>
												</cals:row>
											</cals:thead>
											<cals:tbody>
												<cals:row valign="top">
													<ce:entry>
														<ce:bold>Input: x</ce:bold>
														<ce:inf loc="post">
															<ce:italic>t</ce:italic>
														</ce:inf>
														<ce:hsp sp="0.25"/>=
														<ce:hsp sp="0.25"/>(
														<ce:italic>x</ce:italic>
														<ce:inf loc="post">1,
															<ce:italic>t</ce:italic>
														</ce:inf>,
														<ce:hsp sp="0.12"/>
														<ce:italic>x</ce:italic>
														<ce:inf loc="post">2,
															<ce:italic>t</ce:italic>
														</ce:inf>,
														<ce:hsp sp="0.12"/>…
														<ce:hsp sp="0.12"/>,
														<ce:hsp sp="0.12"/>
														<ce:italic>x</ce:italic>
														<ce:inf loc="post">
															<ce:italic>D</ce:italic>,
															<ce:italic>t</ce:italic>
														</ce:inf>)
														<ce:sup loc="post">
															<ce:italic>T</ce:italic>
														</ce:sup>, 
														<ce:italic>t</ce:italic>
														<ce:hsp sp="0.25"/>∈
														<ce:hsp sp="0.25"/>[
														<ce:italic>t</ce:italic>
														<ce:inf loc="post">1</ce:inf>,
														<ce:hsp sp="0.12"/>
														<ce:italic>t</ce:italic>
														<ce:inf loc="post">
															<ce:italic>n</ce:italic>
														</ce:inf>]
													</ce:entry>
												</cals:row>
												<cals:row valign="top">
													<ce:entry>
														<ce:hsp sp="1"/>
														<ce:bold>Step 1:</ce:bold> expand 
														<mml:math altimg="si32.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
															<mml:mrow>
																<mml:mi mathvariant="bold">X</mml:mi>
																<mml:mo>=</mml:mo>
																<mml:mo stretchy="false">(</mml:mo>
																<mml:msub>
																	<mml:mrow>
																		<mml:mi mathvariant="bold">x</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:msub>
																			<mml:mrow>
																				<mml:mi>t</mml:mi>
																			</mml:mrow>
																			<mml:mrow>
																				<mml:mn>1</mml:mn>
																			</mml:mrow>
																		</mml:msub>
																	</mml:mrow>
																</mml:msub>
																<mml:mtext>,</mml:mtext>
																<mml:msub>
																	<mml:mrow>
																		<mml:mi mathvariant="bold">x</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:msub>
																			<mml:mrow>
																				<mml:mi>t</mml:mi>
																			</mml:mrow>
																			<mml:mrow>
																				<mml:mn>2</mml:mn>
																			</mml:mrow>
																		</mml:msub>
																	</mml:mrow>
																</mml:msub>
																<mml:mtext>,</mml:mtext>
																<mml:mo>…</mml:mo>
																<mml:mtext>,</mml:mtext>
																<mml:msub>
																	<mml:mrow>
																		<mml:mi mathvariant="bold">x</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:msub>
																			<mml:mrow>
																				<mml:mi>t</mml:mi>
																			</mml:mrow>
																			<mml:mrow>
																				<mml:mi>n</mml:mi>
																			</mml:mrow>
																		</mml:msub>
																	</mml:mrow>
																</mml:msub>
																<mml:mo stretchy="false">)</mml:mo>
															</mml:mrow>
														</mml:math> into a nonlinear expanded space to get the expanded data 
														<mml:math altimg="si33.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
															<mml:mrow>
																<mml:mover accent="true">
																	<mml:mrow>
																		<mml:mi mathvariant="bold">X</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:mo stretchy="true">∼</mml:mo>
																	</mml:mrow>
																</mml:mover>
															</mml:mrow>
														</mml:math>.
													</ce:entry>
												</cals:row>
												<cals:row valign="top">
													<ce:entry>
														<ce:hsp sp="1"/>
														<ce:bold>Step 2:</ce:bold> construct 
														<mml:math altimg="si34.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
															<mml:mrow>
																<mml:mi mathvariant="normal">Δ</mml:mi>
																<mml:mover accent="true">
																	<mml:mrow>
																		<mml:mi mathvariant="bold">X</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:mo stretchy="true">∼</mml:mo>
																	</mml:mrow>
																</mml:mover>
															</mml:mrow>
														</mml:math>.
													</ce:entry>
												</cals:row>
												<cals:row valign="top">
													<ce:entry>
														<ce:hsp sp="1"/>
														<ce:bold>Step 3:</ce:bold> calculate 
														<ce:bold>A</ce:bold> and 
														<ce:bold>B</ce:bold> according to Eqs. 
														<ce:cross-refs refid="e0185 e0190">(13) and (14)</ce:cross-refs>.
													</ce:entry>
												</cals:row>
												<cals:row valign="top">
													<ce:entry>
														<ce:hsp sp="1"/>
														<ce:bold>Step 4:</ce:bold> estimate 
														<ce:bold>W</ce:bold> whose columns are the eigenvectors of 
														<ce:bold>AW</ce:bold>
														<ce:hsp sp="0.25"/>=
														<ce:hsp sp="0.25"/>
														<ce:bold>ΛBW</ce:bold> and order the columns according to the eigenvalues.
													</ce:entry>
												</cals:row>
												<cals:row valign="top">
													<ce:entry>
														<ce:hsp sp="1"/>
														<ce:bold>Step 5:</ce:bold> choose 
														<ce:italic>d</ce:italic> smallest non-zero eigenvalues and the associated eigenvectors 
														<ce:bold>U</ce:bold>
														<ce:hsp sp="0.25"/>=
														<ce:hsp sp="0.25"/>(
														<ce:bold>w</ce:bold>
														<ce:inf loc="post">1</ce:inf>,
														<ce:hsp sp="0.12"/>
														<ce:bold>w</ce:bold>
														<ce:inf loc="post">2</ce:inf>,
														<ce:hsp sp="0.12"/>…
														<ce:hsp sp="0.12"/>,
														<ce:hsp sp="0.12"/>
														<ce:bold>w</ce:bold>
														<ce:inf loc="post">
															<ce:italic>d</ce:italic>
														</ce:inf>), and obtain the 
														<ce:italic>d</ce:italic>-dimensional coordinates by 
														<mml:math altimg="si35.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
															<mml:mrow>
																<mml:mi mathvariant="bold">Y</mml:mi>
																<mml:mo>=</mml:mo>
																<mml:msup>
																	<mml:mrow>
																		<mml:mi mathvariant="bold">U</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:mi>T</mml:mi>
																	</mml:mrow>
																</mml:msup>
																<mml:mover accent="true">
																	<mml:mrow>
																		<mml:mi mathvariant="bold">X</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:mo stretchy="true">∼</mml:mo>
																	</mml:mrow>
																</mml:mover>
															</mml:mrow>
														</mml:math>.
													</ce:entry>
												</cals:row>
											</cals:tbody>
										</cals:tgroup>
									</ce:table>
								</ce:display>
							</ce:para>
						</ce:section>
					</ce:section>
					<ce:section id="s0035" view="all">
						<ce:label>3.2</ce:label>
						<ce:section-title>Algorithm NNP-2</ce:section-title>
						<ce:para id="p0095" view="all">Many problems do not have an obvious temporal structure. The NNP-1 algorithm cannot be directly applied to get temporal variation of the input data. However, we expect to deal with not only time series but also data without a temporal structure using the temporal coherence principle. In order to tackle such a problem, we modify the NNP-1 algorithm to be suitable for this situation. The modified algorithm is named NNP-2. It artificially constructs a large set of short time series with only two nearby points. Then the objective function can be reformulated by ensuring that nearby points are as close as possible in the embedding space.</ce:para>
						<ce:section id="s0040" view="all">
							<ce:label>3.2.1</ce:label>
							<ce:section-title>Definition</ce:section-title>
							<ce:para id="p0100" view="all">The algorithmic procedure is stated as follows.</ce:para>
							<ce:para id="p0105" view="all">Given 
								<mml:math altimg="si36.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:mrow>
										<mml:mi mathvariant="bold">X</mml:mi>
										<mml:mo>=</mml:mo>
										<mml:mo stretchy="false">(</mml:mo>
										<mml:msub>
											<mml:mrow>
												<mml:mi mathvariant="bold">x</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:mn>1</mml:mn>
											</mml:mrow>
										</mml:msub>
										<mml:mtext>,</mml:mtext>
										<mml:msub>
											<mml:mrow>
												<mml:mi mathvariant="bold">x</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:mn>2</mml:mn>
											</mml:mrow>
										</mml:msub>
										<mml:mtext>,</mml:mtext>
										<mml:mo>…</mml:mo>
										<mml:mtext>,</mml:mtext>
										<mml:msub>
											<mml:mrow>
												<mml:mi mathvariant="bold">x</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:mi>n</mml:mi>
											</mml:mrow>
										</mml:msub>
										<mml:mo stretchy="false">)</mml:mo>
										<mml:mtext>,</mml:mtext>
										<mml:mspace width="0.35em"/>
										<mml:msub>
											<mml:mrow>
												<mml:mi mathvariant="bold">x</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:mi>i</mml:mi>
											</mml:mrow>
										</mml:msub>
										<mml:mo>∈</mml:mo>
										<mml:msup>
											<mml:mrow>
												<mml:mi mathvariant="double-struck">R</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:mi>D</mml:mi>
											</mml:mrow>
										</mml:msup>
									</mml:mrow>
								</mml:math>, we first find 
								<ce:italic>k</ce:italic> nearest neighbor points 
								<ce:bold>x</ce:bold>
								<ce:inf loc="post">
									<ce:italic>j</ce:italic>
								</ce:inf>, 
								<ce:italic>j</ce:italic>
								<ce:hsp sp="0.25"/>=
								<ce:hsp sp="0.25"/>1,
								<ce:hsp sp="0.12"/>2,
								<ce:hsp sp="0.12"/>…
								<ce:hsp sp="0.12"/>,
								<ce:hsp sp="0.12"/>
								<ce:italic>k</ce:italic> for each point 
								<ce:bold>x</ce:bold>
								<ce:inf loc="post">
									<ce:italic>i</ce:italic>
								</ce:inf>, and then the objective function aims to keep the neighboring points, 
								<ce:bold>y</ce:bold>
								<ce:inf loc="post">
									<ce:italic>i</ce:italic>
								</ce:inf> and 
								<ce:bold>y</ce:bold>
								<ce:inf loc="post">
									<ce:italic>j</ce:italic>
								</ce:inf>, close in the low dimensional space
								<ce:display>
									<ce:formula id="e0065">
										<ce:label>(16)</ce:label>
										<mml:math altimg="si37.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
											<mml:mrow>
												<mml:mi mathvariant="normal">min</mml:mi>
											</mml:mrow>
											<mml:mi mathvariant="normal">Δ</mml:mi>
											<mml:mi mathvariant="bold">y</mml:mi>
											<mml:mo>=</mml:mo>
											<mml:munderover>
												<mml:mrow>
													<mml:mo>∑</mml:mo>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>i</mml:mi>
													<mml:mo>=</mml:mo>
													<mml:mn>1</mml:mn>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>n</mml:mi>
												</mml:mrow>
											</mml:munderover>
											<mml:munderover>
												<mml:mrow>
													<mml:mo>∑</mml:mo>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>j</mml:mi>
													<mml:mo>=</mml:mo>
													<mml:mn>1</mml:mn>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>k</mml:mi>
												</mml:mrow>
											</mml:munderover>
											<mml:mo stretchy="false">(</mml:mo>
											<mml:msub>
												<mml:mrow>
													<mml:mi mathvariant="bold">y</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>i</mml:mi>
												</mml:mrow>
											</mml:msub>
											<mml:mo>-</mml:mo>
											<mml:msub>
												<mml:mrow>
													<mml:mi mathvariant="bold">y</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>j</mml:mi>
												</mml:mrow>
											</mml:msub>
											<mml:msup>
												<mml:mrow>
													<mml:mo stretchy="false">)</mml:mo>
												</mml:mrow>
												<mml:mrow>
													<mml:mn>2</mml:mn>
												</mml:mrow>
											</mml:msup>
										</mml:math>
									</ce:formula>
								</ce:display>where 
								<ce:bold>y</ce:bold>
								<ce:inf loc="post">
									<ce:italic>i</ce:italic>
								</ce:inf> is the embedding vector for an input data 
								<ce:bold>x</ce:bold>
								<ce:inf loc="post">
									<ce:italic>i</ce:italic>
								</ce:inf>, and 
								<ce:bold>y</ce:bold>
								<ce:inf loc="post">
									<ce:italic>j</ce:italic>
								</ce:inf> is the low dimensional representation of the 
								<ce:italic>j</ce:italic>th nearby point for 
								<ce:bold>x</ce:bold>
								<ce:inf loc="post">
									<ce:italic>i</ce:italic>
								</ce:inf>.
							</ce:para>
							<ce:para id="p0110" view="all">In order to solve this optimization problem, we first construct a large set of short time series with only two nearby points
								<ce:display>
									<ce:formula id="e0070">
										<ce:label>(17)</ce:label>
										<mml:math altimg="si38.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
											<mml:mi mathvariant="bold">S</mml:mi>
											<mml:mo>=</mml:mo>
											<mml:mo stretchy="false">{</mml:mo>
											<mml:msub>
												<mml:mrow>
													<mml:mi mathvariant="bold">x</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>i</mml:mi>
												</mml:mrow>
											</mml:msub>
											<mml:mtext>,</mml:mtext>
											<mml:msub>
												<mml:mrow>
													<mml:mi mathvariant="bold">x</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>j</mml:mi>
												</mml:mrow>
											</mml:msub>
											<mml:mo stretchy="false">}</mml:mo>
											<mml:mtext>,</mml:mtext>
											<mml:mspace width="1em"/>
											<mml:mi>i</mml:mi>
											<mml:mo>=</mml:mo>
											<mml:mn>1</mml:mn>
											<mml:mtext>,</mml:mtext>
											<mml:mn>2</mml:mn>
											<mml:mtext>,</mml:mtext>
											<mml:mo>…</mml:mo>
											<mml:mtext>,</mml:mtext>
											<mml:mi>n</mml:mi>
											<mml:mtext>,</mml:mtext>
											<mml:mspace width="0.35em"/>
											<mml:mi>j</mml:mi>
											<mml:mo>=</mml:mo>
											<mml:mn>1</mml:mn>
											<mml:mtext>,</mml:mtext>
											<mml:mn>2</mml:mn>
											<mml:mtext>,</mml:mtext>
											<mml:mo>…</mml:mo>
											<mml:mtext>,</mml:mtext>
											<mml:mi>k</mml:mi>
										</mml:math>
									</ce:formula>
								</ce:display>where 
								<mml:math altimg="si39.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:mrow>
										<mml:msub>
											<mml:mrow>
												<mml:mi mathvariant="bold">s</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:mn>1</mml:mn>
											</mml:mrow>
										</mml:msub>
										<mml:mtext>,</mml:mtext>
										<mml:msub>
											<mml:mrow>
												<mml:mi mathvariant="bold">s</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:mn>2</mml:mn>
											</mml:mrow>
										</mml:msub>
										<mml:mtext>,</mml:mtext>
										<mml:mo>…</mml:mo>
										<mml:mtext>,</mml:mtext>
										<mml:msub>
											<mml:mrow>
												<mml:mi mathvariant="bold">s</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:mn>2</mml:mn>
												<mml:mo>×</mml:mo>
												<mml:mi>n</mml:mi>
												<mml:mo>×</mml:mo>
												<mml:mi>k</mml:mi>
											</mml:mrow>
										</mml:msub>
										<mml:mo>∈</mml:mo>
										<mml:msup>
											<mml:mrow>
												<mml:mi mathvariant="double-struck">R</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:mi>D</mml:mi>
											</mml:mrow>
										</mml:msup>
									</mml:mrow>
								</mml:math>, and 
								<ce:bold>x</ce:bold>
								<ce:inf loc="post">
									<ce:italic>j</ce:italic>
								</ce:inf> is one of the 
								<ce:italic>k</ce:italic> nearest neighbor points of 
								<ce:bold>x</ce:bold>
								<ce:inf loc="post">
									<ce:italic>i</ce:italic>
								</ce:inf>.
							</ce:para>
							<ce:para id="p0115" view="all">Then, we expand 
								<ce:bold>X</ce:bold>
								<ce:hsp sp="0.25"/>=
								<ce:hsp sp="0.25"/>(
								<ce:bold>x</ce:bold>
								<ce:inf loc="post">1</ce:inf>,
								<ce:hsp sp="0.12"/>
								<ce:bold>x</ce:bold>
								<ce:inf loc="post">2</ce:inf>,
								<ce:hsp sp="0.12"/>…
								<ce:hsp sp="0.12"/>,
								<ce:hsp sp="0.12"/>
								<ce:bold>x</ce:bold>
								<ce:inf loc="post">
									<ce:italic>n</ce:italic>
								</ce:inf>) and 
								<ce:bold>S</ce:bold>
								<ce:hsp sp="0.25"/>=
								<ce:hsp sp="0.25"/>(
								<ce:bold>s</ce:bold>
								<ce:inf loc="post">1</ce:inf>,
								<ce:hsp sp="0.12"/>
								<ce:bold>s</ce:bold>
								<ce:inf loc="post">2</ce:inf>,
								<ce:hsp sp="0.12"/>…
								<ce:hsp sp="0.12"/>,
								<ce:hsp sp="0.12"/>
								<ce:bold>s</ce:bold>
								<ce:inf loc="post">2×
									<ce:italic>n</ce:italic>×
									<ce:italic>k</ce:italic>
								</ce:inf>) by introducing a set of nonlinear functions to get the expanded data 
								<mml:math altimg="si40.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:mrow>
										<mml:mover accent="true">
											<mml:mrow>
												<mml:mi mathvariant="bold">X</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:mo stretchy="true">∼</mml:mo>
											</mml:mrow>
										</mml:mover>
									</mml:mrow>
								</mml:math> and 
								<mml:math altimg="si41.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:mrow>
										<mml:mover accent="true">
											<mml:mrow>
												<mml:mi mathvariant="bold">S</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:mo stretchy="true">∼</mml:mo>
											</mml:mrow>
										</mml:mover>
									</mml:mrow>
								</mml:math>, respectively.
							</ce:para>
							<ce:para id="p0120" view="all">For the “time series”
								<mml:math altimg="si42.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:mrow>
										<mml:mover accent="true">
											<mml:mrow>
												<mml:mi mathvariant="bold">S</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:mo stretchy="true">∼</mml:mo>
											</mml:mrow>
										</mml:mover>
									</mml:mrow>
								</mml:math>, we calculate the “temporal variation”
								<mml:math altimg="si43.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:mrow>
										<mml:mi mathvariant="normal">Δ</mml:mi>
										<mml:mover accent="true">
											<mml:mrow>
												<mml:mi mathvariant="bold">S</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:mo stretchy="true">∼</mml:mo>
											</mml:mrow>
										</mml:mover>
									</mml:mrow>
								</mml:math> by approximating the “time difference”, where
								<ce:display>
									<ce:formula id="e0075">
										<ce:label>(18)</ce:label>
										<mml:math altimg="si44.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
											<mml:mi mathvariant="normal">Δ</mml:mi>
											<mml:msub>
												<mml:mrow>
													<mml:mover accent="true">
														<mml:mrow>
															<mml:mi mathvariant="bold">s</mml:mi>
														</mml:mrow>
														<mml:mrow>
															<mml:mo>˜</mml:mo>
														</mml:mrow>
													</mml:mover>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>i</mml:mi>
												</mml:mrow>
											</mml:msub>
											<mml:mo>=</mml:mo>
											<mml:msub>
												<mml:mrow>
													<mml:mover accent="true">
														<mml:mrow>
															<mml:mi mathvariant="bold">s</mml:mi>
														</mml:mrow>
														<mml:mrow>
															<mml:mo>˜</mml:mo>
														</mml:mrow>
													</mml:mover>
												</mml:mrow>
												<mml:mrow>
													<mml:mn>2</mml:mn>
													<mml:mi>i</mml:mi>
												</mml:mrow>
											</mml:msub>
											<mml:mo>-</mml:mo>
											<mml:msub>
												<mml:mrow>
													<mml:mover accent="true">
														<mml:mrow>
															<mml:mi mathvariant="bold">s</mml:mi>
														</mml:mrow>
														<mml:mrow>
															<mml:mo>˜</mml:mo>
														</mml:mrow>
													</mml:mover>
												</mml:mrow>
												<mml:mrow>
													<mml:mn>2</mml:mn>
													<mml:mi>i</mml:mi>
													<mml:mo>-</mml:mo>
													<mml:mn>1</mml:mn>
												</mml:mrow>
											</mml:msub>
											<mml:mtext>,</mml:mtext>
											<mml:mspace width="1em"/>
											<mml:mi>i</mml:mi>
											<mml:mo>=</mml:mo>
											<mml:mn>1</mml:mn>
											<mml:mtext>,</mml:mtext>
											<mml:mn>2</mml:mn>
											<mml:mtext>,</mml:mtext>
											<mml:mo>…</mml:mo>
											<mml:mtext>,</mml:mtext>
											<mml:mi>n</mml:mi>
											<mml:mo>×</mml:mo>
											<mml:mi>k</mml:mi>
										</mml:math>
									</ce:formula>
								</ce:display>Given 
								<mml:math altimg="si45.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:mrow>
										<mml:mi mathvariant="bold">Y</mml:mi>
										<mml:mo>=</mml:mo>
										<mml:msup>
											<mml:mrow>
												<mml:mi mathvariant="bold">W</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:mi>T</mml:mi>
											</mml:mrow>
										</mml:msup>
										<mml:mover accent="true">
											<mml:mrow>
												<mml:mi mathvariant="bold">X</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:mo stretchy="true">∼</mml:mo>
											</mml:mrow>
										</mml:mover>
									</mml:mrow>
								</mml:math>, the objective function 
								<ce:cross-ref refid="e0065">(16)</ce:cross-ref> can be reformulated as
								<ce:display>
									<ce:formula id="e0080">
										<ce:label>(19)</ce:label>
										<mml:math altimg="si46.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
											<mml:mi mathvariant="normal">Δ</mml:mi>
											<mml:mi mathvariant="bold">y</mml:mi>
											<mml:mo>=</mml:mo>
											<mml:munderover>
												<mml:mrow>
													<mml:mo>∑</mml:mo>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>i</mml:mi>
													<mml:mo>=</mml:mo>
													<mml:mn>1</mml:mn>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>n</mml:mi>
												</mml:mrow>
											</mml:munderover>
											<mml:munderover>
												<mml:mrow>
													<mml:mo>∑</mml:mo>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>j</mml:mi>
													<mml:mo>=</mml:mo>
													<mml:mn>1</mml:mn>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>k</mml:mi>
												</mml:mrow>
											</mml:munderover>
											<mml:mo stretchy="false">(</mml:mo>
											<mml:msub>
												<mml:mrow>
													<mml:mi mathvariant="bold">y</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>i</mml:mi>
												</mml:mrow>
											</mml:msub>
											<mml:mo>-</mml:mo>
											<mml:msub>
												<mml:mrow>
													<mml:mi mathvariant="bold">y</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>j</mml:mi>
												</mml:mrow>
											</mml:msub>
											<mml:msup>
												<mml:mrow>
													<mml:mo stretchy="false">)</mml:mo>
												</mml:mrow>
												<mml:mrow>
													<mml:mn>2</mml:mn>
												</mml:mrow>
											</mml:msup>
											<mml:mo>=</mml:mo>
											<mml:mi mathvariant="italic">tr</mml:mi>
											<mml:mrow>
												<mml:mfenced open="(" close=")">
													<mml:mrow>
														<mml:munderover>
															<mml:mrow>
																<mml:mo>∑</mml:mo>
															</mml:mrow>
															<mml:mrow>
																<mml:mi>i</mml:mi>
																<mml:mo>=</mml:mo>
																<mml:mn>1</mml:mn>
															</mml:mrow>
															<mml:mrow>
																<mml:mi>n</mml:mi>
															</mml:mrow>
														</mml:munderover>
														<mml:munderover>
															<mml:mrow>
																<mml:mo>∑</mml:mo>
															</mml:mrow>
															<mml:mrow>
																<mml:mi>j</mml:mi>
																<mml:mo>=</mml:mo>
																<mml:mn>1</mml:mn>
															</mml:mrow>
															<mml:mrow>
																<mml:mi>k</mml:mi>
															</mml:mrow>
														</mml:munderover>
														<mml:mo stretchy="false">(</mml:mo>
														<mml:msup>
															<mml:mrow>
																<mml:mi mathvariant="bold">W</mml:mi>
															</mml:mrow>
															<mml:mrow>
																<mml:mi>T</mml:mi>
															</mml:mrow>
														</mml:msup>
														<mml:msub>
															<mml:mrow>
																<mml:mover accent="true">
																	<mml:mrow>
																		<mml:mi mathvariant="bold">x</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:mo>˜</mml:mo>
																	</mml:mrow>
																</mml:mover>
															</mml:mrow>
															<mml:mrow>
																<mml:mi>i</mml:mi>
															</mml:mrow>
														</mml:msub>
														<mml:mo>-</mml:mo>
														<mml:mi mathvariant="bold">W</mml:mi>
														<mml:msub>
															<mml:mrow>
																<mml:mover accent="true">
																	<mml:mrow>
																		<mml:mi mathvariant="bold">x</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:mo>˜</mml:mo>
																	</mml:mrow>
																</mml:mover>
															</mml:mrow>
															<mml:mrow>
																<mml:mi>j</mml:mi>
															</mml:mrow>
														</mml:msub>
														<mml:msup>
															<mml:mrow>
																<mml:mo stretchy="false">)</mml:mo>
															</mml:mrow>
															<mml:mrow>
																<mml:mn>2</mml:mn>
															</mml:mrow>
														</mml:msup>
													</mml:mrow>
												</mml:mfenced>
											</mml:mrow>
											<mml:mo>=</mml:mo>
											<mml:mi mathvariant="italic">tr</mml:mi>
											<mml:mrow>
												<mml:mfenced open="(" close=")">
													<mml:mrow>
														<mml:munderover>
															<mml:mrow>
																<mml:mo>∑</mml:mo>
															</mml:mrow>
															<mml:mrow>
																<mml:mi>i</mml:mi>
																<mml:mo>=</mml:mo>
																<mml:mn>1</mml:mn>
															</mml:mrow>
															<mml:mrow>
																<mml:mi>n</mml:mi>
															</mml:mrow>
														</mml:munderover>
														<mml:munderover>
															<mml:mrow>
																<mml:mo>∑</mml:mo>
															</mml:mrow>
															<mml:mrow>
																<mml:mi>j</mml:mi>
																<mml:mo>=</mml:mo>
																<mml:mn>1</mml:mn>
															</mml:mrow>
															<mml:mrow>
																<mml:mi>k</mml:mi>
															</mml:mrow>
														</mml:munderover>
														<mml:mo stretchy="false">(</mml:mo>
														<mml:msup>
															<mml:mrow>
																<mml:mi mathvariant="bold">W</mml:mi>
															</mml:mrow>
															<mml:mrow>
																<mml:mi>T</mml:mi>
															</mml:mrow>
														</mml:msup>
														<mml:mo stretchy="false">(</mml:mo>
														<mml:msub>
															<mml:mrow>
																<mml:mover accent="true">
																	<mml:mrow>
																		<mml:mi mathvariant="bold">x</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:mo>˜</mml:mo>
																	</mml:mrow>
																</mml:mover>
															</mml:mrow>
															<mml:mrow>
																<mml:mi>i</mml:mi>
															</mml:mrow>
														</mml:msub>
														<mml:mo>-</mml:mo>
														<mml:msub>
															<mml:mrow>
																<mml:mover accent="true">
																	<mml:mrow>
																		<mml:mi mathvariant="bold">x</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:mo>˜</mml:mo>
																	</mml:mrow>
																</mml:mover>
															</mml:mrow>
															<mml:mrow>
																<mml:mi>j</mml:mi>
															</mml:mrow>
														</mml:msub>
														<mml:mo stretchy="false">)</mml:mo>
														<mml:msup>
															<mml:mrow>
																<mml:mo stretchy="false">)</mml:mo>
															</mml:mrow>
															<mml:mrow>
																<mml:mn>2</mml:mn>
															</mml:mrow>
														</mml:msup>
													</mml:mrow>
												</mml:mfenced>
											</mml:mrow>
											<mml:mo>=</mml:mo>
											<mml:mi mathvariant="italic">tr</mml:mi>
											<mml:mrow>
												<mml:mfenced open="(" close=")">
													<mml:mrow>
														<mml:msup>
															<mml:mrow>
																<mml:mi mathvariant="bold">W</mml:mi>
															</mml:mrow>
															<mml:mrow>
																<mml:mi>T</mml:mi>
															</mml:mrow>
														</mml:msup>
														<mml:munderover>
															<mml:mrow>
																<mml:mo>∑</mml:mo>
															</mml:mrow>
															<mml:mrow>
																<mml:mi>i</mml:mi>
																<mml:mo>=</mml:mo>
																<mml:mn>1</mml:mn>
															</mml:mrow>
															<mml:mrow>
																<mml:mi>n</mml:mi>
																<mml:mo>×</mml:mo>
																<mml:mi>k</mml:mi>
															</mml:mrow>
														</mml:munderover>
														<mml:mo stretchy="false">(</mml:mo>
														<mml:mi mathvariant="normal">Δ</mml:mi>
														<mml:msub>
															<mml:mrow>
																<mml:mover accent="true">
																	<mml:mrow>
																		<mml:mi mathvariant="bold">s</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:mo>˜</mml:mo>
																	</mml:mrow>
																</mml:mover>
															</mml:mrow>
															<mml:mrow>
																<mml:mi>i</mml:mi>
															</mml:mrow>
														</mml:msub>
														<mml:msup>
															<mml:mrow>
																<mml:mo stretchy="false">)</mml:mo>
															</mml:mrow>
															<mml:mrow>
																<mml:mn>2</mml:mn>
															</mml:mrow>
														</mml:msup>
														<mml:mi mathvariant="bold">W</mml:mi>
													</mml:mrow>
												</mml:mfenced>
											</mml:mrow>
											<mml:mo>=</mml:mo>
											<mml:mi mathvariant="italic">tr</mml:mi>
											<mml:mo stretchy="false">(</mml:mo>
											<mml:msup>
												<mml:mrow>
													<mml:mi mathvariant="bold">W</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>T</mml:mi>
												</mml:mrow>
											</mml:msup>
											<mml:mi mathvariant="normal">Δ</mml:mi>
											<mml:mover accent="true">
												<mml:mrow>
													<mml:mi mathvariant="bold">S</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mo stretchy="true">∼</mml:mo>
												</mml:mrow>
											</mml:mover>
											<mml:mi mathvariant="normal">Δ</mml:mi>
											<mml:msup>
												<mml:mrow>
													<mml:mover accent="true">
														<mml:mrow>
															<mml:mi mathvariant="bold">S</mml:mi>
														</mml:mrow>
														<mml:mrow>
															<mml:mo stretchy="true">∼</mml:mo>
														</mml:mrow>
													</mml:mover>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>T</mml:mi>
												</mml:mrow>
											</mml:msup>
											<mml:mi mathvariant="bold">W</mml:mi>
											<mml:mo stretchy="false">)</mml:mo>
										</mml:math>
									</ce:formula>
								</ce:display>In order to solve the above problem, we can also use the zero mean and unit variance constraints that the NNP-1 algorithm uses:
								<ce:display>
									<ce:formula id="e0085">
										<ce:label>(20)</ce:label>
										<mml:math altimg="si47.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
											<mml:mtable columnspacing="0em">
												<mml:mtr>
													<mml:mtd columnalign="right"/>
													<mml:mtd columnalign="left">
														<mml:mrow>
															<mml:mi>E</mml:mi>
															<mml:mo stretchy="false">(</mml:mo>
															<mml:mi mathvariant="bold">Y</mml:mi>
															<mml:mo stretchy="false">)</mml:mo>
															<mml:mo>=</mml:mo>
															<mml:mn>0</mml:mn>
														</mml:mrow>
													</mml:mtd>
												</mml:mtr>
												<mml:mtr>
													<mml:mtd columnalign="right"/>
													<mml:mtd columnalign="left">
														<mml:mrow>
															<mml:mi>E</mml:mi>
															<mml:mo stretchy="false">(</mml:mo>
															<mml:msup>
																<mml:mrow>
																	<mml:mi mathvariant="bold">YY</mml:mi>
																</mml:mrow>
																<mml:mrow>
																	<mml:mi>T</mml:mi>
																</mml:mrow>
															</mml:msup>
															<mml:mo stretchy="false">)</mml:mo>
															<mml:mo>=</mml:mo>
															<mml:mi mathvariant="bold">I</mml:mi>
														</mml:mrow>
													</mml:mtd>
												</mml:mtr>
											</mml:mtable>
										</mml:math>
									</ce:formula>
								</ce:display>Then, the minimization problem is equal to
								<ce:display>
									<ce:formula id="e0090">
										<ce:label>(21)</ce:label>
										<mml:math altimg="si48.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
											<mml:munder>
												<mml:mrow>
													<mml:mi mathvariant="normal">arg</mml:mi>
													<mml:mspace width="0.12em"/>
													<mml:mi mathvariant="normal">min</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mi mathvariant="bold">W</mml:mi>
												</mml:mrow>
											</mml:munder>
											<mml:mfrac>
												<mml:mrow>
													<mml:msup>
														<mml:mrow>
															<mml:mi mathvariant="bold">W</mml:mi>
														</mml:mrow>
														<mml:mrow>
															<mml:mi>T</mml:mi>
														</mml:mrow>
													</mml:msup>
													<mml:mi mathvariant="bold">CW</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:msup>
														<mml:mrow>
															<mml:mi mathvariant="bold">W</mml:mi>
														</mml:mrow>
														<mml:mrow>
															<mml:mi>T</mml:mi>
														</mml:mrow>
													</mml:msup>
													<mml:mi mathvariant="bold">BW</mml:mi>
												</mml:mrow>
											</mml:mfrac>
										</mml:math>
									</ce:formula>
								</ce:display>where
								<ce:display>
									<ce:formula id="e0200">
										<ce:label>(22)</ce:label>
										<mml:math altimg="si49.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
											<mml:mi mathvariant="bold">C</mml:mi>
											<mml:mo>=</mml:mo>
											<mml:mi mathvariant="normal">Δ</mml:mi>
											<mml:mover accent="true">
												<mml:mrow>
													<mml:mi mathvariant="bold">S</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mo stretchy="true">∼</mml:mo>
												</mml:mrow>
											</mml:mover>
											<mml:mi mathvariant="normal">Δ</mml:mi>
											<mml:msup>
												<mml:mrow>
													<mml:mover accent="true">
														<mml:mrow>
															<mml:mi mathvariant="bold">S</mml:mi>
														</mml:mrow>
														<mml:mrow>
															<mml:mo stretchy="true">∼</mml:mo>
														</mml:mrow>
													</mml:mover>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>T</mml:mi>
												</mml:mrow>
											</mml:msup>
										</mml:math>
									</ce:formula>
								</ce:display>
								<ce:display>
									<ce:formula id="e0205">
										<ce:label>(23)</ce:label>
										<mml:math altimg="si50.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
											<mml:mi mathvariant="bold">B</mml:mi>
											<mml:mo>=</mml:mo>
											<mml:mover accent="true">
												<mml:mrow>
													<mml:mi mathvariant="bold">X</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mo stretchy="true">∼</mml:mo>
												</mml:mrow>
											</mml:mover>
											<mml:msup>
												<mml:mrow>
													<mml:mover accent="true">
														<mml:mrow>
															<mml:mi mathvariant="bold">X</mml:mi>
														</mml:mrow>
														<mml:mrow>
															<mml:mo stretchy="true">∼</mml:mo>
														</mml:mrow>
													</mml:mover>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>T</mml:mi>
												</mml:mrow>
											</mml:msup>
										</mml:math>
									</ce:formula>
								</ce:display>Let 
								<ce:bold>W</ce:bold>
								<ce:hsp sp="0.25"/>=
								<ce:hsp sp="0.25"/>(
								<ce:bold>w</ce:bold>
								<ce:inf loc="post">1</ce:inf>,
								<ce:hsp sp="0.12"/>
								<ce:bold>w</ce:bold>
								<ce:inf loc="post">2</ce:inf>,
								<ce:hsp sp="0.12"/>…
								<ce:hsp sp="0.12"/>,
								<ce:hsp sp="0.12"/>
								<ce:bold>w</ce:bold>
								<ce:inf loc="post">
									<ce:italic>D</ce:italic>
								</ce:inf>) be the solutions of Eq. 
								<ce:cross-ref refid="e0090">(21)</ce:cross-ref>. We order 
								<ce:bold>w</ce:bold>
								<ce:inf loc="post">1…
									<ce:italic>D</ce:italic>
								</ce:inf> according to their eigenvalues. Then, we choose 
								<ce:italic>d</ce:italic> smallest non-zero eigenvalues and the associated 
								<ce:italic>d</ce:italic> eigenvectors 
								<ce:bold>U</ce:bold>
								<ce:hsp sp="0.25"/>=
								<ce:hsp sp="0.25"/>(
								<ce:bold>w</ce:bold>
								<ce:inf loc="post">1</ce:inf>,
								<ce:hsp sp="0.12"/>
								<ce:bold>w</ce:bold>
								<ce:inf loc="post">2</ce:inf>,
								<ce:hsp sp="0.12"/>…
								<ce:hsp sp="0.12"/>,
								<ce:hsp sp="0.12"/>
								<ce:bold>w</ce:bold>
								<ce:inf loc="post">
									<ce:italic>d</ce:italic>
								</ce:inf>). The low 
								<ce:italic>d</ce:italic>-dimensional coordinates 
								<ce:bold>y</ce:bold>
								<ce:inf loc="post">
									<ce:italic>i</ce:italic>
								</ce:inf> for the input data 
								<ce:bold>x</ce:bold>
								<ce:inf loc="post">
									<ce:italic>i</ce:italic>
								</ce:inf> are estimated by 
								<ce:bold>y</ce:bold>
								<ce:inf loc="post">
									<ce:italic>i</ce:italic>
								</ce:inf>
								<ce:hsp sp="0.25"/>=
								<ce:hsp sp="0.25"/>
								<ce:bold>U</ce:bold>
								<ce:sup loc="post">
									<ce:italic>T</ce:italic>
								</ce:sup>
								<ce:bold>x</ce:bold>
								<ce:inf loc="post">
									<ce:italic>i</ce:italic>
								</ce:inf>.
							</ce:para>
						</ce:section>
						<ce:section id="s0045" view="all">
							<ce:label>3.2.2</ce:label>
							<ce:section-title>Algorithm summarization</ce:section-title>
							<ce:para id="p0125" view="all">The NNP-2 algorithm for data without an obvious temporal structure is summarized as follows.
								<ce:display>
									<ce:table frame="topbot" id="t0030" rowsep="0" colsep="0">
										<cals:tgroup cols="1" xmlns:cals="http://www.elsevier.com/xml/common/cals/schema">
											<cals:colspec colname="col1" align="left"/>
											<cals:thead>
												<cals:row rowsep="1" valign="top">
													<ce:entry>
														<ce:bold>Algorithm NNP-2</ce:bold>
													</ce:entry>
												</cals:row>
											</cals:thead>
											<cals:tbody>
												<cals:row valign="top">
													<ce:entry>
														<ce:bold>Input:</ce:bold>
														<mml:math altimg="si51.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
															<mml:mrow>
																<mml:mi mathvariant="bold">X</mml:mi>
																<mml:mo>=</mml:mo>
																<mml:mo stretchy="false">(</mml:mo>
																<mml:msub>
																	<mml:mrow>
																		<mml:mi mathvariant="bold">x</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:mn>1</mml:mn>
																	</mml:mrow>
																</mml:msub>
																<mml:mtext>,</mml:mtext>
																<mml:msub>
																	<mml:mrow>
																		<mml:mi mathvariant="bold">x</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:mn>2</mml:mn>
																	</mml:mrow>
																</mml:msub>
																<mml:mtext>,</mml:mtext>
																<mml:mo>…</mml:mo>
																<mml:mtext>,</mml:mtext>
																<mml:msub>
																	<mml:mrow>
																		<mml:mi mathvariant="bold">x</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:mi>n</mml:mi>
																	</mml:mrow>
																</mml:msub>
																<mml:mo stretchy="false">)</mml:mo>
																<mml:mtext>,</mml:mtext>
																<mml:mspace width="0.35em"/>
																<mml:msub>
																	<mml:mrow>
																		<mml:mi mathvariant="bold">x</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:mi>i</mml:mi>
																	</mml:mrow>
																</mml:msub>
																<mml:mo>∈</mml:mo>
																<mml:msup>
																	<mml:mrow>
																		<mml:mi mathvariant="double-struck">R</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:mi>D</mml:mi>
																	</mml:mrow>
																</mml:msup>
															</mml:mrow>
														</mml:math>
													</ce:entry>
												</cals:row>
												<cals:row valign="top">
													<ce:entry>
														<ce:hsp sp="1"/>
														<ce:bold>Step 1:</ce:bold> find 
														<ce:italic>k</ce:italic> nearest neighbor points for each 
														<ce:bold>x</ce:bold>
														<ce:inf loc="post">
															<ce:italic>i</ce:italic>
														</ce:inf>.
													</ce:entry>
												</cals:row>
												<cals:row valign="top">
													<ce:entry>
														<ce:hsp sp="1"/>
														<ce:bold>Step 2:</ce:bold> construct 
														<ce:bold>S</ce:bold> consisting of neighboring points.
													</ce:entry>
												</cals:row>
												<cals:row valign="top">
													<ce:entry>
														<ce:hsp sp="1"/>
														<ce:bold>Step 3:</ce:bold> expand 
														<ce:bold>X</ce:bold> and 
														<ce:bold>S</ce:bold> into a nonlinear expanded space to get the expanded data 
														<mml:math altimg="si52.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
															<mml:mrow>
																<mml:mover accent="true">
																	<mml:mrow>
																		<mml:mi mathvariant="bold">X</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:mo stretchy="true">∼</mml:mo>
																	</mml:mrow>
																</mml:mover>
															</mml:mrow>
														</mml:math> and 
														<mml:math altimg="si53.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
															<mml:mrow>
																<mml:mover accent="true">
																	<mml:mrow>
																		<mml:mi mathvariant="bold">S</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:mo stretchy="true">∼</mml:mo>
																	</mml:mrow>
																</mml:mover>
															</mml:mrow>
														</mml:math>, respectively.
													</ce:entry>
												</cals:row>
												<cals:row valign="top">
													<ce:entry>
														<ce:hsp sp="1"/>
														<ce:bold>Step 4:</ce:bold> estimate the time difference 
														<mml:math altimg="si54.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
															<mml:mrow>
																<mml:mi mathvariant="normal">Δ</mml:mi>
																<mml:mover accent="true">
																	<mml:mrow>
																		<mml:mi mathvariant="bold">S</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:mo stretchy="true">∼</mml:mo>
																	</mml:mrow>
																</mml:mover>
															</mml:mrow>
														</mml:math>.
													</ce:entry>
												</cals:row>
												<cals:row valign="top">
													<ce:entry>
														<ce:hsp sp="1"/>
														<ce:bold>Step 5:</ce:bold> calculate 
														<ce:bold>C</ce:bold> and 
														<ce:bold>B</ce:bold> according to Eqs. 
														<ce:cross-refs refid="e0200 e0205">(22) and (23)</ce:cross-refs>.
													</ce:entry>
												</cals:row>
												<cals:row valign="top">
													<ce:entry>
														<ce:hsp sp="1"/>
														<ce:bold>Step 6:</ce:bold> estimate 
														<ce:bold>W</ce:bold> whose columns are the eigenvectors of 
														<ce:bold>CW</ce:bold>
														<ce:hsp sp="0.25"/>=
														<ce:hsp sp="0.25"/>
														<ce:bold>ΛBW</ce:bold> and order the columns according to the eigenvalues.
													</ce:entry>
												</cals:row>
												<cals:row valign="top">
													<ce:entry>
														<ce:hsp sp="1"/>
														<ce:bold>Step 7:</ce:bold> choose 
														<ce:italic>d</ce:italic> smallest non-zero eigenvalues and the associated eigenvectors 
														<ce:bold>U</ce:bold>
														<ce:hsp sp="0.25"/>=
														<ce:hsp sp="0.25"/>(
														<ce:bold>w</ce:bold>
														<ce:inf loc="post">1</ce:inf>,
														<ce:hsp sp="0.12"/>
														<ce:bold>w</ce:bold>
														<ce:inf loc="post">2</ce:inf>,
														<ce:hsp sp="0.12"/>…
														<ce:hsp sp="0.12"/>,
														<ce:hsp sp="0.12"/>
														<ce:bold>w</ce:bold>
														<ce:inf loc="post">
															<ce:italic>d</ce:italic>
														</ce:inf>), and obtain the 
														<ce:italic>d</ce:italic>-dimensional coordinates by 
														<mml:math altimg="si55.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
															<mml:mrow>
																<mml:mi mathvariant="bold">Y</mml:mi>
																<mml:mo>=</mml:mo>
																<mml:msup>
																	<mml:mrow>
																		<mml:mi mathvariant="bold">U</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:mi>T</mml:mi>
																	</mml:mrow>
																</mml:msup>
																<mml:mover accent="true">
																	<mml:mrow>
																		<mml:mi mathvariant="bold">X</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:mo stretchy="true">∼</mml:mo>
																	</mml:mrow>
																</mml:mover>
															</mml:mrow>
														</mml:math>.
													</ce:entry>
												</cals:row>
											</cals:tbody>
										</cals:tgroup>
									</ce:table>
								</ce:display>
							</ce:para>
						</ce:section>
					</ce:section>
					<ce:section id="s0050" view="all">
						<ce:label>3.3</ce:label>
						<ce:section-title>Algorithm NNP-3</ce:section-title>
						<ce:para id="p0130" view="all">The NNP-2 Algorithm can deal with data without a temporal structure, but its objective function is only to minimize the neighboring points and the remaining points are not considered. For example, for the non-uniform sampling data shown by “Gaussian randomly sampled” in Section 
							<ce:cross-ref refid="s0090">5.2.2</ce:cross-ref>, this criterion cannot guarantee to yield a good mapping. Therefore, we need to modify the objective function to find a suitable mapping which can minimize the distances of neighboring points in the embedding space, and ensure the remaining points are as far apart as possible simultaneously. Furthermore, the modified algorithm, named NNP-3, is also suitable for classification and pattern recognition tasks due to its ability to preserve the discriminatory information.
						</ce:para>
						<ce:section id="s0055" view="all">
							<ce:label>3.3.1</ce:label>
							<ce:section-title>Definition</ce:section-title>
							<ce:para id="p0135" view="all">The NNP-3 algorithm is described as follows:</ce:para>
							<ce:para id="p0140" view="all">First, being similar to the NNP-2 algorithm, given 
								<mml:math altimg="si56.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:mrow>
										<mml:mi mathvariant="bold">X</mml:mi>
										<mml:mo>=</mml:mo>
										<mml:mo stretchy="false">(</mml:mo>
										<mml:msub>
											<mml:mrow>
												<mml:mi mathvariant="bold">x</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:mn>1</mml:mn>
											</mml:mrow>
										</mml:msub>
										<mml:mtext>,</mml:mtext>
										<mml:msub>
											<mml:mrow>
												<mml:mi mathvariant="bold">x</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:mn>2</mml:mn>
											</mml:mrow>
										</mml:msub>
										<mml:mtext>,</mml:mtext>
										<mml:mo>…</mml:mo>
										<mml:mtext>,</mml:mtext>
										<mml:msub>
											<mml:mrow>
												<mml:mi mathvariant="bold">x</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:mi>n</mml:mi>
											</mml:mrow>
										</mml:msub>
										<mml:mo stretchy="false">)</mml:mo>
										<mml:mtext>,</mml:mtext>
										<mml:mspace width="0.35em"/>
										<mml:msub>
											<mml:mrow>
												<mml:mi mathvariant="bold">x</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:mi>i</mml:mi>
											</mml:mrow>
										</mml:msub>
										<mml:mo>∈</mml:mo>
										<mml:msup>
											<mml:mrow>
												<mml:mi mathvariant="double-struck">R</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:mi>D</mml:mi>
											</mml:mrow>
										</mml:msup>
									</mml:mrow>
								</mml:math>, we find 
								<ce:italic>k</ce:italic> nearest neighbor points 
								<ce:bold>x</ce:bold>
								<ce:inf loc="post">
									<ce:italic>j</ce:italic>
								</ce:inf> for each point 
								<ce:bold>x</ce:bold>
								<ce:inf loc="post">
									<ce:italic>i</ce:italic>
								</ce:inf>, and construct 
								<ce:bold>S</ce:bold> consisting of neighboring points.
							</ce:para>
							<ce:para id="p0145" view="all">Then, we find 
								<ce:italic>m</ce:italic> farthest points 
								<ce:bold>x</ce:bold>
								<ce:inf loc="post">
									<ce:italic>l</ce:italic>
								</ce:inf>, 
								<ce:italic>l</ce:italic>
								<ce:hsp sp="0.25"/>=
								<ce:hsp sp="0.25"/>1,
								<ce:hsp sp="0.12"/>2,
								<ce:hsp sp="0.12"/>…
								<ce:hsp sp="0.12"/>,
								<ce:hsp sp="0.12"/>
								<ce:italic>m</ce:italic> for each point 
								<ce:bold>x</ce:bold>
								<ce:inf loc="post">
									<ce:italic>i</ce:italic>
								</ce:inf>. Each point and its 
								<ce:italic>m</ce:italic> farthest points generate 
								<ce:bold>F</ce:bold>:
								<ce:display>
									<ce:formula id="e0095">
										<ce:label>(24)</ce:label>
										<mml:math altimg="si57.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
											<mml:mi mathvariant="bold">F</mml:mi>
											<mml:mo>=</mml:mo>
											<mml:mo stretchy="false">{</mml:mo>
											<mml:msub>
												<mml:mrow>
													<mml:mi mathvariant="bold">x</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>i</mml:mi>
												</mml:mrow>
											</mml:msub>
											<mml:mtext>,</mml:mtext>
											<mml:msub>
												<mml:mrow>
													<mml:mi mathvariant="bold">x</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>l</mml:mi>
												</mml:mrow>
											</mml:msub>
											<mml:mo stretchy="false">}</mml:mo>
											<mml:mtext>,</mml:mtext>
											<mml:mspace width="1em"/>
											<mml:mi>i</mml:mi>
											<mml:mo>=</mml:mo>
											<mml:mn>1</mml:mn>
											<mml:mtext>,</mml:mtext>
											<mml:mn>2</mml:mn>
											<mml:mtext>,</mml:mtext>
											<mml:mo>…</mml:mo>
											<mml:mtext>,</mml:mtext>
											<mml:mi>n</mml:mi>
											<mml:mtext>,</mml:mtext>
											<mml:mspace width="0.35em"/>
											<mml:mi>l</mml:mi>
											<mml:mo>=</mml:mo>
											<mml:mn>1</mml:mn>
											<mml:mtext>,</mml:mtext>
											<mml:mn>2</mml:mn>
											<mml:mtext>,</mml:mtext>
											<mml:mo>…</mml:mo>
											<mml:mtext>,</mml:mtext>
											<mml:mi>m</mml:mi>
										</mml:math>
									</ce:formula>
								</ce:display>
							</ce:para>
							<ce:para id="p0150" view="all">After an expansion procedure, 
								<ce:bold>X</ce:bold>, 
								<ce:bold>S</ce:bold> and 
								<ce:bold>F</ce:bold> are expanded to 
								<mml:math altimg="si58.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:mrow>
										<mml:mover accent="true">
											<mml:mrow>
												<mml:mi mathvariant="bold">X</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:mo stretchy="true">∼</mml:mo>
											</mml:mrow>
										</mml:mover>
										<mml:mtext>,</mml:mtext>
										<mml:mspace width="0.35em"/>
										<mml:mover accent="true">
											<mml:mrow>
												<mml:mi mathvariant="bold">S</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:mo stretchy="true">∼</mml:mo>
											</mml:mrow>
										</mml:mover>
										<mml:mtext>,</mml:mtext>
										<mml:mspace width="0.35em"/>
										<mml:mover accent="true">
											<mml:mrow>
												<mml:mi mathvariant="bold">F</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:mo stretchy="true">∼</mml:mo>
											</mml:mrow>
										</mml:mover>
									</mml:mrow>
								</mml:math>, respectively.
							</ce:para>
							<ce:para id="p0155" view="all">For 
								<mml:math altimg="si59.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:mrow>
										<mml:mover accent="true">
											<mml:mrow>
												<mml:mi mathvariant="bold">F</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:mo stretchy="true">∼</mml:mo>
											</mml:mrow>
										</mml:mover>
									</mml:mrow>
								</mml:math>, we also calculate the “temporal variation”
								<mml:math altimg="si60.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:mrow>
										<mml:mi mathvariant="normal">Δ</mml:mi>
										<mml:mover accent="true">
											<mml:mrow>
												<mml:mi mathvariant="bold">F</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:mo stretchy="true">∼</mml:mo>
											</mml:mrow>
										</mml:mover>
									</mml:mrow>
								</mml:math> by approximating the “time difference”, where
								<ce:display>
									<ce:formula id="e0100">
										<ce:label>(25)</ce:label>
										<mml:math altimg="si61.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
											<mml:mi mathvariant="normal">Δ</mml:mi>
											<mml:mover accent="true">
												<mml:mrow>
													<mml:msub>
														<mml:mrow>
															<mml:mi mathvariant="bold">f</mml:mi>
														</mml:mrow>
														<mml:mrow>
															<mml:mi>i</mml:mi>
														</mml:mrow>
													</mml:msub>
												</mml:mrow>
												<mml:mrow>
													<mml:mo>˜</mml:mo>
												</mml:mrow>
											</mml:mover>
											<mml:mo>=</mml:mo>
											<mml:msub>
												<mml:mrow>
													<mml:mover accent="true">
														<mml:mrow>
															<mml:mi mathvariant="bold">f</mml:mi>
														</mml:mrow>
														<mml:mrow>
															<mml:mo>˜</mml:mo>
														</mml:mrow>
													</mml:mover>
												</mml:mrow>
												<mml:mrow>
													<mml:mn>2</mml:mn>
													<mml:mi>i</mml:mi>
												</mml:mrow>
											</mml:msub>
											<mml:mo>-</mml:mo>
											<mml:msub>
												<mml:mrow>
													<mml:mover accent="true">
														<mml:mrow>
															<mml:mi mathvariant="bold">f</mml:mi>
														</mml:mrow>
														<mml:mrow>
															<mml:mo>˜</mml:mo>
														</mml:mrow>
													</mml:mover>
												</mml:mrow>
												<mml:mrow>
													<mml:mn>2</mml:mn>
													<mml:mi>i</mml:mi>
													<mml:mo>-</mml:mo>
													<mml:mn>1</mml:mn>
												</mml:mrow>
											</mml:msub>
											<mml:mtext>,</mml:mtext>
											<mml:mspace width="1em"/>
											<mml:mi>i</mml:mi>
											<mml:mo>=</mml:mo>
											<mml:mn>1</mml:mn>
											<mml:mtext>,</mml:mtext>
											<mml:mn>2</mml:mn>
											<mml:mtext>,</mml:mtext>
											<mml:mo>…</mml:mo>
											<mml:mtext>,</mml:mtext>
											<mml:mi>n</mml:mi>
											<mml:mo>×</mml:mo>
											<mml:mi>m</mml:mi>
										</mml:math>
									</ce:formula>
								</ce:display>The lengths of 
								<mml:math altimg="si62.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:mrow>
										<mml:mover accent="true">
											<mml:mrow>
												<mml:mi mathvariant="bold">F</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:mo stretchy="true">∼</mml:mo>
											</mml:mrow>
										</mml:mover>
									</mml:mrow>
								</mml:math> and 
								<mml:math altimg="si63.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:mrow>
										<mml:mi mathvariant="normal">Δ</mml:mi>
										<mml:mover accent="true">
											<mml:mrow>
												<mml:mi mathvariant="bold">F</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:mo stretchy="true">∼</mml:mo>
											</mml:mrow>
										</mml:mover>
									</mml:mrow>
								</mml:math> are 2
								<ce:hsp sp="0.25"/>×
								<ce:hsp sp="0.25"/>
								<ce:italic>n</ce:italic>
								<ce:hsp sp="0.25"/>×
								<ce:hsp sp="0.25"/>
								<ce:italic>m</ce:italic> and 
								<ce:italic>n</ce:italic>
								<ce:hsp sp="0.25"/>×
								<ce:hsp sp="0.25"/>
								<ce:italic>m</ce:italic>, respectively.
							</ce:para>
							<ce:para id="p0160" view="all">The purpose of NNP-3 is to find a suitable mapping which minimizes the distances of neighboring points in the low dimensional space and ensures the remaining points are as far apart as possible. Therefore, we obtain the following objective function
								<ce:display>
									<ce:formula id="e0105">
										<ce:label>(26)</ce:label>
										<mml:math altimg="si64.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
											<mml:munder>
												<mml:mrow>
													<mml:mi mathvariant="normal">arg</mml:mi>
													<mml:mspace width="0.12em"/>
													<mml:mi mathvariant="normal">min</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mi mathvariant="bold">W</mml:mi>
												</mml:mrow>
											</mml:munder>
											<mml:mfrac>
												<mml:mrow>
													<mml:msup>
														<mml:mrow>
															<mml:mi mathvariant="bold">W</mml:mi>
														</mml:mrow>
														<mml:mrow>
															<mml:mi>T</mml:mi>
														</mml:mrow>
													</mml:msup>
													<mml:mi mathvariant="bold">CW</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:msup>
														<mml:mrow>
															<mml:mi mathvariant="bold">W</mml:mi>
														</mml:mrow>
														<mml:mrow>
															<mml:mi>T</mml:mi>
														</mml:mrow>
													</mml:msup>
													<mml:mi mathvariant="bold">DW</mml:mi>
												</mml:mrow>
											</mml:mfrac>
										</mml:math>
									</ce:formula>
								</ce:display>where 
								<mml:math altimg="si65.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:mrow>
										<mml:mi mathvariant="bold">C</mml:mi>
										<mml:mo>=</mml:mo>
										<mml:mi mathvariant="normal">Δ</mml:mi>
										<mml:mover accent="true">
											<mml:mrow>
												<mml:mi mathvariant="bold">S</mml:mi>
											</mml:mrow>
											<mml:mrow>
												<mml:mo stretchy="true">∼</mml:mo>
											</mml:mrow>
										</mml:mover>
										<mml:mi mathvariant="normal">Δ</mml:mi>
										<mml:msup>
											<mml:mrow>
												<mml:mover accent="true">
													<mml:mrow>
														<mml:mi mathvariant="bold">S</mml:mi>
													</mml:mrow>
													<mml:mrow>
														<mml:mo stretchy="true">∼</mml:mo>
													</mml:mrow>
												</mml:mover>
											</mml:mrow>
											<mml:mrow>
												<mml:mi>T</mml:mi>
											</mml:mrow>
										</mml:msup>
									</mml:mrow>
								</mml:math> is defined by Eq. 
								<ce:cross-ref refid="e0200">(22)</ce:cross-ref> and 
								<ce:bold>D</ce:bold> is defined by
								<ce:display>
									<ce:formula id="e0110">
										<ce:label>(27)</ce:label>
										<mml:math altimg="si66.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
											<mml:mi mathvariant="bold">D</mml:mi>
											<mml:mo>=</mml:mo>
											<mml:mi mathvariant="normal">Δ</mml:mi>
											<mml:mover accent="true">
												<mml:mrow>
													<mml:mi mathvariant="bold">F</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mo stretchy="true">∼</mml:mo>
												</mml:mrow>
											</mml:mover>
											<mml:mi mathvariant="normal">Δ</mml:mi>
											<mml:msup>
												<mml:mrow>
													<mml:mover accent="true">
														<mml:mrow>
															<mml:mi mathvariant="bold">F</mml:mi>
														</mml:mrow>
														<mml:mrow>
															<mml:mo stretchy="true">∼</mml:mo>
														</mml:mrow>
													</mml:mover>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>T</mml:mi>
												</mml:mrow>
											</mml:msup>
										</mml:math>
									</ce:formula>
								</ce:display>
								<ce:bold>W</ce:bold>
								<ce:hsp sp="0.25"/>=
								<ce:hsp sp="0.25"/>(
								<ce:bold>w</ce:bold>
								<ce:inf loc="post">1</ce:inf>,
								<ce:hsp sp="0.12"/>
								<ce:bold>w</ce:bold>
								<ce:inf loc="post">2</ce:inf>,
								<ce:hsp sp="0.12"/>…
								<ce:hsp sp="0.12"/>,
								<ce:hsp sp="0.12"/>
								<ce:bold>w</ce:bold>
								<ce:inf loc="post">
									<ce:italic>D</ce:italic>
								</ce:inf>) is the matrix of the eigenvectors corresponding to the eigenvalues. We choose 
								<ce:italic>d</ce:italic> smallest non-zero eigenvalues. Then the low 
								<ce:italic>d</ce:italic>-dimensional coordinates 
								<ce:bold>y</ce:bold>
								<ce:inf loc="post">
									<ce:italic>i</ce:italic>
								</ce:inf> for the input data 
								<ce:bold>x</ce:bold>
								<ce:inf loc="post">
									<ce:italic>i</ce:italic>
								</ce:inf> are estimated by 
								<ce:bold>y</ce:bold>
								<ce:inf loc="post">
									<ce:italic>i</ce:italic>
								</ce:inf>
								<ce:hsp sp="0.25"/>=
								<ce:hsp sp="0.25"/>
								<ce:bold>U</ce:bold>
								<ce:sup loc="post">
									<ce:italic>T</ce:italic>
								</ce:sup>
								<ce:bold>x</ce:bold>
								<ce:inf loc="post">
									<ce:italic>i</ce:italic>
								</ce:inf>, 
								<ce:bold>U</ce:bold>
								<ce:hsp sp="0.25"/>=
								<ce:hsp sp="0.25"/>(
								<ce:bold>w</ce:bold>
								<ce:inf loc="post">1</ce:inf>,
								<ce:hsp sp="0.12"/>
								<ce:bold>w</ce:bold>
								<ce:inf loc="post">2</ce:inf>,
								<ce:hsp sp="0.12"/>…
								<ce:hsp sp="0.12"/>,
								<ce:hsp sp="0.12"/>
								<ce:bold>w</ce:bold>
								<ce:inf loc="post">
									<ce:italic>d</ce:italic>
								</ce:inf>).
							</ce:para>
						</ce:section>
						<ce:section id="s0060" view="all">
							<ce:label>3.3.2</ce:label>
							<ce:section-title>Algorithm summarization</ce:section-title>
							<ce:para id="p0165" view="all">The NNP-3 algorithm is summarized as follows.
								<ce:display>
									<ce:table frame="topbot" id="t0035" rowsep="0" colsep="0">
										<cals:tgroup cols="1" xmlns:cals="http://www.elsevier.com/xml/common/cals/schema">
											<cals:colspec colname="col1" align="left"/>
											<cals:thead>
												<cals:row rowsep="1" valign="top">
													<ce:entry>
														<ce:bold>Algorithm NNP-3</ce:bold>
													</ce:entry>
												</cals:row>
											</cals:thead>
											<cals:tbody>
												<cals:row valign="top">
													<ce:entry>
														<ce:bold>Input:</ce:bold>
														<mml:math altimg="si67.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
															<mml:mrow>
																<mml:mi mathvariant="bold">X</mml:mi>
																<mml:mo>=</mml:mo>
																<mml:mo stretchy="false">(</mml:mo>
																<mml:msub>
																	<mml:mrow>
																		<mml:mi mathvariant="bold">x</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:mn>1</mml:mn>
																	</mml:mrow>
																</mml:msub>
																<mml:mtext>,</mml:mtext>
																<mml:msub>
																	<mml:mrow>
																		<mml:mi mathvariant="bold">x</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:mn>2</mml:mn>
																	</mml:mrow>
																</mml:msub>
																<mml:mtext>,</mml:mtext>
																<mml:mo>…</mml:mo>
																<mml:mtext>,</mml:mtext>
																<mml:msub>
																	<mml:mrow>
																		<mml:mi mathvariant="bold">x</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:mi>n</mml:mi>
																	</mml:mrow>
																</mml:msub>
																<mml:mo stretchy="false">)</mml:mo>
																<mml:mtext>,</mml:mtext>
																<mml:mspace width="0.35em"/>
																<mml:msub>
																	<mml:mrow>
																		<mml:mi mathvariant="bold">x</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:mi>i</mml:mi>
																	</mml:mrow>
																</mml:msub>
																<mml:mo>∈</mml:mo>
																<mml:msup>
																	<mml:mrow>
																		<mml:mi mathvariant="double-struck">R</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:mi>D</mml:mi>
																	</mml:mrow>
																</mml:msup>
															</mml:mrow>
														</mml:math>
													</ce:entry>
												</cals:row>
												<cals:row valign="top">
													<ce:entry>
														<ce:hsp sp="1"/>
														<ce:bold>Step 1:</ce:bold> find 
														<ce:italic>k</ce:italic> nearest neighbor points for each 
														<ce:bold>x</ce:bold>
														<ce:inf loc="post">
															<ce:italic>i</ce:italic>
														</ce:inf>.
													</ce:entry>
												</cals:row>
												<cals:row valign="top">
													<ce:entry>
														<ce:hsp sp="1"/>
														<ce:bold>Step 2:</ce:bold> construct 
														<ce:bold>S</ce:bold> consisting of pairs of two neighboring points.
													</ce:entry>
												</cals:row>
												<cals:row valign="top">
													<ce:entry>
														<ce:hsp sp="1"/>
														<ce:bold>Step 3:</ce:bold> find 
														<ce:italic>m</ce:italic> farthest points for each 
														<ce:bold>x</ce:bold>
														<ce:inf loc="post">
															<ce:italic>i</ce:italic>
														</ce:inf>.
													</ce:entry>
												</cals:row>
												<cals:row valign="top">
													<ce:entry>
														<ce:hsp sp="1"/>
														<ce:bold>Step 4:</ce:bold> construct 
														<ce:bold>F</ce:bold> consisting of pairs of two points far from each other.
													</ce:entry>
												</cals:row>
												<cals:row valign="top">
													<ce:entry>
														<ce:hsp sp="1"/>
														<ce:bold>Step 5:</ce:bold> expand 
														<ce:bold>X</ce:bold>, 
														<ce:bold>S</ce:bold> and 
														<ce:bold>F</ce:bold> into a nonlinear expanded space to get the expanded data 
														<mml:math altimg="si68.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
															<mml:mrow>
																<mml:mover accent="true">
																	<mml:mrow>
																		<mml:mi mathvariant="bold">X</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:mo stretchy="true">∼</mml:mo>
																	</mml:mrow>
																</mml:mover>
																<mml:mtext>,</mml:mtext>
																<mml:mspace width="0.35em"/>
																<mml:mover accent="true">
																	<mml:mrow>
																		<mml:mi mathvariant="bold">S</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:mo stretchy="true">∼</mml:mo>
																	</mml:mrow>
																</mml:mover>
															</mml:mrow>
														</mml:math> and 
														<mml:math altimg="si69.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
															<mml:mrow>
																<mml:mover accent="true">
																	<mml:mrow>
																		<mml:mi mathvariant="bold">F</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:mo stretchy="true">∼</mml:mo>
																	</mml:mrow>
																</mml:mover>
															</mml:mrow>
														</mml:math>, respectively.
													</ce:entry>
												</cals:row>
												<cals:row valign="top">
													<ce:entry>
														<ce:hsp sp="1"/>
														<ce:bold>Step 6:</ce:bold> estimate the time difference 
														<mml:math altimg="si70.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
															<mml:mrow>
																<mml:mi mathvariant="normal">Δ</mml:mi>
																<mml:mover accent="true">
																	<mml:mrow>
																		<mml:mi mathvariant="bold">S</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:mo stretchy="true">∼</mml:mo>
																	</mml:mrow>
																</mml:mover>
															</mml:mrow>
														</mml:math> and 
														<mml:math altimg="si71.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
															<mml:mrow>
																<mml:mi mathvariant="normal">Δ</mml:mi>
																<mml:mover accent="true">
																	<mml:mrow>
																		<mml:mi mathvariant="bold">F</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:mo stretchy="true">∼</mml:mo>
																	</mml:mrow>
																</mml:mover>
															</mml:mrow>
														</mml:math>.
													</ce:entry>
												</cals:row>
												<cals:row valign="top">
													<ce:entry>
														<ce:hsp sp="1"/>
														<ce:bold>Step 7:</ce:bold> calculate 
														<ce:bold>C</ce:bold> and 
														<ce:bold>D</ce:bold> according to Eqs. 
														<ce:cross-refs refid="e0200 e0110">(22) and (27)</ce:cross-refs>.
													</ce:entry>
												</cals:row>
												<cals:row valign="top">
													<ce:entry>
														<ce:hsp sp="1"/>
														<ce:bold>Step 8:</ce:bold> estimate 
														<ce:bold>W</ce:bold> whose columns are the eigenvectors of 
														<ce:bold>CW</ce:bold>
														<ce:hsp sp="0.25"/>=
														<ce:hsp sp="0.25"/>
														<ce:bold>ΛDW</ce:bold> and order the columns according to the eigenvalues.
													</ce:entry>
												</cals:row>
												<cals:row valign="top">
													<ce:entry>
														<ce:hsp sp="1"/>
														<ce:bold>Step 9:</ce:bold> choose 
														<ce:italic>d</ce:italic> smallest non-zero eigenvalues and the associated eigenvectors 
														<ce:bold>U</ce:bold>
														<ce:hsp sp="0.25"/>=
														<ce:hsp sp="0.25"/>(
														<ce:bold>w</ce:bold>
														<ce:inf loc="post">1</ce:inf>,
														<ce:hsp sp="0.12"/>
														<ce:bold>w</ce:bold>
														<ce:inf loc="post">2</ce:inf>,
														<ce:hsp sp="0.12"/>…
														<ce:hsp sp="0.12"/>,
														<ce:hsp sp="0.12"/>
														<ce:bold>w</ce:bold>
														<ce:inf loc="post">
															<ce:italic>d</ce:italic>
														</ce:inf>), and obtain the 
														<ce:italic>d</ce:italic>-dimensional coordinates by 
														<mml:math altimg="si72.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
															<mml:mrow>
																<mml:mi mathvariant="bold">Y</mml:mi>
																<mml:mo>=</mml:mo>
																<mml:msup>
																	<mml:mrow>
																		<mml:mi mathvariant="bold">U</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:mi>T</mml:mi>
																	</mml:mrow>
																</mml:msup>
																<mml:mover accent="true">
																	<mml:mrow>
																		<mml:mi mathvariant="bold">X</mml:mi>
																	</mml:mrow>
																	<mml:mrow>
																		<mml:mo stretchy="true">∼</mml:mo>
																	</mml:mrow>
																</mml:mover>
															</mml:mrow>
														</mml:math>.
													</ce:entry>
												</cals:row>
											</cals:tbody>
										</cals:tgroup>
									</ce:table>
								</ce:display>
							</ce:para>
						</ce:section>
					</ce:section>
				</ce:section>
				<ce:section id="s0065" view="all">
					<ce:label>4</ce:label>
					<ce:section-title>Extension: kernel NNP</ce:section-title>
					<ce:para id="p0170" view="all">As discussed in Section 
						<ce:cross-ref refid="s0015">3</ce:cross-ref>, we use a nonlinear expansion to find the low dimensional coordinates. Since the nonlinear space grows exponentially as the input dimension increases, our method clearly suffers from the curse of dimensionality. In order to solve this problem, we can use a “kernel trick” which projects the input data into a nonlinear kernel induced space that is never explicitly represented.
					</ce:para>
					<ce:para id="p0175" view="all">Supposing that the input data is projected to Hilbert space via a nonlinear mapping function 
						<ce:italic>ϕ</ce:italic>, Eqs. 
						<ce:cross-refs refid="e0185 e0190 e0200 e0110">(13), (14), (22) and (27)</ce:cross-refs> can be rewritten as follows
						<ce:display>
							<ce:formula id="e0115">
								<ce:label>(28)</ce:label>
								<mml:math altimg="si73.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:mi mathvariant="bold">A</mml:mi>
									<mml:mo>=</mml:mo>
									<mml:mi mathvariant="normal">Δ</mml:mi>
									<mml:mover accent="true">
										<mml:mrow>
											<mml:mi mathvariant="bold">X</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mo stretchy="true">∼</mml:mo>
										</mml:mrow>
									</mml:mover>
									<mml:mi mathvariant="normal">Δ</mml:mi>
									<mml:msup>
										<mml:mrow>
											<mml:mover accent="true">
												<mml:mrow>
													<mml:mi mathvariant="bold">X</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mo stretchy="true">∼</mml:mo>
												</mml:mrow>
											</mml:mover>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msup>
									<mml:mo>=</mml:mo>
									<mml:munder>
										<mml:mrow>
											<mml:mo>∑</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:munder>
									<mml:mi mathvariant="normal">Δ</mml:mi>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">x</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:mo stretchy="false">)</mml:mo>
									<mml:mi mathvariant="normal">Δ</mml:mi>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">x</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:msup>
										<mml:mrow>
											<mml:mo stretchy="false">)</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msup>
								</mml:math>
							</ce:formula>
						</ce:display>
						<ce:display>
							<ce:formula id="e0120">
								<ce:label>(29)</ce:label>
								<mml:math altimg="si74.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:mi mathvariant="bold">B</mml:mi>
									<mml:mo>=</mml:mo>
									<mml:mover accent="true">
										<mml:mrow>
											<mml:mi mathvariant="bold">X</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mo stretchy="true">∼</mml:mo>
										</mml:mrow>
									</mml:mover>
									<mml:msup>
										<mml:mrow>
											<mml:mover accent="true">
												<mml:mrow>
													<mml:mi mathvariant="bold">X</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mo stretchy="true">∼</mml:mo>
												</mml:mrow>
											</mml:mover>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msup>
									<mml:mo>=</mml:mo>
									<mml:munder>
										<mml:mrow>
											<mml:mo>∑</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:munder>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">x</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:mo stretchy="false">)</mml:mo>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">x</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:msup>
										<mml:mrow>
											<mml:mo stretchy="false">)</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msup>
								</mml:math>
							</ce:formula>
						</ce:display>
						<ce:display>
							<ce:formula id="e0125">
								<ce:label>(30)</ce:label>
								<mml:math altimg="si75.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:mi mathvariant="bold">C</mml:mi>
									<mml:mo>=</mml:mo>
									<mml:mi mathvariant="normal">Δ</mml:mi>
									<mml:mover accent="true">
										<mml:mrow>
											<mml:mi mathvariant="bold">S</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mo stretchy="true">∼</mml:mo>
										</mml:mrow>
									</mml:mover>
									<mml:mi mathvariant="normal">Δ</mml:mi>
									<mml:msup>
										<mml:mrow>
											<mml:mover accent="true">
												<mml:mrow>
													<mml:mi mathvariant="bold">S</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mo stretchy="true">∼</mml:mo>
												</mml:mrow>
											</mml:mover>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msup>
									<mml:mo>=</mml:mo>
									<mml:munder>
										<mml:mrow>
											<mml:mo>∑</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:munder>
									<mml:mi mathvariant="normal">Δ</mml:mi>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">s</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:mo stretchy="false">)</mml:mo>
									<mml:mi mathvariant="normal">Δ</mml:mi>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">s</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:msup>
										<mml:mrow>
											<mml:mo stretchy="false">)</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msup>
								</mml:math>
							</ce:formula>
						</ce:display>
						<ce:display>
							<ce:formula id="e0130">
								<ce:label>(31)</ce:label>
								<mml:math altimg="si76.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:mi mathvariant="bold">D</mml:mi>
									<mml:mo>=</mml:mo>
									<mml:mi mathvariant="normal">Δ</mml:mi>
									<mml:mover accent="true">
										<mml:mrow>
											<mml:mi mathvariant="bold">F</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mo stretchy="true">∼</mml:mo>
										</mml:mrow>
									</mml:mover>
									<mml:mi mathvariant="normal">Δ</mml:mi>
									<mml:msup>
										<mml:mrow>
											<mml:mover accent="true">
												<mml:mrow>
													<mml:mi mathvariant="bold">F</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mo stretchy="true">∼</mml:mo>
												</mml:mrow>
											</mml:mover>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msup>
									<mml:mo>=</mml:mo>
									<mml:munder>
										<mml:mrow>
											<mml:mo>∑</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:munder>
									<mml:mi mathvariant="normal">Δ</mml:mi>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">f</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:mo stretchy="false">)</mml:mo>
									<mml:mi mathvariant="normal">Δ</mml:mi>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">f</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:msup>
										<mml:mrow>
											<mml:mo stretchy="false">)</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msup>
								</mml:math>
							</ce:formula>
						</ce:display>In order to avoid calculating with the expanded data directly, we rewrite 
						<ce:bold>W</ce:bold> as
						<ce:display>
							<ce:formula id="e0135">
								<ce:label>(32)</ce:label>
								<mml:math altimg="si77.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:mi mathvariant="bold">W</mml:mi>
									<mml:mo>=</mml:mo>
									<mml:munderover>
										<mml:mrow>
											<mml:mo>∑</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
											<mml:mo>=</mml:mo>
											<mml:mn>1</mml:mn>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>n</mml:mi>
										</mml:mrow>
									</mml:munderover>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold-italic">α</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">x</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:mo stretchy="false">)</mml:mo>
								</mml:math>
							</ce:formula>
						</ce:display>we can now obtain
						<ce:display>
							<ce:formula id="e0140">
								<ce:label>(33)</ce:label>
								<mml:math altimg="si78.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:msup>
										<mml:mrow>
											<mml:mi mathvariant="bold">W</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msup>
									<mml:mi mathvariant="bold">AW</mml:mi>
									<mml:mo>=</mml:mo>
									<mml:munder>
										<mml:mrow>
											<mml:mo>∑</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
											<mml:mtext>,</mml:mtext>
											<mml:mi>j</mml:mi>
										</mml:mrow>
									</mml:munder>
									<mml:msub>
										<mml:mrow>
											<mml:mi>α</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:msub>
										<mml:mrow>
											<mml:mi>α</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>j</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">x</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:msup>
										<mml:mrow>
											<mml:mo stretchy="false">)</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msup>
									<mml:mi mathvariant="bold">A</mml:mi>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">x</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:mo stretchy="false">)</mml:mo>
									<mml:mo>=</mml:mo>
									<mml:munder>
										<mml:mrow>
											<mml:mo>∑</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
											<mml:mtext>,</mml:mtext>
											<mml:mi>j</mml:mi>
										</mml:mrow>
									</mml:munder>
									<mml:msub>
										<mml:mrow>
											<mml:mi>α</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:msub>
										<mml:mrow>
											<mml:mi>α</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>j</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">x</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:msup>
										<mml:mrow>
											<mml:mo stretchy="false">)</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msup>
									<mml:munder>
										<mml:mrow>
											<mml:mo>∑</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>k</mml:mi>
										</mml:mrow>
									</mml:munder>
									<mml:mi mathvariant="normal">Δ</mml:mi>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">x</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>k</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:mo stretchy="false">)</mml:mo>
									<mml:mi mathvariant="normal">Δ</mml:mi>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">x</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>k</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:msup>
										<mml:mrow>
											<mml:mo stretchy="false">)</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msup>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">x</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:mo stretchy="false">)</mml:mo>
									<mml:mo>=</mml:mo>
									<mml:munder>
										<mml:mrow>
											<mml:mo>∑</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
											<mml:mtext>,</mml:mtext>
											<mml:mi>j</mml:mi>
										</mml:mrow>
									</mml:munder>
									<mml:msub>
										<mml:mrow>
											<mml:mi>α</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:msub>
										<mml:mrow>
											<mml:mi>α</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>j</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:munder>
										<mml:mrow>
											<mml:mo>∑</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>k</mml:mi>
										</mml:mrow>
									</mml:munder>
									<mml:mi mathvariant="normal">Δ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">x</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:msup>
										<mml:mrow>
											<mml:mo stretchy="false">)</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msup>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">x</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>k</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:mo stretchy="false">)</mml:mo>
									<mml:mo stretchy="false">)</mml:mo>
									<mml:mi mathvariant="normal">Δ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">x</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>k</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:msup>
										<mml:mrow>
											<mml:mo stretchy="false">)</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msup>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">x</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:mo stretchy="false">)</mml:mo>
									<mml:mo stretchy="false">)</mml:mo>
									<mml:mo>=</mml:mo>
									<mml:msup>
										<mml:mrow>
											<mml:mi mathvariant="bold-italic">α</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msup>
									<mml:mi mathvariant="normal">Δ</mml:mi>
									<mml:mi mathvariant="bold">K</mml:mi>
									<mml:mi mathvariant="normal">Δ</mml:mi>
									<mml:msup>
										<mml:mrow>
											<mml:mi mathvariant="bold">K</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msup>
									<mml:mi mathvariant="bold-italic">α</mml:mi>
								</mml:math>
							</ce:formula>
						</ce:display>
						<ce:display>
							<ce:formula id="e0145">
								<ce:label>(34)</ce:label>
								<mml:math altimg="si79.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:msup>
										<mml:mrow>
											<mml:mi mathvariant="bold">W</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msup>
									<mml:mi mathvariant="bold">BW</mml:mi>
									<mml:mo>=</mml:mo>
									<mml:munder>
										<mml:mrow>
											<mml:mo>∑</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
											<mml:mtext>,</mml:mtext>
											<mml:mi>j</mml:mi>
										</mml:mrow>
									</mml:munder>
									<mml:msub>
										<mml:mrow>
											<mml:mi>α</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:msub>
										<mml:mrow>
											<mml:mi>α</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>j</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">x</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:msup>
										<mml:mrow>
											<mml:mo stretchy="false">)</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msup>
									<mml:mi mathvariant="bold">B</mml:mi>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">x</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:mo stretchy="false">)</mml:mo>
									<mml:mo>=</mml:mo>
									<mml:munder>
										<mml:mrow>
											<mml:mo>∑</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
											<mml:mtext>,</mml:mtext>
											<mml:mi>j</mml:mi>
										</mml:mrow>
									</mml:munder>
									<mml:msub>
										<mml:mrow>
											<mml:mi>α</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:msub>
										<mml:mrow>
											<mml:mi>α</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>j</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">x</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:msup>
										<mml:mrow>
											<mml:mo stretchy="false">)</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msup>
									<mml:munder>
										<mml:mrow>
											<mml:mo>∑</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>k</mml:mi>
										</mml:mrow>
									</mml:munder>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">x</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>k</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:mo stretchy="false">)</mml:mo>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">x</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>k</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:msup>
										<mml:mrow>
											<mml:mo stretchy="false">)</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msup>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">x</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:mo stretchy="false">)</mml:mo>
									<mml:mo>=</mml:mo>
									<mml:munder>
										<mml:mrow>
											<mml:mo>∑</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
											<mml:mtext>,</mml:mtext>
											<mml:mi>j</mml:mi>
										</mml:mrow>
									</mml:munder>
									<mml:msub>
										<mml:mrow>
											<mml:mi>α</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:msub>
										<mml:mrow>
											<mml:mi>α</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>j</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:munder>
										<mml:mrow>
											<mml:mo>∑</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>k</mml:mi>
										</mml:mrow>
									</mml:munder>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">x</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:msup>
										<mml:mrow>
											<mml:mo stretchy="false">)</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msup>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">x</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>k</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:mo stretchy="false">)</mml:mo>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">x</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>k</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:msup>
										<mml:mrow>
											<mml:mo stretchy="false">)</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msup>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">x</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:mo stretchy="false">)</mml:mo>
									<mml:mo>=</mml:mo>
									<mml:msup>
										<mml:mrow>
											<mml:mi mathvariant="bold-italic">α</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msup>
									<mml:msup>
										<mml:mrow>
											<mml:mi mathvariant="bold">KK</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msup>
									<mml:mi mathvariant="bold-italic">α</mml:mi>
								</mml:math>
							</ce:formula>
						</ce:display>where
						<ce:display>
							<ce:formula id="e0150">
								<ce:label>(35)</ce:label>
								<mml:math altimg="si80.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:mtable columnspacing="0em">
										<mml:mtr>
											<mml:mtd columnalign="right"/>
											<mml:mtd columnalign="left">
												<mml:mrow>
													<mml:msub>
														<mml:mrow>
															<mml:mi>k</mml:mi>
														</mml:mrow>
														<mml:mrow>
															<mml:mi mathvariant="italic">ij</mml:mi>
														</mml:mrow>
													</mml:msub>
													<mml:mo>=</mml:mo>
													<mml:mi>ϕ</mml:mi>
													<mml:mo stretchy="false">(</mml:mo>
													<mml:msub>
														<mml:mrow>
															<mml:mi mathvariant="bold">x</mml:mi>
														</mml:mrow>
														<mml:mrow>
															<mml:mi>i</mml:mi>
														</mml:mrow>
													</mml:msub>
													<mml:msup>
														<mml:mrow>
															<mml:mo stretchy="false">)</mml:mo>
														</mml:mrow>
														<mml:mrow>
															<mml:mi>T</mml:mi>
														</mml:mrow>
													</mml:msup>
													<mml:mi>ϕ</mml:mi>
													<mml:mo stretchy="false">(</mml:mo>
													<mml:msub>
														<mml:mrow>
															<mml:mi mathvariant="bold">x</mml:mi>
														</mml:mrow>
														<mml:mrow>
															<mml:mi>j</mml:mi>
														</mml:mrow>
													</mml:msub>
													<mml:mo stretchy="false">)</mml:mo>
												</mml:mrow>
											</mml:mtd>
										</mml:mtr>
										<mml:mtr>
											<mml:mtd columnalign="right"/>
											<mml:mtd columnalign="left">
												<mml:mrow>
													<mml:mi mathvariant="normal">Δ</mml:mi>
													<mml:msub>
														<mml:mrow>
															<mml:mi mathvariant="bold">k</mml:mi>
														</mml:mrow>
														<mml:mrow>
															<mml:mi>i</mml:mi>
														</mml:mrow>
													</mml:msub>
													<mml:mo>=</mml:mo>
													<mml:msub>
														<mml:mrow>
															<mml:mi mathvariant="bold">k</mml:mi>
														</mml:mrow>
														<mml:mrow>
															<mml:mi>i</mml:mi>
															<mml:mo>+</mml:mo>
															<mml:mn>1</mml:mn>
														</mml:mrow>
													</mml:msub>
													<mml:mo>-</mml:mo>
													<mml:msub>
														<mml:mrow>
															<mml:mi mathvariant="bold">k</mml:mi>
														</mml:mrow>
														<mml:mrow>
															<mml:mi>i</mml:mi>
														</mml:mrow>
													</mml:msub>
													<mml:mtext>,</mml:mtext>
													<mml:mspace width="1em"/>
													<mml:mi>i</mml:mi>
													<mml:mo>=</mml:mo>
													<mml:mn>1</mml:mn>
													<mml:mtext>,</mml:mtext>
													<mml:mn>2</mml:mn>
													<mml:mtext>,</mml:mtext>
													<mml:mo>…</mml:mo>
													<mml:mtext>,</mml:mtext>
													<mml:mi>n</mml:mi>
													<mml:mo>-</mml:mo>
													<mml:mn>1</mml:mn>
												</mml:mrow>
											</mml:mtd>
										</mml:mtr>
									</mml:mtable>
								</mml:math>
							</ce:formula>
						</ce:display>We can also estimate
						<ce:display>
							<ce:formula id="e0155">
								<ce:label>(36)</ce:label>
								<mml:math altimg="si81.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:msup>
										<mml:mrow>
											<mml:mi mathvariant="bold">W</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msup>
									<mml:mi mathvariant="bold">CW</mml:mi>
									<mml:mo>=</mml:mo>
									<mml:munder>
										<mml:mrow>
											<mml:mo>∑</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
											<mml:mtext>,</mml:mtext>
											<mml:mi>j</mml:mi>
										</mml:mrow>
									</mml:munder>
									<mml:msub>
										<mml:mrow>
											<mml:mi>α</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:msub>
										<mml:mrow>
											<mml:mi>α</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>j</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">x</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:msup>
										<mml:mrow>
											<mml:mo stretchy="false">)</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msup>
									<mml:mi mathvariant="bold">C</mml:mi>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">x</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:mo stretchy="false">)</mml:mo>
									<mml:mo>=</mml:mo>
									<mml:munder>
										<mml:mrow>
											<mml:mo>∑</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
											<mml:mtext>,</mml:mtext>
											<mml:mi>j</mml:mi>
										</mml:mrow>
									</mml:munder>
									<mml:msub>
										<mml:mrow>
											<mml:mi>α</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:msub>
										<mml:mrow>
											<mml:mi>α</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>j</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">x</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:msup>
										<mml:mrow>
											<mml:mo stretchy="false">)</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msup>
									<mml:munder>
										<mml:mrow>
											<mml:mo>∑</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>k</mml:mi>
										</mml:mrow>
									</mml:munder>
									<mml:mi mathvariant="normal">Δ</mml:mi>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">s</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>k</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:mo stretchy="false">)</mml:mo>
									<mml:mi mathvariant="normal">Δ</mml:mi>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">s</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>k</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:msup>
										<mml:mrow>
											<mml:mo stretchy="false">)</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msup>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">x</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:mo stretchy="false">)</mml:mo>
									<mml:mo>=</mml:mo>
									<mml:munder>
										<mml:mrow>
											<mml:mo>∑</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
											<mml:mtext>,</mml:mtext>
											<mml:mi>j</mml:mi>
										</mml:mrow>
									</mml:munder>
									<mml:msub>
										<mml:mrow>
											<mml:mi>α</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:msub>
										<mml:mrow>
											<mml:mi>α</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>j</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:munder>
										<mml:mrow>
											<mml:mo>∑</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>k</mml:mi>
										</mml:mrow>
									</mml:munder>
									<mml:mi mathvariant="normal">Δ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">x</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:msup>
										<mml:mrow>
											<mml:mo stretchy="false">)</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msup>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">s</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>k</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:mo stretchy="false">)</mml:mo>
									<mml:mo stretchy="false">)</mml:mo>
									<mml:mi mathvariant="normal">Δ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">s</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>k</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:msup>
										<mml:mrow>
											<mml:mo stretchy="false">)</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msup>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">x</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:mo stretchy="false">)</mml:mo>
									<mml:mo stretchy="false">)</mml:mo>
									<mml:mo>=</mml:mo>
									<mml:msup>
										<mml:mrow>
											<mml:mi mathvariant="bold-italic">α</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msup>
									<mml:mi mathvariant="normal">Δ</mml:mi>
									<mml:mover accent="true">
										<mml:mrow>
											<mml:mi mathvariant="bold">K</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mo stretchy="true">¯</mml:mo>
										</mml:mrow>
									</mml:mover>
									<mml:mi mathvariant="normal">Δ</mml:mi>
									<mml:msup>
										<mml:mrow>
											<mml:mover accent="true">
												<mml:mrow>
													<mml:mi mathvariant="bold">K</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mo stretchy="true">¯</mml:mo>
												</mml:mrow>
											</mml:mover>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msup>
									<mml:mi mathvariant="bold-italic">α</mml:mi>
								</mml:math>
							</ce:formula>
						</ce:display>where
						<ce:display>
							<ce:formula id="e0160">
								<ce:label>(37)</ce:label>
								<mml:math altimg="si82.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:mtable columnspacing="0em">
										<mml:mtr>
											<mml:mtd columnalign="right"/>
											<mml:mtd columnalign="left">
												<mml:mrow>
													<mml:msub>
														<mml:mrow>
															<mml:mover accent="true">
																<mml:mrow>
																	<mml:mi>k</mml:mi>
																</mml:mrow>
																<mml:mrow>
																	<mml:mo>¯</mml:mo>
																</mml:mrow>
															</mml:mover>
														</mml:mrow>
														<mml:mrow>
															<mml:mi mathvariant="italic">ij</mml:mi>
														</mml:mrow>
													</mml:msub>
													<mml:mo>=</mml:mo>
													<mml:mi>ϕ</mml:mi>
													<mml:mo stretchy="false">(</mml:mo>
													<mml:msub>
														<mml:mrow>
															<mml:mi mathvariant="bold">x</mml:mi>
														</mml:mrow>
														<mml:mrow>
															<mml:mi>i</mml:mi>
														</mml:mrow>
													</mml:msub>
													<mml:msup>
														<mml:mrow>
															<mml:mo stretchy="false">)</mml:mo>
														</mml:mrow>
														<mml:mrow>
															<mml:mi>T</mml:mi>
														</mml:mrow>
													</mml:msup>
													<mml:mi>ϕ</mml:mi>
													<mml:mo stretchy="false">(</mml:mo>
													<mml:msub>
														<mml:mrow>
															<mml:mi mathvariant="bold">s</mml:mi>
														</mml:mrow>
														<mml:mrow>
															<mml:mi>j</mml:mi>
														</mml:mrow>
													</mml:msub>
													<mml:mo stretchy="false">)</mml:mo>
												</mml:mrow>
											</mml:mtd>
										</mml:mtr>
										<mml:mtr>
											<mml:mtd columnalign="right"/>
											<mml:mtd columnalign="left">
												<mml:mrow>
													<mml:mi mathvariant="normal">Δ</mml:mi>
													<mml:msub>
														<mml:mrow>
															<mml:mover accent="true">
																<mml:mrow>
																	<mml:mi mathvariant="bold">k</mml:mi>
																</mml:mrow>
																<mml:mrow>
																	<mml:mo>¯</mml:mo>
																</mml:mrow>
															</mml:mover>
														</mml:mrow>
														<mml:mrow>
															<mml:mi>i</mml:mi>
														</mml:mrow>
													</mml:msub>
													<mml:mo>=</mml:mo>
													<mml:msub>
														<mml:mrow>
															<mml:mover accent="true">
																<mml:mrow>
																	<mml:mi mathvariant="bold">k</mml:mi>
																</mml:mrow>
																<mml:mrow>
																	<mml:mo>¯</mml:mo>
																</mml:mrow>
															</mml:mover>
														</mml:mrow>
														<mml:mrow>
															<mml:mn>2</mml:mn>
															<mml:mi>i</mml:mi>
														</mml:mrow>
													</mml:msub>
													<mml:mo>-</mml:mo>
													<mml:msub>
														<mml:mrow>
															<mml:mover accent="true">
																<mml:mrow>
																	<mml:mi mathvariant="bold">k</mml:mi>
																</mml:mrow>
																<mml:mrow>
																	<mml:mo>¯</mml:mo>
																</mml:mrow>
															</mml:mover>
														</mml:mrow>
														<mml:mrow>
															<mml:mn>2</mml:mn>
															<mml:mi>i</mml:mi>
															<mml:mo>-</mml:mo>
															<mml:mn>1</mml:mn>
														</mml:mrow>
													</mml:msub>
													<mml:mtext>,</mml:mtext>
													<mml:mspace width="1em"/>
													<mml:mi>i</mml:mi>
													<mml:mo>=</mml:mo>
													<mml:mn>1</mml:mn>
													<mml:mtext>,</mml:mtext>
													<mml:mn>2</mml:mn>
													<mml:mtext>,</mml:mtext>
													<mml:mo>…</mml:mo>
													<mml:mtext>,</mml:mtext>
													<mml:mi>n</mml:mi>
													<mml:mo>×</mml:mo>
													<mml:mi>k</mml:mi>
												</mml:mrow>
											</mml:mtd>
										</mml:mtr>
									</mml:mtable>
								</mml:math>
							</ce:formula>
						</ce:display>and
						<ce:display>
							<ce:formula id="e0165">
								<ce:label>(38)</ce:label>
								<mml:math altimg="si83.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:msup>
										<mml:mrow>
											<mml:mi mathvariant="bold">W</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msup>
									<mml:mi mathvariant="bold">DW</mml:mi>
									<mml:mo>=</mml:mo>
									<mml:munder>
										<mml:mrow>
											<mml:mo>∑</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
											<mml:mtext>,</mml:mtext>
											<mml:mi>j</mml:mi>
										</mml:mrow>
									</mml:munder>
									<mml:msub>
										<mml:mrow>
											<mml:mi>α</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:msub>
										<mml:mrow>
											<mml:mi>α</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>j</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">x</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:msup>
										<mml:mrow>
											<mml:mo stretchy="false">)</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msup>
									<mml:mi mathvariant="bold">D</mml:mi>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">x</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:mo stretchy="false">)</mml:mo>
									<mml:mo>=</mml:mo>
									<mml:munder>
										<mml:mrow>
											<mml:mo>∑</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
											<mml:mtext>,</mml:mtext>
											<mml:mi>j</mml:mi>
										</mml:mrow>
									</mml:munder>
									<mml:msub>
										<mml:mrow>
											<mml:mi>α</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:msub>
										<mml:mrow>
											<mml:mi>α</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>j</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">x</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:msup>
										<mml:mrow>
											<mml:mo stretchy="false">)</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msup>
									<mml:munder>
										<mml:mrow>
											<mml:mo>∑</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>k</mml:mi>
										</mml:mrow>
									</mml:munder>
									<mml:mi mathvariant="normal">Δ</mml:mi>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">f</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>k</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:mo stretchy="false">)</mml:mo>
									<mml:mi mathvariant="normal">Δ</mml:mi>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">f</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>k</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:msup>
										<mml:mrow>
											<mml:mo stretchy="false">)</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msup>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">x</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:mo stretchy="false">)</mml:mo>
									<mml:mo>=</mml:mo>
									<mml:munder>
										<mml:mrow>
											<mml:mo>∑</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
											<mml:mtext>,</mml:mtext>
											<mml:mi>j</mml:mi>
										</mml:mrow>
									</mml:munder>
									<mml:msub>
										<mml:mrow>
											<mml:mi>α</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:msub>
										<mml:mrow>
											<mml:mi>α</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>j</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:munder>
										<mml:mrow>
											<mml:mo>∑</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>k</mml:mi>
										</mml:mrow>
									</mml:munder>
									<mml:mi mathvariant="normal">Δ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">x</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:msup>
										<mml:mrow>
											<mml:mo stretchy="false">)</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msup>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">f</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>k</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:mo stretchy="false">)</mml:mo>
									<mml:mo stretchy="false">)</mml:mo>
									<mml:mi mathvariant="normal">Δ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">f</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>k</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:msup>
										<mml:mrow>
											<mml:mo stretchy="false">)</mml:mo>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msup>
									<mml:mi>ϕ</mml:mi>
									<mml:mo stretchy="false">(</mml:mo>
									<mml:msub>
										<mml:mrow>
											<mml:mi mathvariant="bold">x</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>i</mml:mi>
										</mml:mrow>
									</mml:msub>
									<mml:mo stretchy="false">)</mml:mo>
									<mml:mo stretchy="false">)</mml:mo>
									<mml:mo>=</mml:mo>
									<mml:msup>
										<mml:mrow>
											<mml:mi mathvariant="bold-italic">α</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msup>
									<mml:mi mathvariant="normal">Δ</mml:mi>
									<mml:mover accent="true">
										<mml:mrow>
											<mml:mi mathvariant="bold">K</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mo stretchy="true">∼</mml:mo>
										</mml:mrow>
									</mml:mover>
									<mml:mi mathvariant="normal">Δ</mml:mi>
									<mml:msup>
										<mml:mrow>
											<mml:mover accent="true">
												<mml:mrow>
													<mml:mi mathvariant="bold">K</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mo stretchy="true">∼</mml:mo>
												</mml:mrow>
											</mml:mover>
										</mml:mrow>
										<mml:mrow>
											<mml:mi>T</mml:mi>
										</mml:mrow>
									</mml:msup>
									<mml:mi mathvariant="bold-italic">α</mml:mi>
								</mml:math>
							</ce:formula>
						</ce:display>where
						<ce:display>
							<ce:formula id="e0170">
								<ce:label>(39)</ce:label>
								<mml:math altimg="si84.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:mtable columnspacing="0em">
										<mml:mtr>
											<mml:mtd columnalign="right"/>
											<mml:mtd columnalign="left">
												<mml:mrow>
													<mml:msub>
														<mml:mrow>
															<mml:mover accent="true">
																<mml:mrow>
																	<mml:mi>k</mml:mi>
																</mml:mrow>
																<mml:mrow>
																	<mml:mo>˜</mml:mo>
																</mml:mrow>
															</mml:mover>
														</mml:mrow>
														<mml:mrow>
															<mml:mi mathvariant="italic">ij</mml:mi>
														</mml:mrow>
													</mml:msub>
													<mml:mo>=</mml:mo>
													<mml:mi>ϕ</mml:mi>
													<mml:mo stretchy="false">(</mml:mo>
													<mml:msub>
														<mml:mrow>
															<mml:mi mathvariant="bold">x</mml:mi>
														</mml:mrow>
														<mml:mrow>
															<mml:mi>i</mml:mi>
														</mml:mrow>
													</mml:msub>
													<mml:msup>
														<mml:mrow>
															<mml:mo stretchy="false">)</mml:mo>
														</mml:mrow>
														<mml:mrow>
															<mml:mi>T</mml:mi>
														</mml:mrow>
													</mml:msup>
													<mml:mi>ϕ</mml:mi>
													<mml:mo stretchy="false">(</mml:mo>
													<mml:msub>
														<mml:mrow>
															<mml:mi mathvariant="bold">f</mml:mi>
														</mml:mrow>
														<mml:mrow>
															<mml:mi>j</mml:mi>
														</mml:mrow>
													</mml:msub>
													<mml:mo stretchy="false">)</mml:mo>
												</mml:mrow>
											</mml:mtd>
										</mml:mtr>
										<mml:mtr>
											<mml:mtd columnalign="right"/>
											<mml:mtd columnalign="left">
												<mml:mrow>
													<mml:mi mathvariant="normal">Δ</mml:mi>
													<mml:msub>
														<mml:mrow>
															<mml:mover accent="true">
																<mml:mrow>
																	<mml:mi mathvariant="bold">k</mml:mi>
																</mml:mrow>
																<mml:mrow>
																	<mml:mo>˜</mml:mo>
																</mml:mrow>
															</mml:mover>
														</mml:mrow>
														<mml:mrow>
															<mml:mi>i</mml:mi>
														</mml:mrow>
													</mml:msub>
													<mml:mo>=</mml:mo>
													<mml:msub>
														<mml:mrow>
															<mml:mover accent="true">
																<mml:mrow>
																	<mml:mi mathvariant="bold">k</mml:mi>
																</mml:mrow>
																<mml:mrow>
																	<mml:mo>˜</mml:mo>
																</mml:mrow>
															</mml:mover>
														</mml:mrow>
														<mml:mrow>
															<mml:mn>2</mml:mn>
															<mml:mi>i</mml:mi>
														</mml:mrow>
													</mml:msub>
													<mml:mo>-</mml:mo>
													<mml:msub>
														<mml:mrow>
															<mml:mover accent="true">
																<mml:mrow>
																	<mml:mi mathvariant="bold">k</mml:mi>
																</mml:mrow>
																<mml:mrow>
																	<mml:mo>˜</mml:mo>
																</mml:mrow>
															</mml:mover>
														</mml:mrow>
														<mml:mrow>
															<mml:mn>2</mml:mn>
															<mml:mi>i</mml:mi>
															<mml:mo>-</mml:mo>
															<mml:mn>1</mml:mn>
														</mml:mrow>
													</mml:msub>
													<mml:mtext>,</mml:mtext>
													<mml:mspace width="1em"/>
													<mml:mi>i</mml:mi>
													<mml:mo>=</mml:mo>
													<mml:mn>1</mml:mn>
													<mml:mtext>,</mml:mtext>
													<mml:mn>2</mml:mn>
													<mml:mtext>,</mml:mtext>
													<mml:mo>…</mml:mo>
													<mml:mtext>,</mml:mtext>
													<mml:mi>n</mml:mi>
													<mml:mo>×</mml:mo>
													<mml:mi>m</mml:mi>
												</mml:mrow>
											</mml:mtd>
										</mml:mtr>
									</mml:mtable>
								</mml:math>
							</ce:formula>
						</ce:display>The objective functions 
						<ce:cross-refs refid="e0055 e0090 e0105">(12), (21) and (26)</ce:cross-refs> can be rewritten as
						<ce:display>
							<ce:formula id="e0210">
								<ce:label>(40)</ce:label>
								<mml:math altimg="si85.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:munder>
										<mml:mrow>
											<mml:mi mathvariant="normal">arg</mml:mi>
											<mml:mspace width="0.12em"/>
											<mml:mi mathvariant="normal">min</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi mathvariant="bold-italic">α</mml:mi>
										</mml:mrow>
									</mml:munder>
									<mml:mfrac>
										<mml:mrow>
											<mml:msup>
												<mml:mrow>
													<mml:mi mathvariant="bold-italic">α</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>T</mml:mi>
												</mml:mrow>
											</mml:msup>
											<mml:mi mathvariant="normal">Δ</mml:mi>
											<mml:mi mathvariant="bold">K</mml:mi>
											<mml:mi mathvariant="normal">Δ</mml:mi>
											<mml:msup>
												<mml:mrow>
													<mml:mi mathvariant="bold">K</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>T</mml:mi>
												</mml:mrow>
											</mml:msup>
											<mml:mi mathvariant="bold-italic">α</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:msup>
												<mml:mrow>
													<mml:mi mathvariant="bold-italic">α</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>T</mml:mi>
												</mml:mrow>
											</mml:msup>
											<mml:msup>
												<mml:mrow>
													<mml:mi mathvariant="bold">KK</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>T</mml:mi>
												</mml:mrow>
											</mml:msup>
											<mml:mi mathvariant="bold-italic">α</mml:mi>
										</mml:mrow>
									</mml:mfrac>
								</mml:math>
							</ce:formula>
						</ce:display>
						<ce:display>
							<ce:formula id="e0215">
								<ce:label>(41)</ce:label>
								<mml:math altimg="si86.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:munder>
										<mml:mrow>
											<mml:mi mathvariant="normal">arg</mml:mi>
											<mml:mspace width="0.12em"/>
											<mml:mi mathvariant="normal">min</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi mathvariant="bold-italic">α</mml:mi>
										</mml:mrow>
									</mml:munder>
									<mml:mfrac>
										<mml:mrow>
											<mml:msup>
												<mml:mrow>
													<mml:mi mathvariant="bold-italic">α</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>T</mml:mi>
												</mml:mrow>
											</mml:msup>
											<mml:mi mathvariant="normal">Δ</mml:mi>
											<mml:mover accent="true">
												<mml:mrow>
													<mml:mi mathvariant="bold">K</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mo stretchy="true">¯</mml:mo>
												</mml:mrow>
											</mml:mover>
											<mml:mi mathvariant="normal">Δ</mml:mi>
											<mml:msup>
												<mml:mrow>
													<mml:mover accent="true">
														<mml:mrow>
															<mml:mi mathvariant="bold">K</mml:mi>
														</mml:mrow>
														<mml:mrow>
															<mml:mo stretchy="true">¯</mml:mo>
														</mml:mrow>
													</mml:mover>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>T</mml:mi>
												</mml:mrow>
											</mml:msup>
											<mml:mi mathvariant="bold-italic">α</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:msup>
												<mml:mrow>
													<mml:mi mathvariant="bold-italic">α</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>T</mml:mi>
												</mml:mrow>
											</mml:msup>
											<mml:msup>
												<mml:mrow>
													<mml:mi mathvariant="bold">KK</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>T</mml:mi>
												</mml:mrow>
											</mml:msup>
											<mml:mi mathvariant="bold-italic">α</mml:mi>
										</mml:mrow>
									</mml:mfrac>
								</mml:math>
							</ce:formula>
						</ce:display>
						<ce:display>
							<ce:formula id="e0220">
								<ce:label>(42)</ce:label>
								<mml:math altimg="si87.gif" overflow="scroll" xmlns:mml="http://www.w3.org/1998/Math/MathML">
									<mml:munder>
										<mml:mrow>
											<mml:mi mathvariant="normal">arg</mml:mi>
											<mml:mspace width="0.12em"/>
											<mml:mi mathvariant="normal">min</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:mi mathvariant="bold-italic">α</mml:mi>
										</mml:mrow>
									</mml:munder>
									<mml:mfrac>
										<mml:mrow>
											<mml:msup>
												<mml:mrow>
													<mml:mi mathvariant="bold-italic">α</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>T</mml:mi>
												</mml:mrow>
											</mml:msup>
											<mml:mi mathvariant="normal">Δ</mml:mi>
											<mml:mover accent="true">
												<mml:mrow>
													<mml:mi mathvariant="bold">K</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mo stretchy="true">¯</mml:mo>
												</mml:mrow>
											</mml:mover>
											<mml:mi mathvariant="normal">Δ</mml:mi>
											<mml:msup>
												<mml:mrow>
													<mml:mover accent="true">
														<mml:mrow>
															<mml:mi mathvariant="bold">K</mml:mi>
														</mml:mrow>
														<mml:mrow>
															<mml:mo stretchy="true">¯</mml:mo>
														</mml:mrow>
													</mml:mover>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>T</mml:mi>
												</mml:mrow>
											</mml:msup>
											<mml:mi mathvariant="bold-italic">α</mml:mi>
										</mml:mrow>
										<mml:mrow>
											<mml:msup>
												<mml:mrow>
													<mml:mi mathvariant="bold-italic">α</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>T</mml:mi>
												</mml:mrow>
											</mml:msup>
											<mml:mi mathvariant="normal">Δ</mml:mi>
											<mml:mover accent="true">
												<mml:mrow>
													<mml:mi mathvariant="bold">K</mml:mi>
												</mml:mrow>
												<mml:mrow>
													<mml:mo stretchy="true">∼</mml:mo>
												</mml:mrow>
											</mml:mover>
											<mml:mi mathvariant="normal">Δ</mml:mi>
											<mml:msup>
												<mml:mrow>
													<mml:mover accent="true">
														<mml:mrow>
															<mml:mi mathvariant="bold">K</mml:mi>
														</mml:mrow>
														<mml:mrow>
															<mml:mo stretchy="true">∼</mml:mo>
														</mml:mrow>
													</mml:mover>
												</mml:mrow>
												<mml:mrow>
													<mml:mi>T</mml:mi>
												</mml:mrow>
											</mml:msup>
											<mml:mi mathvariant="bold-italic">α</mml:mi>
										</mml:mrow>
									</mml:mfrac>
								</mml:math>
							</ce:formula>
						</ce:display>Finally, we obtain the corresponding eigenvalue problem to minimize the objective functions.
					</ce:para>
				</ce:section>
				<ce:section id="s0070" view="all">
					<ce:label>5</ce:label>
					<ce:section-title>Experimental results</ce:section-title>
					<ce:section id="s0075" view="all">
						<ce:label>5.1</ce:label>
						<ce:section-title>Overview</ce:section-title>
						<ce:para id="p0180" view="all">In this section, we demonstrate several visualization and classification applications using the NNP framework. 
							<ce:cross-ref refid="t0005">Table 1</ce:cross-ref>
							<ce:float-anchor refid="t0005"/> shows an overview for the data sets and the corresponding algorithms used in the experiments.
						</ce:para>
					</ce:section>
					<ce:section id="s0080" view="all">
						<ce:label>5.2</ce:label>
						<ce:section-title>Visualization tasks</ce:section-title>
						<ce:para id="p0185" view="all">We first apply the NNP-1, NNP-2, and NNP-3 algorithms to several visualization applications.</ce:para>
						<ce:section id="s0085" view="all">
							<ce:label>5.2.1</ce:label>
							<ce:section-title>NNP-1 on image sequences</ce:section-title>
							<ce:para id="p0190" view="all">The proposed NNP-1 algorithm can be applied to deal with image sequences. In this section, we demonstrate the NNP-1 algorithm on two examples.
								<ce:list id="l0040">
									<ce:list-item id="o0090">
										<ce:para id="p0440" view="all">
											<ce:bold>COIL-100 image sequence</ce:bold>: The synthetic image sequences are generated from the COIL-100 (Columbia object image library) database. The COIL-100 database contains 100 objects, and each object has 72 images with different angles of rotation. The image size is 64
											<ce:hsp sp="0.25"/>×
											<ce:hsp sp="0.25"/>64
											<ce:hsp sp="0.25"/>=
											<ce:hsp sp="0.25"/>4096. 
											<ce:cross-ref refid="f0005">Fig. 1</ce:cross-ref>
											<ce:float-anchor refid="f0005"/> gives 72 images of a duck object.
										</ce:para>
										<ce:para id="p0195" view="all">We perform the NNP-1 algorithm in the expanded space of polynomials of second degree. It is obvious that the input dimensions become much higher after an expansion. For this reason, at the preprocessing stage, PCA is adopted to reduce the sample dimensionality from 4096 to 50. We choose two image sequences. One includes only a single object, and the other includes two objects. The experimental results are shown in 
											<ce:cross-ref refid="f0010">Fig. 2</ce:cross-ref>
											<ce:float-anchor refid="f0010"/>. We also obtain good mapping results when the parameter of polynomial degree is set to 3. (In this case, the original data dimensionality is reduced to 20 by PCA considering the computational cost.) Moreover, similar results are also obtained when a Gaussian kernel of 
											<ce:italic>σ</ce:italic>
											<ce:hsp sp="0.25"/>=
											<ce:hsp sp="0.25"/>1 is used.
										</ce:para>
									</ce:list-item>
									<ce:list-item id="o0095">
										<ce:para id="p0445" view="all">
											<ce:bold>Vista analog clock image sequence</ce:bold>: We test our algorithm on the Vista analog clock image sequence, which is synthesized by screen captures. The image sequence consists of 60 frames. The size of each frame is 240
											<ce:hsp sp="0.25"/>×
											<ce:hsp sp="0.25"/>240. PCA is adopted to reduce the input dimensionality to 50. The results with a polynomial expansion of second degree are shown in 
											<ce:cross-ref refid="f0015">Fig. 3</ce:cross-ref>
											<ce:float-anchor refid="f0015"/>.
										</ce:para>
										<ce:para id="p0200" view="all">Obviously, if the last frame was the same as the first one, the mapping representations would also be a circle.</ce:para>
									</ce:list-item>
									<ce:list-item id="o0100">
										<ce:para id="p0450" view="all">
											<ce:bold>Face image sequence</ce:bold>: We also apply our algorithm to a face image sequence 
											<ce:cross-ref refid="b0175">[35]</ce:cross-ref>. This face image sequence contains 1965 frames. Each image is a 560-dimensional vector. We first use PCA to reduce the input dimensionality to 50. 
											<ce:cross-ref refid="f0020">Fig. 4</ce:cross-ref>
											<ce:float-anchor refid="f0020"/> shows the mapping results with a polynomial expansion of second degree. As shown in 
											<ce:cross-ref refid="f0020">Fig. 4</ce:cross-ref>, the face images are correctly divided into two clusters. The left cluster includes the faces with an open mouth, and the right cluster are the faces with a closed mouth.
										</ce:para>
									</ce:list-item>
								</ce:list>
							</ce:para>
						</ce:section>
						<ce:section id="s0090" view="all">
							<ce:label>5.2.2</ce:label>
							<ce:section-title>NNP-2 and NNP-3 on image data sets</ce:section-title>
							<ce:para id="p0205" view="all">In this section, we consider some data sets without a temporal structure using the proposed NNP-2 and NNP-3 algorithms. We perform them on synthetic data sets, COIL-100 database, and face images to validate their efficiency.
								<ce:list id="l0045">
									<ce:list-item id="o0105">
										<ce:para id="p0455" view="all">
											<ce:bold>Synthetic image data sets</ce:bold>: We execute our algorithms on synthetic image data sets including Swiss roll, S curve, 3D cluster (Cluster equals to 3 and 8), Punctured sphere, Twin peaks, Gaussian randomly sampled, Occluded disks, Corner planes and Toroidal helix. The number of data points is 800. The results are compared to other manifold learning approaches using mani matlab package
											<ce:footnote id="fn1">
												<ce:label>1</ce:label>
												<ce:note-para>
													<ce:inter-ref xlink:href="http://www.math.ucla.edu/wittman/mani/index.html" xlink:type="simple" xmlns:xlink="http://www.w3.org/1999/xlink">http://www.math.ucla.edu/wittman/mani/index.html</ce:inter-ref>.
												</ce:note-para>
											</ce:footnote>
											<ce:cross-ref refid="fn1">
												<ce:sup loc="post">1</ce:sup>
											</ce:cross-ref> written by Todd Wittman.
										</ce:para>
										<ce:para id="p0210" view="all">We choose a polynomial expansion of third degree. The experimental results (
											<ce:italic>k</ce:italic>
											<ce:hsp sp="0.25"/>=
											<ce:hsp sp="0.25"/>8) are shown in 
											<ce:cross-ref refid="f0025">Fig. 5</ce:cross-ref>
											<ce:float-anchor refid="f0025"/>. Moreover, similar results are also obtained when using a Gaussian kernel (
											<ce:italic>σ</ce:italic>
											<ce:hsp sp="0.25"/>=
											<ce:hsp sp="0.25"/>1).
										</ce:para>
										<ce:para id="p0215" view="all">As shown in 
											<ce:cross-ref refid="f0025">Fig. 5</ce:cross-ref>, the NNP-2 algorithm can find better low dimensional representations on most data sets. For the Swiss Roll, NNP-2 can find the manifold but the result is distorted. In addition, for the non-uniform sampling data “Gaussian randomly sampled” discussed in Section 
											<ce:cross-ref refid="s0050">3.3</ce:cross-ref>, NNP-2 cannot handle the changes in sampling. So we adopt NNP-3 to justify the results shown in 
											<ce:cross-ref refid="f0030">Fig. 6</ce:cross-ref>
											<ce:float-anchor refid="f0030"/>.
										</ce:para>
										<ce:para id="p0220" view="all">In some cases, the proposed algorithm should be robust on sparse data sets when only a few data points can be obtained. Experimental results on three sparse data sets are shown in 
											<ce:cross-ref refid="f0035">Fig. 7</ce:cross-ref>
											<ce:float-anchor refid="f0035"/>. From the results, we can see that the algorithms can deal relatively well with sparse data sets.
										</ce:para>
									</ce:list-item>
									<ce:list-item id="o0110">
										<ce:para id="p0460" view="all">
											<ce:bold>COIL-100 database</ce:bold>: We apply NNP-2 and NNP-3 with polynomials of second degree to dimensionality reduction tasks on the COIL-100 database. PCA is also adopted to reduce the data dimensionality from 4096 to 50. The experimental results (
											<ce:italic>k</ce:italic>
											<ce:hsp sp="0.25"/>=
											<ce:hsp sp="0.25"/>3) are shown in 
											<ce:cross-ref refid="f0040">Fig. 8</ce:cross-ref>
											<ce:float-anchor refid="f0040"/>.
										</ce:para>
										<ce:para id="p0225" view="all">In this uniform sampling data experiment, the NNP-2 algorithm looks better than the NNP-3 algorithm. This is because NNP-3 is suitable for non-uniform sampling data, e.g., “Gaussian randomly sampled”. We also compare the results with those of other classical manifold learning algorithms. As 
											<ce:cross-ref refid="f0045">Fig. 9</ce:cross-ref>
											<ce:float-anchor refid="f0045"/> shows, only Isomap and our algorithm can find the satisfied representations.
										</ce:para>
									</ce:list-item>
									<ce:list-item id="o0115">
										<ce:para id="p0465" view="all">
											<ce:bold>Face images</ce:bold>: Three face image data sets are used to verify the effectiveness of the NNP-2 algorithm on visualization applications.
											<ce:list id="l0005">
												<ce:list-item id="o0005">
													<ce:label>•</ce:label>
													<ce:para id="p0355" view="all">We apply the NNP-2 algorithm to the face image data set #1 which is the same as 
														<ce:cross-ref refid="b0220">[44]</ce:cross-ref>. This data set consists of 698 face images taken from sequential frames of a small video. The size of each face image is 64
														<ce:hsp sp="0.25"/>×
														<ce:hsp sp="0.25"/>64
														<ce:hsp sp="0.25"/>=
														<ce:hsp sp="0.25"/>4096. In order to reduce the input dimensionality, we perform PCA on this data set first. Then, each face image is represented by a point in the 50-dimensional space. 
														<ce:cross-ref refid="f0050">Fig. 10</ce:cross-ref>
														<ce:float-anchor refid="f0050"/>(a) shows the results with 
														<ce:italic>k</ce:italic>
														<ce:hsp sp="0.25"/>=
														<ce:hsp sp="0.25"/>8 using a polynomials expansion of second degree or a Gaussian kernel (
														<ce:italic>σ</ce:italic>
														<ce:hsp sp="0.25"/>=
														<ce:hsp sp="0.25"/>1). It is clear that the pose of each face changes smoothly from left to right along the horizonal line, and the view angle alters gradually from bottom to top along the vertical line. Thus, the NNP-2 algorithm can discover the satisfied low dimensional representations.
													</ce:para>
												</ce:list-item>
												<ce:list-item id="o0010">
													<ce:label>•</ce:label>
													<ce:para id="p0360" view="all">We apply the NNP-2 algorithm to another face image data set #2 
														<ce:cross-ref refid="b0175">[35]</ce:cross-ref>. This data set contains 1965 face images taken from sequential frames of a relatively longer video. Each image is a 560-dimensional vector. We employ the same preprocessing stage and parameters that are used in the face image data set #1. 
														<ce:cross-ref refid="f0050">Fig. 10</ce:cross-ref>(b) shows the mapping results. As shown in 
														<ce:cross-ref refid="f0050">Fig. 10</ce:cross-ref>(b), the face images are correctly divided into two clusters. The left cluster corresponds to the faces with a closed mouth, and the right cluster corresponds to the faces with an open mouth.
													</ce:para>
													<ce:para id="p0230" view="all">As this data set is taken from a video, we can directly use NNP-1 for this video. The results on both the sequence and the face images (shown in Figs. 
														<ce:cross-ref refid="f0020">4</ce:cross-ref> and 
														<ce:cross-ref refid="f0050">10</ce:cross-ref>(b)) demonstrate that NNP-2 uses KNN to realign the video frames into an approximation of the original video and can be regarded as an extension of NNP-1 to deal with data without a temporal structure.
													</ce:para>
												</ce:list-item>
												<ce:list-item id="o0015">
													<ce:label>•</ce:label>
													<ce:para id="p0365" view="all">Next, we randomly select 500 images from the face image data set #2 without the restriction that the images must be from sequential frames. 
														<ce:cross-ref refid="f0050">Fig. 10</ce:cross-ref>(c) shows the mapping results on the face data set #3. From the results, we see that our proposed method can also successfully deal with relatively sparse data sets.
													</ce:para>
												</ce:list-item>
											</ce:list>
										</ce:para>
									</ce:list-item>
								</ce:list>
							</ce:para>
						</ce:section>
					</ce:section>
					<ce:section id="s0095" view="all">
						<ce:label>5.3</ce:label>
						<ce:section-title>Handwritten digit recognition task</ce:section-title>
						<ce:para id="p0235" view="all">In this section, we discuss the results obtained using NNP-2 and NNP-3 on the MNIST handwritten digit database. The MNIST database 
							<ce:cross-ref refid="b0135">[27]</ce:cross-ref> is a widely known benchmark, which consists of 70,000 digits, divided into 60,000 training digits and 10,000 test digits. The image size of each handwritten digit is 28
							<ce:hsp sp="0.25"/>×
							<ce:hsp sp="0.25"/>28
							<ce:hsp sp="0.25"/>=
							<ce:hsp sp="0.25"/>784. The experiments performed here are based on the data set of matlab format.
							<ce:footnote id="fn2">
								<ce:label>2</ce:label>
								<ce:note-para>
									<ce:inter-ref xlink:href="http://www.cs.toronto.edu/roweis/data.html" xlink:type="simple" xmlns:xlink="http://www.w3.org/1999/xlink">http://www.cs.toronto.edu/roweis/data.html</ce:inter-ref>.
								</ce:note-para>
							</ce:footnote>
							<ce:cross-ref refid="fn2">
								<ce:sup loc="post">2</ce:sup>
							</ce:cross-ref>
						</ce:para>
						<ce:para id="p0240" view="all">As NNP-2 and NNP-3 are unsupervised algorithms, we modify them to perform classification tasks using class label information. The detailed modification is stated below:</ce:para>
						<ce:para id="p0245" view="all">Recall that given 
							<ce:bold>X</ce:bold> we construct 
							<ce:bold>S</ce:bold> consisting of neighboring points and 
							<ce:bold>F</ce:bold> consisting of pairs of points far from each other. Here we add additional class label constraints. In other words, for each point 
							<ce:bold>x</ce:bold>
							<ce:inf loc="post">
								<ce:italic>i</ce:italic>
							</ce:inf>, we randomly choose 
							<ce:italic>m</ce:italic> points from the same class and 
							<ce:italic>l</ce:italic> farthest points from different classes, and then construct 
							<ce:bold>S</ce:bold> and 
							<ce:bold>F</ce:bold> respectively. The values of 
							<ce:italic>m</ce:italic> and 
							<ce:italic>l</ce:italic> parameters can be chosen as large as possible. But for very large training samples, it is necessary to consider the computation cost, so more suitable values are preferred. In our case, the experiments are performed with 
							<ce:italic>m</ce:italic>
							<ce:hsp sp="0.25"/>=
							<ce:hsp sp="0.25"/>15 and 
							<ce:italic>l</ce:italic>
							<ce:hsp sp="0.25"/>=
							<ce:hsp sp="0.25"/>10.
						</ce:para>
						<ce:para id="p0250" view="all">We use 
							<ce:italic>k</ce:italic>-nearest neighbor classifier with Mahalanobis distance to perform classification tasks. We select the Mahalanobis distance for two reasons. First, Mahalanobis distance takes into account the correlation of the data set and can be widely used in calculating the similarity between an unknown sample set and a known one in pattern recognition tasks 
							<ce:cross-ref refid="b0145">[29]</ce:cross-ref>. Second, the experimental results on the MNIST database have also proven that performance using the Mahalanobis distance is better than using the Euclidean distance.
						</ce:para>
						<ce:para id="p0255" view="all">For an original 28
							<ce:hsp sp="0.25"/>×
							<ce:hsp sp="0.25"/>28
							<ce:hsp sp="0.25"/>=
							<ce:hsp sp="0.25"/>784 image, it is clear that the input dimensions become much higher after a nonlinear expansion. For this reason, at the preprocessing stage, PCA is adopted to reduce the sample dimensions from 784 to a smaller number of dimensions (from 10 to 75 with polynomials of second degree and from 10 to 35 with polynomials of third degree). It is obvious that the performance can be further improved if we use a higher number of input dimensions and polynomials of higher degree. Under the limited computational resources of our system (Windows XP with P4 CPU and 1.0
							<ce:hsp sp="0.25"/>GB RAM), the best performance achieved is 98.58% using supervised NNP-3 and KNN classifier (
							<ce:italic>k</ce:italic>
							<ce:hsp sp="0.25"/>=
							<ce:hsp sp="0.25"/>4) with polynomial of third degree and 35 input dimensions. 
							<ce:cross-ref refid="t0010">Table 2</ce:cross-ref>
							<ce:float-anchor refid="t0010"/> gives the error rates compared to other methods. These methods can be divided into two categories based on whether they have preprocessing or not. Some of these methods used the deskewed training images by computing the principal axis of the shape that is closest to the vertical and shifting the lines to make it vertical. In other methods, the training set was expanded by artificially distorting the original training samples. The detailed overview of error rates on the MNIST database can be found at the web site.
							<ce:footnote id="fn3">
								<ce:label>3</ce:label>
								<ce:note-para>
									<ce:inter-ref xlink:href="http://yann.lecun.com/exdb/mnist/" xlink:type="simple" xmlns:xlink="http://www.w3.org/1999/xlink">http://yann.lecun.com/exdb/mnist/</ce:inter-ref>.
								</ce:note-para>
							</ce:footnote>
							<ce:cross-ref refid="fn3">
								<ce:sup loc="post">3</ce:sup>
							</ce:cross-ref>
						</ce:para>
						<ce:para id="p0260" view="all">From 
							<ce:cross-ref refid="t0010">Table 2</ce:cross-ref>, we see that the performance using the supervised NNP-3 algorithm is better than using the supervised NNP-2 algorithm, because the former considers local and class discriminant information simultaneously. This characteristic makes the supervised NNP-3 more powerful and more intuitive than the supervised NNP-2 for classification tasks. Although the error rates of our methods (1.51% and 1.42%) are higher than some methods on the MNIST database, it is still an interesting work considering the fact that many manifold learning algorithms cannot be directly applied to pattern recognition tasks. Furthermore, we can use many approaches to improve the recognition performance as is done in other handwritten recognition algorithms. For example, in some methods shown in 
							<ce:cross-ref refid="t0010">Table 2</ce:cross-ref>, the training set was increased by the artificially distorting patterns. In addition, some better classifiers such as SVM may also be used to further improve the performance.
						</ce:para>
					</ce:section>
					<ce:section id="s0100" view="all">
						<ce:label>5.4</ce:label>
						<ce:section-title>Discussion</ce:section-title>
						<ce:para id="p0265" view="all">In this paper, we provide a nonlinear dimensionality reduction framework using the principle of temporal coherence. Under such a framework, we propose three algorithms to deal with both image sequences and image data. Our experimental results show that the biologically motivated temporal coherence principle, as an attractive learning rule, can lead to invariant low dimensional feature representations for fast varying input data.</ce:para>
						<ce:section id="s0105" view="all">
							<ce:label>5.4.1</ce:label>
							<ce:section-title>NNP-1 on image sequences</ce:section-title>
							<ce:para id="p0270" view="all">The experimental results on image sequences demonstrate that the NNP-1 algorithm is suitable to deal with video data. In comparison with other manifold learning algorithms, the NNP-1 algorithm has several characteristics.</ce:para>
							<ce:para id="p0275" view="all">Firstly, the NNP-1 algorithm applies the temporal coherence principle to dimensionality reduction problems. Although many manifold learning algorithms have been successfully employed to discover the low dimensional representations of image data, they always ignore the temporal coherence between frames when dealing with video data. By considering the temporal coherence in the proposed algorithm, we can take advantage of the information about neighborhood structure and local geometry of the manifold.</ce:para>
							<ce:para id="p0280" view="all">Secondly, other classic manifold learning algorithms require a neighborhood-size parameter 
								<ce:italic>k</ce:italic>. In contrast, the NNP-1 algorithm does not require such a parameter for video data. However, we need to define the parameter of a nonlinear expansion, such as 
								<ce:italic>d</ce:italic> for a polynomial expansion. It is fortunate that we can follow a simple rule to choose an appropriate parameter. In brief, we should choose a higher degree for a polynomial expansion provided that there is enough system memory. For example, we can obtain similar circle manifolds on the second or third degree polynomial expansion space as shown in 
								<ce:cross-ref refid="f0010">Fig. 2</ce:cross-ref>. Generally, if we can use higher degree polynomials, the results will be better. However, higher degree polynomials have to rely on a smaller number of input dimensions. In our experiments, we choose 
								<ce:italic>d</ce:italic>
								<ce:hsp sp="0.25"/>=
								<ce:hsp sp="0.25"/>2 for higher input dimensions and 
								<ce:italic>d</ce:italic>
								<ce:hsp sp="0.25"/>=
								<ce:hsp sp="0.25"/>3 for lower input dimensions.
							</ce:para>
							<ce:para id="p0285" view="all">Finally, the NNP-1 algorithm provides an explicit map for both training and test data, so it can be easily used to perform recognition and classification tasks. Comparatively, most manifold learning algorithms, such as Isomap, LLE, and Laplacian Eigenmap, only generate an implicit map based on training data sets. When used on test data, they cannot estimate the mapping representations. Some recent studies try to tackle such limits through computing the Kullback–Leibler divergence between the test image data and a learned manifold density 
								<ce:cross-ref refid="b0005">[1]</ce:cross-ref>.
							</ce:para>
						</ce:section>
						<ce:section id="s0110" view="all">
							<ce:label>5.4.2</ce:label>
							<ce:section-title>NNP-2 and NNP-3 on image data sets</ce:section-title>
							<ce:para id="p0290" view="all">For the data without a temporal structure, considering effectiveness (mapping results) and efficiency, we compare NNP-2 and NNP-3 with other manifold learning algorithms using synthetic image data sets generated by Todd Wittman. The mapping quality results are given in 
								<ce:cross-ref refid="t0015">Table 3</ce:cross-ref>
								<ce:float-anchor refid="t0015"/>. The symbols, √ and ×, represent the good or bad mapping results obtained by each method respectively. The efficiency comparison results are obtained with a Windows XP system with P4 CPU and 1.0
								<ce:hsp sp="0.25"/>GB RAM, and are shown in 
								<ce:cross-ref refid="t0020">Table 4</ce:cross-ref>
								<ce:float-anchor refid="t0020"/>. The fastest method for each data set is emphasized with bold font.
							</ce:para>
							<ce:para id="p0295" view="all">It is hard to say which one is the best. In terms of mapping quality, Isomap and NNP-2 (NNP-3 for “Gaussian randomly sampled”) can handle most data sets, but they are slower than other algorithms. However, NNP-2 is faster than Isomap.</ce:para>
						</ce:section>
						<ce:section id="s0115" view="all">
							<ce:label>5.4.3</ce:label>
							<ce:section-title>Kernel extension</ce:section-title>
							<ce:para id="p0300" view="all">Since the explicit nonlinear expansion grows exponentially as the input dimension increases, the proposed methods clearly suffer from the curse of dimensionality. In order to solve this problem, the kernel extension is introduced in Section 
								<ce:cross-ref refid="s0065">4</ce:cross-ref>.
							</ce:para>
							<ce:para id="p0305" view="all">We evaluate the kernel based algorithms on the same data sets mentioned in Section 
								<ce:cross-ref refid="s0070">5</ce:cross-ref>. First, we apply the kernel based NNP-1 to the COIL-100 object image sequence. The results obtained using a Gaussian kernel (
								<ce:italic>σ</ce:italic>
								<ce:hsp sp="0.25"/>=
								<ce:hsp sp="0.25"/>1) look like 
								<ce:cross-ref refid="f0010">Fig. 2</ce:cross-ref>, so we do not show them anymore. Second, we test the kernel based NNP-2 and NNP-3 on synthetic image data sets. We also obtain similar results with a Gaussian kernel (
								<ce:italic>σ</ce:italic>
								<ce:hsp sp="0.25"/>=
								<ce:hsp sp="0.25"/>1) to those shown in 
								<ce:cross-ref refid="f0025">Fig. 5</ce:cross-ref>.
							</ce:para>
							<ce:para id="p0310" view="all">In general, the kernel based NNP algorithms can avoid the curse of dimensionality by calculating the covariance matrices on temporal dimensions instead of space dimensions. They, however, require that the length of the data set is small. For example, the kernel NNP methods rapidly reach their limits on the MNIST database due to the large number of samples. Thus, we can only perform the classification task using a polynomial expansion with second or third degree.</ce:para>
						</ce:section>
						<ce:section id="s0120" view="all">
							<ce:label>5.4.4</ce:label>
							<ce:section-title>Effect of the parameters</ce:section-title>
							<ce:para id="p0315" view="all">Our proposed NNP-1 algorithm needs to define the parameter of a nonlinear expansion space, such as 
								<ce:italic>d</ce:italic> for a polynomial expansion. Moreover, the NNP-2 and NNP-3 algorithms require a neighborhood-size parameter, which is similar to other classic manifold learning algorithms, such as Isomap, LLE, and Laplacian Eigenmaps. So in this section we give basic instructions on how to define a suitable parameter.
								<ce:list id="l0050">
									<ce:list-item id="o0120">
										<ce:para id="p0470" view="all">
											<ce:bold>Degree of polynomial expansion</ce:bold>: The idea for choosing the degree of a polynomial expansion is simple. This degree should be as high as possible. 
											<ce:cross-ref refid="f0055">Fig. 11</ce:cross-ref>
											<ce:float-anchor refid="f0055"/> gives the classification accuracies on the MNIST benchmark using different degree values and different input dimensions.
										</ce:para>
										<ce:para id="p0320" view="all">From 
											<ce:cross-ref refid="f0055">Fig. 11</ce:cross-ref>, we conclude that the accuracy rate increases monotonically with increasing degree of polynomials or input dimensions. However, higher degree polynomials require smaller number of input dimensions. In our experiments, we choose 
											<ce:italic>d</ce:italic>
											<ce:hsp sp="0.25"/>=
											<ce:hsp sp="0.25"/>2 for the higher dimensional input data and 
											<ce:italic>d</ce:italic>
											<ce:hsp sp="0.25"/>=
											<ce:hsp sp="0.25"/>3 for the lower dimensional input data. Specially:
											<ce:list id="l0010">
												<ce:list-item id="o0020">
													<ce:label>•</ce:label>
													<ce:para id="p0370" view="all">Section 
														<ce:cross-ref refid="s0085">5.2.1</ce:cross-ref>: We use
														<ce:list id="l0015">
															<ce:list-item id="o0025">
																<ce:label>–</ce:label>
																<ce:para id="p0375" view="all">second degree polynomial expansion for the 50-dimensional reduced data.</ce:para>
															</ce:list-item>
															<ce:list-item id="o0030">
																<ce:label>–</ce:label>
																<ce:para id="p0380" view="all">third degree polynomial expansion for the 20-dimensional reduced data.</ce:para>
															</ce:list-item>
														</ce:list>
													</ce:para>
												</ce:list-item>
												<ce:list-item id="o0035">
													<ce:label>•</ce:label>
													<ce:para id="p0385" view="all">Section 
														<ce:cross-ref refid="s0090">5.2.2</ce:cross-ref>: We use
														<ce:list id="l0020">
															<ce:list-item id="o0040">
																<ce:label>–</ce:label>
																<ce:para id="p0390" view="all">third degree polynomial expansion for the original data without dimensionality reduction.</ce:para>
															</ce:list-item>
														</ce:list>
													</ce:para>
												</ce:list-item>
												<ce:list-item id="o0045">
													<ce:label>•</ce:label>
													<ce:para id="p0395" view="all">Section 
														<ce:cross-ref refid="s0090">5.2.2</ce:cross-ref>: We use
														<ce:list id="l0025">
															<ce:list-item id="o0050">
																<ce:label>–</ce:label>
																<ce:para id="p0400" view="all">second degree polynomial expansion for the 50-dimensional reduced data.</ce:para>
															</ce:list-item>
														</ce:list>
													</ce:para>
												</ce:list-item>
												<ce:list-item id="o0055">
													<ce:label>•</ce:label>
													<ce:para id="p0405" view="all">Section 
														<ce:cross-ref refid="s0095">5.3</ce:cross-ref>: We use
														<ce:list id="l0030">
															<ce:list-item id="o0060">
																<ce:label>–</ce:label>
																<ce:para id="p0410" view="all">second degree polynomial expansion with input dimensions ranging from 10 to 75.</ce:para>
															</ce:list-item>
															<ce:list-item id="o0065">
																<ce:label>–</ce:label>
																<ce:para id="p0415" view="all">third degree polynomial expansion with input dimensions ranging from 10 to 35.</ce:para>
															</ce:list-item>
															<ce:list-item id="o0070">
																<ce:label>–</ce:label>
																<ce:para id="p0420" view="all">
																	<ce:bold>Neighborhood size</ce:bold>: The choice of the neighborhood-size parameter 
																	<ce:italic>k</ce:italic> is similar to other manifold learning methods. The simplest way is to perform an exhaustive search over 
																	<ce:italic>k</ce:italic> and pick the best one. In practice, if the data set is dense enough, we can simply set 
																	<ce:italic>k</ce:italic>
																	<ce:hsp sp="0.25"/>=
																	<ce:hsp sp="0.25"/>8. However, when the data set is very sparse (it always occurs in real applications), it is very important to set 
																	<ce:italic>k</ce:italic> appropriately, neither too big nor small. In 
																	<ce:cross-ref refid="b0230">[46]</ce:cross-ref>, an adaptive selection of the neighborhood size 
																	<ce:italic>k</ce:italic> was proposed.
																</ce:para>
															</ce:list-item>
														</ce:list>
													</ce:para>
												</ce:list-item>
											</ce:list>
										</ce:para>
										<ce:para id="p0325" view="all">In addition, for the supervised algorithms, we need to define the values of 
											<ce:italic>m</ce:italic> and 
											<ce:italic>l</ce:italic>. Since the total number of training patterns is very large in some applications, we cannot compute the covariance matrices using all samples due to the limited time. In this case, we need to choose samples randomly to estimate the covariance matrices of the “temporal variation”. Generally, we simply run the algorithms over various values and compare the efficiency to pick an appropriate parameter.
										</ce:para>
										<ce:para id="p0330" view="all">For example, in the MNIST handwritten digit recognition experiments, when choosing 
											<ce:italic>m</ce:italic>
											<ce:hsp sp="0.25"/>=
											<ce:hsp sp="0.25"/>15 and 
											<ce:italic>l</ce:italic>
											<ce:hsp sp="0.25"/>=
											<ce:hsp sp="0.25"/>10, the lengths of 
											<ce:bold>S</ce:bold> and 
											<ce:bold>F</ce:bold> are 2
											<ce:hsp sp="0.25"/>×
											<ce:hsp sp="0.25"/>60,000
											<ce:hsp sp="0.25"/>×
											<ce:hsp sp="0.25"/>15
											<ce:hsp sp="0.25"/>=
											<ce:hsp sp="0.25"/>1,800,000 and 2
											<ce:hsp sp="0.25"/>×
											<ce:hsp sp="0.25"/>60,000
											<ce:hsp sp="0.25"/>×
											<ce:hsp sp="0.25"/>10
											<ce:hsp sp="0.25"/>=
											<ce:hsp sp="0.25"/>1,200,000, respectively. The computation on those large matrices takes much more time. We choose several values of 
											<ce:italic>m</ce:italic> and 
											<ce:italic>l</ce:italic>. The performance of 
											<ce:italic>m</ce:italic>
											<ce:hsp sp="0.25"/>=
											<ce:hsp sp="0.25"/>15 and 
											<ce:italic>l</ce:italic>
											<ce:hsp sp="0.25"/>=
											<ce:hsp sp="0.25"/>10 is better than small values. Even if larger values are chosen, the performance does not improve anymore. Thus, we choose 
											<ce:italic>m</ce:italic>
											<ce:hsp sp="0.25"/>=
											<ce:hsp sp="0.25"/>15 and 
											<ce:italic>l</ce:italic>
											<ce:hsp sp="0.25"/>=
											<ce:hsp sp="0.25"/>10 in our experiments. Unfortunately, the choosing method for parameters is not backed up by any proof and only based on practical experience.
										</ce:para>
									</ce:list-item>
								</ce:list>
							</ce:para>
						</ce:section>
						<ce:section id="s0125" view="all">
							<ce:label>5.4.5</ce:label>
							<ce:section-title>Comparisons with SFA</ce:section-title>
							<ce:para id="p0335" view="all">In comparison to SFA, our proposed framework uses the temporal coherence principle to deal with nonlinear dimensionality reduction tasks. We take the COIL-100 duck object as an example. The schematic comparison between NNP and SFA is given in 
								<ce:cross-ref refid="f0060">Fig. 12</ce:cross-ref>
								<ce:float-anchor refid="f0060"/>. In addition, as mentioned earlier, we also use NNP-1 and NNP-2 on the same face images as shown in Figs. 
								<ce:cross-ref refid="f0020">4</ce:cross-ref> and 
								<ce:cross-ref refid="f0050">10</ce:cross-ref>(b). From two experimental results, we see that NNP-2 can be regarded as an extension of NNP-1 to deal with data without a temporal structure.
							</ce:para>
							<ce:para id="p0340" view="all">From 
								<ce:cross-ref refid="f0060">Fig. 12</ce:cross-ref>, we can formulate the following conclusions.
								<ce:list id="l0035">
									<ce:list-item id="o0075">
										<ce:label>•</ce:label>
										<ce:para id="p0425" view="all">The NNP-1 algorithm is proposed for time series such as image sequences, which is directly optimized using the SFA algorithm.</ce:para>
									</ce:list-item>
									<ce:list-item id="o0080">
										<ce:label>•</ce:label>
										<ce:para id="p0430" view="all">The NNP-2 and NNP-3 algorithms are proposed for image data sets. However, NNP-2 is suitable for visualization tasks on the uniform data set. For example, for the COIL-100 duck object, the result of NNP-2 is better than that of NNP-3. For the non-uniform data set, e.g., “Gaussian randomly sampled”, NNP-3 is a better choice.</ce:para>
									</ce:list-item>
									<ce:list-item id="o0085">
										<ce:label>•</ce:label>
										<ce:para id="p0435" view="all">When we use the NNP framework to perform classification tasks, the performance of the NNP-3 algorithm is better than that of NNP-2. The reason could be that NNP-3 considers local and class discriminant information at the same time. Thus, it is an intuitive and more powerful tool for classification tasks.</ce:para>
									</ce:list-item>
								</ce:list>
							</ce:para>
						</ce:section>
					</ce:section>
				</ce:section>
				<ce:section id="s0130" view="all">
					<ce:label>6</ce:label>
					<ce:section-title>Conclusions</ce:section-title>
					<ce:para id="p0345" view="all">In this article, we propose a new nonlinear dimensionality reduction framework NNP using the temporal coherence principle. Under such a framework, we provide three algorithms to deal with different types of data, e.g., image sequences, image data sets. In summary, our proposed algorithms have three advantages: First, the NNP-1 algorithm can deal with temporal data using the temporal coherence principle, such as video data. Although some classic manifold learning algorithms can also deal with video data, they use the same procedure that has been used with image data and do not consider the temporal coherence between sequential frames. In fact, the temporal coherence provides useful information about the neighborhood structure and the local geometry of the manifold. It is reasonable to apply the temporal coherence principle to dimensionality reduction problems. Second, NNP-1, NNP-2, and NNP-3 can be applied to estimating the embedding representations not only on training points but also on test points. Third, NNP-3 combines local and class discriminant information so as to be suitable for classification tasks. Furthermore, the proposed methods can be easily modified to supervised methods to perform classification tasks.</ce:para>
					<ce:para id="p0350" view="all">Our experimental results on several applications, including image sequences, image data sets and the MNIST database, demonstrate that the NNP-1, NNP-2 and NNP-3 algorithms are effective tools for nonlinear dimensionality reduction tasks. So far, our experimental results are obtained on relatively small data sets. These algorithms should be further applied to large data sets and real video data. Ongoing work is still being performed and the results will be reported in the near future.</ce:para>
				</ce:section>
			</ce:sections>
			<ce:acknowledgment xmlns:ce="http://www.elsevier.com/xml/common/schema">
				<ce:section-title>Acknowledgements</ce:section-title>
				<ce:para id="p0475" view="all">We thank David W. Taylor (Yale University) for his intensive reading and we also thank the anonymous reviewers for their helpful comments and constructive suggestions. This work is supported by 
					<ce:grant-sponsor id="GS1" xlink:type="simple" xlink:role="http://www.elsevier.com/xml/linking-roles/grant-sponsor" xmlns:xlink="http://www.w3.org/1999/xlink">National Nature Science Foundation of China</ce:grant-sponsor> (
					<ce:grant-number refid="GS1">60975078</ce:grant-number>, 
					<ce:grant-number refid="GS1">60902058</ce:grant-number>, 
					<ce:grant-number refid="GS1">60805041</ce:grant-number>, 
					<ce:grant-number refid="GS1">60872082</ce:grant-number>) and 
					<ce:grant-sponsor id="GS2" xlink:type="simple" xlink:role="http://www.elsevier.com/xml/linking-roles/grant-sponsor" xmlns:xlink="http://www.w3.org/1999/xlink">Beijing Natural Science Foundation</ce:grant-sponsor> (
					<ce:grant-number refid="GS2">4092033</ce:grant-number>).
				</ce:para>
			</ce:acknowledgment>
		</ja:body>
		<ja:tail view="all">
			<ce:bibliography id="bi005" view="all" xmlns:ce="http://www.elsevier.com/xml/common/schema">
				<ce:section-title>References</ce:section-title>
				<ce:bibliography-sec id="bs005">
					<ce:bib-reference id="b0005">
						<ce:label>[1]</ce:label>
						<ce:other-ref>
							<ce:textref>O. Arandjelovic, G. Shakhnarovich, J. Fisher, R. Cipolla, T. Darrell, Face recognition with image sets using manifold density divergence, in: IEEE Conference on Computer Vision and Pattern Recognition, vol. 15, 2005, pp. 581–588.</ce:textref>
						</ce:other-ref>
					</ce:bib-reference>
					<ce:bib-reference id="b0010">
						<ce:label>[2]</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>M.</ce:given-name>
										<ce:surname>Balasubramanian</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>E.L.</ce:given-name>
										<ce:surname>Schwartz</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>The isomap algorithm and topological stability</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>Science</sb:maintitle>
										</sb:title>
										<sb:volume-nr>295</sb:volume-nr>
									</sb:series>
									<sb:issue-nr>5552</sb:issue-nr>
									<sb:date>2002</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>9</sb:first-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="b0015">
						<ce:label>[3]</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>M.</ce:given-name>
										<ce:surname>Belkin</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>P.</ce:given-name>
										<ce:surname>Niyogi</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Laplacian Eigenmaps and spectral techniques for embedding and clustering</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>Advances in Neural Information Processing Systems</sb:maintitle>
										</sb:title>
										<sb:volume-nr>14</sb:volume-nr>
									</sb:series>
									<sb:date>2001</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>585</sb:first-page>
									<sb:last-page>591</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="b0020">
						<ce:label>[4]</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>M.</ce:given-name>
										<ce:surname>Belkin</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>P.</ce:given-name>
										<ce:surname>Niyogi</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Laplacian Eigenmaps for dimensionality reduction and data representation</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>Neural Computation</sb:maintitle>
										</sb:title>
										<sb:volume-nr>15</sb:volume-nr>
									</sb:series>
									<sb:issue-nr>6</sb:issue-nr>
									<sb:date>2003</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>1373</sb:first-page>
									<sb:last-page>1396</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="b0025">
						<ce:label>[5]</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>M.</ce:given-name>
										<ce:surname>Belkin</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>P.</ce:given-name>
										<ce:surname>Niyogi</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>V.</ce:given-name>
										<ce:surname>Sindhwani</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Manifold regularization: a geometric framework for learning from labeled and unlabeled examples</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>Journal of Machine Learning Research</sb:maintitle>
										</sb:title>
										<sb:volume-nr>6</sb:volume-nr>
									</sb:series>
									<sb:date>2006</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>2399</sb:first-page>
									<sb:last-page>2424</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="b0030">
						<ce:label>[6]</ce:label>
						<ce:other-ref>
							<ce:textref>P. Berkes, Temporal Slowness as an Unsupervised Learning Principle: Self-organization of Complex-cell Receptive Fields and Application to Pattern Recognition, Ph.D. Thesis, Institute for Theoretical Biology, Humboldt University, Berlin, 2005.</ce:textref>
						</ce:other-ref>
					</ce:bib-reference>
					<ce:bib-reference id="b0035">
						<ce:label>[7]</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>P.</ce:given-name>
										<ce:surname>Berkes</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Pattern recognition with slow feature analysis</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>Cognitive Sciences EPrint Archive (CogPrint)</sb:maintitle>
										</sb:title>
										<sb:volume-nr>4104</sb:volume-nr>
									</sb:series>
									<sb:date>2005</sb:date>
								</sb:issue>
							</sb:host>
							<sb:host>
								<sb:e-host>
									<ce:inter-ref xlink:href="http://cogprints.org/4104/" xlink:type="simple" xmlns:xlink="http://www.w3.org/1999/xlink">&lt;http://cogprints.org/4104/&gt;</ce:inter-ref>
								</sb:e-host>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="b0040">
						<ce:label>[8]</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>D.</ce:given-name>
										<ce:surname>Chelidze</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>W.</ce:given-name>
										<ce:surname>Zhou</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Smooth orthogonal decomposition based modal analysis</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>Journal of Sound and Vibration</sb:maintitle>
										</sb:title>
										<sb:volume-nr>292</sb:volume-nr>
									</sb:series>
									<sb:issue-nr>3-5</sb:issue-nr>
									<sb:date>2006</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>461</sb:first-page>
									<sb:last-page>473</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="b0045">
						<ce:label>[9]</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>D.</ce:given-name>
										<ce:surname>Chelidze</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>M.</ce:given-name>
										<ce:surname>Liu</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Reconstructing slow-time dynamics from fasttime measurements</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>Philosophical Transaction of the Royal Society A</sb:maintitle>
										</sb:title>
										<sb:volume-nr>366</sb:volume-nr>
									</sb:series>
									<sb:date>2008</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>729</sb:first-page>
									<sb:last-page>7445</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="b0050">
						<ce:label>[10]</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>D.</ce:given-name>
										<ce:surname>Chelidze</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>J.P.</ce:given-name>
										<ce:surname>Cusumano</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Phase space warping: nonlinear time series analysis for slowly drifting systems</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>Philosophical Transactions of the Royal Society A</sb:maintitle>
										</sb:title>
										<sb:volume-nr>364</sb:volume-nr>
									</sb:series>
									<sb:date>2006</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>2495</sb:first-page>
									<sb:last-page>2513</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="b0055">
						<ce:label>[11]</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>R.R.</ce:given-name>
										<ce:surname>Coifman</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>S.</ce:given-name>
										<ce:surname>Lafon</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>A.B.</ce:given-name>
										<ce:surname>Lee</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>M.</ce:given-name>
										<ce:surname>Maggioni</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>B.</ce:given-name>
										<ce:surname>Nadler</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>F.</ce:given-name>
										<ce:surname>Warner</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>S.W.</ce:given-name>
										<ce:surname>Zucker</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Geometric diffusions as a tool for harmonic analysis and structure definition of data. Part I: Diffusion maps</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>Proceedings of the National Academy of Sciences</sb:maintitle>
										</sb:title>
										<sb:volume-nr>102</sb:volume-nr>
									</sb:series>
									<sb:issue-nr>21</sb:issue-nr>
									<sb:date>2005</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>7426</sb:first-page>
									<sb:last-page>7431</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="b0060">
						<ce:label>[12]</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>P.</ce:given-name>
										<ce:surname>Demartines</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>J.</ce:given-name>
										<ce:surname>Hérault</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Curvilinear component analysis: a selforganizing neural network for nonlinear mapping of data sets</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>IEEE Transactions on Neural Networks</sb:maintitle>
										</sb:title>
										<sb:volume-nr>8</sb:volume-nr>
									</sb:series>
									<sb:issue-nr>1</sb:issue-nr>
									<sb:date>1997</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>148</sb:first-page>
									<sb:last-page>154</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="b0065">
						<ce:label>[13]</ce:label>
						<ce:other-ref>
							<ce:textref>D.L. Donoho, C. Grimes, Hessian Eigenmaps: New Locally Linear Embedding Techniques for High-dimensional Data, Technical Report TR-2003-08, Department of Statistics, Stanford University, 2003.</ce:textref>
						</ce:other-ref>
					</ce:bib-reference>
					<ce:bib-reference id="b0070">
						<ce:label>[14]</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>W.</ce:given-name>
										<ce:surname>Einhäuser</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>J.</ce:given-name>
										<ce:surname>Hipp</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>J.</ce:given-name>
										<ce:surname>Eggert</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>E.</ce:given-name>
										<ce:surname>Körner</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>P.</ce:given-name>
										<ce:surname>König</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Learning viewpoint invariant object representation using a temporal coherence principle</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>Biological Cybernetics</sb:maintitle>
										</sb:title>
										<sb:volume-nr>93</sb:volume-nr>
									</sb:series>
									<sb:date>2005</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>79</sb:first-page>
									<sb:last-page>90</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="b0075">
						<ce:label>[15]</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>P.</ce:given-name>
										<ce:surname>Földiák</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Learning invariance from transformation sequences</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>Neural Computation</sb:maintitle>
										</sb:title>
										<sb:volume-nr>3</sb:volume-nr>
									</sb:series>
									<sb:date>1991</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>194</sb:first-page>
									<sb:last-page>200</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="b0080">
						<ce:label>[16]</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>X.</ce:given-name>
										<ce:surname>Geng</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>D.C.</ce:given-name>
										<ce:surname>Zhan</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>Z.H.</ce:given-name>
										<ce:surname>Zhou</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Supervised nonlinear dimensionality reduction for visualization and classification</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>IEEE Transactions on Systems, Man, and Cybernetics – Part B: Cybernetics</sb:maintitle>
										</sb:title>
										<sb:volume-nr>35</sb:volume-nr>
									</sb:series>
									<sb:issue-nr>6</sb:issue-nr>
									<sb:date>2005</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>1098</sb:first-page>
									<sb:last-page>1107</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="b0085">
						<ce:label>[17]</ce:label>
						<ce:other-ref>
							<ce:textref>A. Guréin-Dugué, P. Teissier, G. Delso-Gafaro, J. Hérault, Curvilinear component analysis for high-dimensional data representation: II. Examples of introducing additional mapping constraints for specific applications, in: International Work-Conference on Artificial and Natural Neural Networks, Alicante, Spain, 1999.</ce:textref>
						</ce:other-ref>
					</ce:bib-reference>
					<ce:bib-reference id="b0090">
						<ce:label>[18]</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>X.F.</ce:given-name>
										<ce:surname>He</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>P.</ce:given-name>
										<ce:surname>Niyogi</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Locality preserving projections</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>Advances in Neural Information Processing Systems</sb:maintitle>
										</sb:title>
										<sb:volume-nr>16</sb:volume-nr>
									</sb:series>
									<sb:date>2003</sb:date>
								</sb:issue>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="b0095">
						<ce:label>[19]</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>G.</ce:given-name>
										<ce:surname>Hinton</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Connectionist learning procedures</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>Artificial Intelligence</sb:maintitle>
										</sb:title>
										<sb:volume-nr>40</sb:volume-nr>
									</sb:series>
									<sb:date>1989</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>185</sb:first-page>
									<sb:last-page>234</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="b0100">
						<ce:label>[20]</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>J.</ce:given-name>
										<ce:surname>Hurri</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>A.</ce:given-name>
										<ce:surname>Hyvärinen</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Simple-cell-like receptive fields maximize temporal coherence in natural video</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>Neural Computation</sb:maintitle>
										</sb:title>
										<sb:volume-nr>15</sb:volume-nr>
									</sb:series>
									<sb:issue-nr>3</sb:issue-nr>
									<sb:date>2003</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>663</sb:first-page>
									<sb:last-page>691</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="b0105">
						<ce:label>[21]</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>A.</ce:given-name>
										<ce:surname>Hyvärinen</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>J.</ce:given-name>
										<ce:surname>Hurri</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>J.</ce:given-name>
										<ce:surname>Väyrynen</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Bubbles: a unifying framework for low-level statistical properties of natural image sequences</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>Optical Society of America</sb:maintitle>
										</sb:title>
										<sb:volume-nr>20</sb:volume-nr>
									</sb:series>
									<sb:issue-nr>7</sb:issue-nr>
									<sb:date>2003</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>1237</sb:first-page>
									<sb:last-page>1252</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="b0110">
						<ce:label>[22]</ce:label>
						<ce:other-ref>
							<ce:textref>C. Kayser, W. Einhäuser, O. Dümmer, P. König, K. Körding, Extracting slow subspaces from natural videos leads to complex cells, in: International Conference on Artificial Neural Networks, Vienna, Austria, 2001, pp. 1075–1080.</ce:textref>
						</ce:other-ref>
					</ce:bib-reference>
					<ce:bib-reference id="b0115">
						<ce:label>[23]</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>D.</ce:given-name>
										<ce:surname>Keysers</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>T.</ce:given-name>
										<ce:surname>Deselaers</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>C.</ce:given-name>
										<ce:surname>Gollan</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>H.</ce:given-name>
										<ce:surname>Ney</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Deformation models for image recognition</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>IEEE Transaction on Pattern Analysis and Machine Intelligence</sb:maintitle>
										</sb:title>
										<sb:volume-nr>29</sb:volume-nr>
									</sb:series>
									<sb:issue-nr>8</sb:issue-nr>
									<sb:date>2007</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>1422</sb:first-page>
									<sb:last-page>1435</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="b0120">
						<ce:label>[24]</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>T.</ce:given-name>
										<ce:surname>Kohonen</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Self-organized formation of topologically correct feature maps</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>Biological Cybernetics</sb:maintitle>
										</sb:title>
										<sb:volume-nr>43</sb:volume-nr>
									</sb:series>
									<sb:date>1982</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>59</sb:first-page>
									<sb:last-page>69</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="b0125">
						<ce:label>[25]</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>K.</ce:given-name>
										<ce:surname>Körding</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>C.</ce:given-name>
										<ce:surname>Kayser</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>W.</ce:given-name>
										<ce:surname>Einhäuser</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>P.</ce:given-name>
										<ce:surname>König</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>How are complex cell properties adapted to the statistics of natural scenes?</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>Journal of Neurophysiology</sb:maintitle>
										</sb:title>
										<sb:volume-nr>91</sb:volume-nr>
									</sb:series>
									<sb:issue-nr>1</sb:issue-nr>
									<sb:date>2004</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>206</sb:first-page>
									<sb:last-page>212</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="b0130">
						<ce:label>[26]</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>F.</ce:given-name>
										<ce:surname>Lauer</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>C.Y.</ce:given-name>
										<ce:surname>Suen</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>G.</ce:given-name>
										<ce:surname>Bloch</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>A trainable feature extractor for handwritten digit recognition</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>Pattern Recognition</sb:maintitle>
										</sb:title>
										<sb:volume-nr>40</sb:volume-nr>
									</sb:series>
									<sb:issue-nr>6</sb:issue-nr>
									<sb:date>2007</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>1816</sb:first-page>
									<sb:last-page>1824</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="b0135">
						<ce:label>[27]</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>Y.</ce:given-name>
										<ce:surname>LeCun</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>L.</ce:given-name>
										<ce:surname>Bottou</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>Y.</ce:given-name>
										<ce:surname>Bengio</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>P.</ce:given-name>
										<ce:surname>Haffner</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Gradient-based learning applied to document recognition</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>Proceedings of the IEEE</sb:maintitle>
										</sb:title>
										<sb:volume-nr>86</sb:volume-nr>
									</sb:series>
									<sb:issue-nr>11</sb:issue-nr>
									<sb:date>1998</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>2278</sb:first-page>
									<sb:last-page>2324</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="b0140">
						<ce:label>[28]</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>J.B.</ce:given-name>
										<ce:surname>Li</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>J.S.</ce:given-name>
										<ce:surname>Pan</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>S.C.</ce:given-name>
										<ce:surname>Chu</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Kernel class-wise locality preserving projection</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>Information Sciences</sb:maintitle>
										</sb:title>
										<sb:volume-nr>178</sb:volume-nr>
									</sb:series>
									<sb:issue-nr>7</sb:issue-nr>
									<sb:date>2008</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>1825</sb:first-page>
									<sb:last-page>1835</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="b0145">
						<ce:label>[29]</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>R.</ce:given-name>
										<ce:surname>De Maesschalck</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>D.</ce:given-name>
										<ce:surname>Jouan-Rimbaud</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>D.L.</ce:given-name>
										<ce:surname>Massart</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>The mahalanobis distance</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>Chemometrics and Intelligent Laboratory Systems</sb:maintitle>
										</sb:title>
										<sb:volume-nr>50</sb:volume-nr>
									</sb:series>
									<sb:issue-nr>1, 4</sb:issue-nr>
									<sb:date>2000</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>1</sb:first-page>
									<sb:last-page>18</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="b0150">
						<ce:label>[30]</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>J.L.</ce:given-name>
										<ce:surname>McFarland</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>A.F.</ce:given-name>
										<ce:surname>Fuchs</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Discharge patterns in nucleus prepositus hypoglossi and adjacent medial vestibular nucleus during horizontal eye movement in behaving macaques</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>Journal of Neurophysiology</sb:maintitle>
										</sb:title>
										<sb:volume-nr>68</sb:volume-nr>
									</sb:series>
									<sb:issue-nr>7</sb:issue-nr>
									<sb:date>1992</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>319</sb:first-page>
									<sb:last-page>332</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="b0155">
						<ce:label>[31]</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>G.</ce:given-name>
										<ce:surname>Mitchison</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Removing time variation with the anti-Hebbian differential synapse</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>Neural Computation</sb:maintitle>
										</sb:title>
										<sb:volume-nr>3</sb:volume-nr>
									</sb:series>
									<sb:date>1991</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>312</sb:first-page>
									<sb:last-page>320</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="b0160">
						<ce:label>[32]</ce:label>
						<ce:other-ref>
							<ce:textref>A. Mojsilovic, B.E. Rogowitz, Capturing image semantics with low-level descriptors, in: International Conference on Image Processing, I, Thessaloniki, Greece, 2001, pp. 18–21.</ce:textref>
						</ce:other-ref>
					</ce:bib-reference>
					<ce:bib-reference id="b0165">
						<ce:label>[33]</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>B.</ce:given-name>
										<ce:surname>Nadler</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>S.</ce:given-name>
										<ce:surname>Lafon</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>R.R.</ce:given-name>
										<ce:surname>Coifman</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>I.G.</ce:given-name>
										<ce:surname>Kevrekidis</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Diffusion maps, spectral clustering and eigenfunctions of Fokker–Planck operators</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>Advances in Neural Information Processing Systems</sb:maintitle>
										</sb:title>
										<sb:volume-nr>18</sb:volume-nr>
									</sb:series>
									<sb:date>2005</sb:date>
								</sb:issue>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="b0170">
						<ce:label>[34]</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>M.</ce:given-name>
										<ce:surname>Ranzato</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>C.S.</ce:given-name>
										<ce:surname>Poultney</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>S.</ce:given-name>
										<ce:surname>Chopra</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>Y.</ce:given-name>
										<ce:surname>LeCun</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Efficient learning of sparse representations with an energy-based model</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>Advances in Neural Information Processing Systems</sb:maintitle>
										</sb:title>
										<sb:volume-nr>19</sb:volume-nr>
									</sb:series>
									<sb:date>2006</sb:date>
								</sb:issue>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="b0175">
						<ce:label>[35]</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>S.T.</ce:given-name>
										<ce:surname>Roweis</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>L.K.</ce:given-name>
										<ce:surname>Saul</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Nonlinear dimensionality analysis by locally linear embedding</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>Science</sb:maintitle>
										</sb:title>
										<sb:volume-nr>290</sb:volume-nr>
									</sb:series>
									<sb:issue-nr>12</sb:issue-nr>
									<sb:date>2000</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>2323</sb:first-page>
									<sb:last-page>2326</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="b0180">
						<ce:label>[36]</ce:label>
						<ce:other-ref>
							<ce:textref>S.A. Sarcia, G. Cantone, V.R. Basili, Adopting curvilinear component analysis to improve software cost estimation accuracy: model, application strategy, and an experimental verification, in: Evaluation and Assessment in Software Engineering, University of Bari, Italy, 2008.</ce:textref>
						</ce:other-ref>
					</ce:bib-reference>
					<ce:bib-reference id="b0185">
						<ce:label>[37]</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>B.</ce:given-name>
										<ce:surname>Schölkopf</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>A.J.</ce:given-name>
										<ce:surname>Smola</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>K.-R.</ce:given-name>
										<ce:surname>Müller</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Nonlinear component analysis as a kernel eigenvalue problem</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>Neural Computation</sb:maintitle>
										</sb:title>
										<sb:volume-nr>10</sb:volume-nr>
									</sb:series>
									<sb:issue-nr>5</sb:issue-nr>
									<sb:date>1998</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>1299</sb:first-page>
									<sb:last-page>1319</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="b0190">
						<ce:label>[38]</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>H.S.</ce:given-name>
										<ce:surname>Seung</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>D.D.</ce:given-name>
										<ce:surname>Lee</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>The manifold ways of perception</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>Science</sb:maintitle>
										</sb:title>
										<sb:volume-nr>290</sb:volume-nr>
									</sb:series>
									<sb:issue-nr>12</sb:issue-nr>
									<sb:date>2000</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>2268</sb:first-page>
									<sb:last-page>2269</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="b0195">
						<ce:label>[39]</ce:label>
						<ce:other-ref>
							<ce:textref>P.Y. Simard, D. Steinkraus, J.C. Platt, Best practices for convolutional neural networks applied to visual document analysis, in: International Conference on Document Analysis and Recognition, vol. 2, 2003, pp. 958–962.</ce:textref>
						</ce:other-ref>
					</ce:bib-reference>
					<ce:bib-reference id="b0200">
						<ce:label>[40]</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>Y.Q.</ce:given-name>
										<ce:surname>Song</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>F.P.</ce:given-name>
										<ce:surname>Nie</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>C.S.</ce:given-name>
										<ce:surname>Zhang</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>S.M.</ce:given-name>
										<ce:surname>Xiang</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>A unified framework for semi-supervised dimensionality reduction</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>Pattern Recognition</sb:maintitle>
										</sb:title>
										<sb:volume-nr>41</sb:volume-nr>
									</sb:series>
									<sb:issue-nr>9</sb:issue-nr>
									<sb:date>2008</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>2789</sb:first-page>
									<sb:last-page>2799</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="b0205">
						<ce:label>[41]</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>J.V.</ce:given-name>
										<ce:surname>Stone</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>A.J.</ce:given-name>
										<ce:surname>Bray</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>A learning rule for extracting spatio-temporal invariances</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>Network: Computation in Neural Systems</sb:maintitle>
										</sb:title>
										<sb:volume-nr>6</sb:volume-nr>
									</sb:series>
									<sb:issue-nr>3</sb:issue-nr>
									<sb:date>1995</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>429</sb:first-page>
									<sb:last-page>436</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="b0210">
						<ce:label>[42]</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>J.S.</ce:given-name>
										<ce:surname>Taube</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Head direction cells and the neurophysiological basis for a sense of direction</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>Progress in Neurobiology</sb:maintitle>
										</sb:title>
										<sb:volume-nr>55</sb:volume-nr>
									</sb:series>
									<sb:issue-nr>3</sb:issue-nr>
									<sb:date>1998</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>225</sb:first-page>
									<sb:last-page>256</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="b0215">
						<ce:label>[43]</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>P.</ce:given-name>
										<ce:surname>Teissier</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>A.A.</ce:given-name>
										<ce:surname>Guréin-Dugué</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>J.L.</ce:given-name>
										<ce:surname>Schwartz</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Models for audiovisual fusion in a noisy-vowel recognition task</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>Journal of VLSI Signal Processing</sb:maintitle>
										</sb:title>
										<sb:volume-nr>20</sb:volume-nr>
									</sb:series>
									<sb:date>1998</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>25</sb:first-page>
									<sb:last-page>44</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="b0220">
						<ce:label>[44]</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>J.B.</ce:given-name>
										<ce:surname>Tenenbaum</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>V.</ce:given-name>
										<ce:surname>de Silva</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>J.C.</ce:given-name>
										<ce:surname>Langford</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>A global geometric framework for nonlinear dimensionality reduction</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>Science</sb:maintitle>
										</sb:title>
										<sb:volume-nr>290</sb:volume-nr>
									</sb:series>
									<sb:issue-nr>12</sb:issue-nr>
									<sb:date>2000</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>2319</sb:first-page>
									<sb:last-page>2323</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="b0225">
						<ce:label>[45]</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>A.</ce:given-name>
										<ce:surname>Vathy-Fogarassy</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>Janos</ce:given-name>
										<ce:surname>Abonyib</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Local and global mappings of topology representing networks</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>Information Sciences</sb:maintitle>
										</sb:title>
										<sb:volume-nr>179</sb:volume-nr>
									</sb:series>
									<sb:issue-nr>21</sb:issue-nr>
									<sb:date>2009</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>3791</sb:first-page>
									<sb:last-page>3803</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="b0230">
						<ce:label>[46]</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>J.</ce:given-name>
										<ce:surname>Wang</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>Z.Y.</ce:given-name>
										<ce:surname>Zhang</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>H.Y.</ce:given-name>
										<ce:surname>Zha</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Adaptive manifold learning</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>Advances in Neural Information Processing Systems</sb:maintitle>
										</sb:title>
										<sb:volume-nr>17</sb:volume-nr>
									</sb:series>
									<sb:date>2005</sb:date>
								</sb:issue>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="b0235">
						<ce:label>[47]</ce:label>
						<ce:other-ref>
							<ce:textref>K.Q. Weinberger, F. Sha, L.K. Saul, Learning a kernel matrix for nonlinear dimensionality reduction, in: International Conference on Machine Learning, 2004.</ce:textref>
						</ce:other-ref>
					</ce:bib-reference>
					<ce:bib-reference id="b0240">
						<ce:label>[48]</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>L.</ce:given-name>
										<ce:surname>Wiskott</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>T.</ce:given-name>
										<ce:surname>Sejnowski</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Slow feature analysis: unsupervised learning of invariances</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>Neural Computation</sb:maintitle>
										</sb:title>
										<sb:volume-nr>14</sb:volume-nr>
									</sb:series>
									<sb:issue-nr>4</sb:issue-nr>
									<sb:date>2002</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>715</sb:first-page>
									<sb:last-page>770</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="b0245">
						<ce:label>[49]</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>J.</ce:given-name>
										<ce:surname>Yang</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>D.</ce:given-name>
										<ce:surname>Zhang</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>J.Y.</ce:given-name>
										<ce:surname>Yang</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>B.</ce:given-name>
										<ce:surname>Niu</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Globally maximizing, locally minimizing: unsupervised discriminant projection with applications to face and palm biometrics</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>IEEE Transactions on Pattern Analysis and Machine Intelligence</sb:maintitle>
										</sb:title>
										<sb:volume-nr>29</sb:volume-nr>
									</sb:series>
									<sb:issue-nr>4</sb:issue-nr>
									<sb:date>2007</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>650</sb:first-page>
									<sb:last-page>664</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="b0250">
						<ce:label>[50]</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>S.C.</ce:given-name>
										<ce:surname>Yan</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>D.</ce:given-name>
										<ce:surname>Xu</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>B.Y.</ce:given-name>
										<ce:surname>Zhang</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>H.J.</ce:given-name>
										<ce:surname>Zhang</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>Q.A.</ce:given-name>
										<ce:surname>Yang</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>S.</ce:given-name>
										<ce:surname>Lin</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Graph embedding and extensions: a general framework for dimensionality reduction</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>IEEE Transactions on Pattern Analysis and Machine Intelligence</sb:maintitle>
										</sb:title>
										<sb:volume-nr>29</sb:volume-nr>
									</sb:series>
									<sb:issue-nr>1</sb:issue-nr>
									<sb:date>2007</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>40</sb:first-page>
									<sb:last-page>51</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="b0255">
						<ce:label>[51]</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>H.J.</ce:given-name>
										<ce:surname>Yin</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>W.L.</ce:given-name>
										<ce:surname>Huang</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Adaptive nonlinear manifolds and their applications to pattern recognition</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>Information Sciences</sb:maintitle>
										</sb:title>
										<sb:volume-nr>180</sb:volume-nr>
									</sb:series>
									<sb:issue-nr>14</sb:issue-nr>
									<sb:date>2010</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>2649</sb:first-page>
									<sb:last-page>2662</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
					<ce:bib-reference id="b0260">
						<ce:label>[52]</ce:label>
						<sb:reference xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema">
							<sb:contribution langtype="en">
								<sb:authors>
									<sb:author>
										<ce:given-name>Z.Y.</ce:given-name>
										<ce:surname>Zhang</ce:surname>
									</sb:author>
									<sb:author>
										<ce:given-name>H.Y.</ce:given-name>
										<ce:surname>Zha</ce:surname>
									</sb:author>
								</sb:authors>
								<sb:title>
									<sb:maintitle>Principal manifolds and nonlinear dimensionality reduction via tangent space alignment</sb:maintitle>
								</sb:title>
							</sb:contribution>
							<sb:host>
								<sb:issue>
									<sb:series>
										<sb:title>
											<sb:maintitle>SIAM Journal of Scientific Computing</sb:maintitle>
										</sb:title>
										<sb:volume-nr>26</sb:volume-nr>
									</sb:series>
									<sb:issue-nr>1</sb:issue-nr>
									<sb:date>2004</sb:date>
								</sb:issue>
								<sb:pages>
									<sb:first-page>313</sb:first-page>
									<sb:last-page>338</sb:last-page>
								</sb:pages>
							</sb:host>
						</sb:reference>
					</ce:bib-reference>
				</ce:bibliography-sec>
			</ce:bibliography>
		</ja:tail>
	</ja:article></doc:document>
